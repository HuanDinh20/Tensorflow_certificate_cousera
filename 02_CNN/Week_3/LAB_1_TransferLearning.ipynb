{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.models import Model, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Flatten, Dense, Dropout"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load pretrained model\n",
    "1. load pretrained model\n",
    "2. load local weights\n",
    "3. frezee its layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "local_weights_file = \"./inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "pretrained_model = InceptionV3(input_shape=(150, 150, 3), include_top=False, weights=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Variable 'conv2d_94/kernel:0' shape=(3, 3, 3, 32) dtype=float32, numpy=\n array([[[[ 1.17440358e-01, -1.16611049e-01, -1.20218992e-02,\n            5.54118305e-02, -5.61316907e-02, -4.38375026e-02,\n            7.56480098e-02, -3.53852957e-02,  1.30200371e-01,\n           -2.78072655e-02,  6.47689253e-02, -7.39864111e-02,\n           -1.34375438e-01,  9.36517566e-02, -1.37786821e-01,\n           -6.66838288e-02, -4.82702851e-02, -1.10198855e-02,\n           -1.12204060e-01, -8.01860243e-02,  6.56046569e-02,\n           -1.22324482e-01, -1.09677851e-01, -7.39870742e-02,\n            8.57607722e-02,  7.38600194e-02,  8.09815526e-03,\n           -4.42118645e-02, -1.05181992e-01, -1.73378810e-02,\n            4.80303466e-02,  6.32096827e-03],\n          [ 1.24079093e-01, -6.91562742e-02, -1.03034750e-01,\n           -1.93515942e-02,  3.81706655e-03, -1.12529755e-01,\n           -1.02668911e-01, -4.71615791e-03,  6.81407005e-02,\n            4.39552665e-02,  1.21095464e-01, -6.97784051e-02,\n            7.60413557e-02,  1.13811418e-01,  1.22052923e-01,\n            5.43338358e-02,  2.25526094e-02, -2.80383900e-02,\n           -7.20662847e-02,  3.62703055e-02, -4.09840047e-03,\n            6.70102835e-02, -5.51719889e-02,  1.88966095e-03,\n            5.45503795e-02, -1.03769645e-01, -7.80973211e-02,\n            4.28819209e-02,  7.22432137e-02, -1.29062220e-01,\n            1.73708797e-02, -3.21042463e-02],\n          [ 8.59170705e-02,  8.53161663e-02, -7.79925883e-02,\n           -6.78696558e-02,  5.88715523e-02, -4.80911136e-03,\n            1.33200780e-01,  1.07411757e-01,  1.05666950e-01,\n            1.09992102e-01, -1.17857322e-01, -9.68979895e-02,\n           -7.06594363e-02,  1.40857548e-02, -6.14565909e-02,\n            6.71600252e-02, -1.05399989e-01, -4.25409228e-02,\n            8.58370811e-02, -4.83822301e-02, -1.12001829e-01,\n           -3.73909771e-02, -1.24000035e-01, -1.34858623e-01,\n            7.40453154e-02, -9.65600237e-02, -1.36353523e-01,\n           -1.07766114e-01,  5.74819446e-02,  7.56683797e-02,\n           -1.00342177e-01, -1.02599680e-01]],\n \n         [[-1.23344012e-01,  1.10592276e-01, -1.26690105e-01,\n            4.60019261e-02, -1.42016858e-02,  1.37820378e-01,\n           -7.47772530e-02, -1.01497233e-01,  6.14002347e-03,\n           -5.37275970e-02, -3.68554145e-02,  3.67271155e-02,\n           -4.35746610e-02,  1.18176952e-01,  4.40336913e-02,\n           -1.16218127e-01,  8.96814167e-02,  1.30650595e-01,\n            6.68530315e-02, -6.42375201e-02, -2.59678513e-02,\n           -4.01823297e-02, -9.88810658e-02, -9.91769806e-02,\n            1.11752763e-01,  3.71384323e-02, -4.48384881e-03,\n           -1.02245264e-01, -6.39791787e-02,  1.01716444e-01,\n           -3.80079150e-02,  1.05598867e-01],\n          [ 6.90485686e-02, -4.32915986e-03, -9.17153656e-02,\n           -2.59172097e-02,  8.04592669e-02,  9.51997340e-02,\n           -1.98405981e-02, -1.17096260e-01,  1.06055677e-01,\n           -3.91563550e-02,  3.78896445e-02,  9.08931792e-02,\n           -7.09423795e-02, -7.82656670e-03, -1.18612878e-01,\n            7.01606572e-02,  3.71074080e-02,  7.56066442e-02,\n           -5.07281870e-02, -2.73834839e-02,  5.26136011e-02,\n            8.26120377e-03,  4.77555841e-02,  9.55474079e-02,\n           -4.70829830e-02, -2.07506791e-02, -8.71120393e-02,\n            7.52784312e-03,  1.18732288e-01,  6.56685829e-02,\n           -8.21192563e-02,  1.03589624e-01],\n          [ 1.25049874e-01,  7.68030435e-02,  7.46220648e-02,\n           -1.30113110e-01,  6.62229061e-02, -5.38335517e-02,\n            1.22144818e-04,  1.82117969e-02,  3.34565789e-02,\n            1.63891017e-02, -3.23718935e-02,  6.38916194e-02,\n            4.07830775e-02,  1.25197038e-01, -9.63242948e-02,\n            2.31325626e-02,  1.13576204e-02, -7.90449530e-02,\n           -2.41520554e-02,  2.65787244e-02, -5.54896891e-02,\n            9.96637791e-02,  6.49068654e-02, -2.29028240e-02,\n           -4.21591103e-03,  6.17203563e-02, -5.91172501e-02,\n            3.19008976e-02, -1.35080129e-01, -2.95542181e-02,\n            8.59953463e-02, -5.65084890e-02]],\n \n         [[-3.63878384e-02,  3.31207812e-02, -1.00845061e-01,\n            9.50802565e-02, -2.08805203e-02, -2.76606083e-02,\n            8.77610892e-02, -1.00339383e-01, -1.05964988e-02,\n           -5.19592240e-02, -1.34763002e-01,  8.87622535e-02,\n            1.30254760e-01,  1.29805431e-01,  2.71082371e-02,\n            4.09452021e-02,  4.17003036e-03, -1.31687567e-01,\n            1.09987259e-01,  1.56014264e-02, -4.47087958e-02,\n           -1.05484650e-01, -2.38144174e-02, -1.37680441e-01,\n           -5.35343140e-02, -3.61840278e-02, -1.11268774e-01,\n           -7.40227401e-02, -1.16983071e-01,  5.91297895e-02,\n           -6.75131008e-02,  7.97876716e-02],\n          [-8.52003992e-02, -5.96503466e-02,  9.43759233e-02,\n           -2.22645700e-02,  1.06496766e-01, -2.79903486e-02,\n            5.67677170e-02,  1.50266141e-02, -8.49796757e-02,\n            1.09074548e-01,  4.68967706e-02, -1.33460909e-01,\n           -9.25087780e-02,  9.64826047e-02, -9.88599062e-02,\n           -7.89102316e-02, -8.47018212e-02,  1.10173374e-01,\n            1.06052130e-01, -1.32220984e-03,  1.06853500e-01,\n            1.24620423e-01, -9.68359262e-02,  1.23723283e-01,\n            1.28832087e-01, -7.23562092e-02,  6.09927922e-02,\n           -1.31226674e-01, -2.06976384e-02,  8.35424513e-02,\n            2.88345814e-02,  5.02685755e-02],\n          [ 4.55018878e-03,  2.93423235e-03,  1.82083845e-02,\n            1.06932208e-01, -3.46913263e-02,  1.68564916e-03,\n           -1.22929968e-01, -6.80267811e-02,  1.27185240e-01,\n            1.02773026e-01, -1.32034943e-01, -2.28258893e-02,\n            5.74179143e-02, -3.10615599e-02, -7.47937039e-02,\n           -2.90023014e-02,  8.66586119e-02,  1.31231323e-01,\n            1.13188878e-01, -5.16375452e-02,  1.05061725e-01,\n           -8.30631629e-02,  1.09853998e-01,  1.41622573e-02,\n           -5.64213917e-02,  1.31386086e-01, -7.89805502e-02,\n           -5.18932939e-03,  1.16113350e-01, -1.34378567e-01,\n            1.06818154e-01, -1.33768767e-01]]],\n \n \n        [[[-6.27777874e-02, -3.88158560e-02, -7.17563853e-02,\n            6.78046048e-02,  5.15023023e-02, -2.77410299e-02,\n           -2.46155262e-02,  1.24321029e-01,  1.10579774e-01,\n           -8.83592069e-02, -2.26536393e-03, -1.12546369e-01,\n            1.04133353e-01,  4.95743752e-02,  1.14781305e-01,\n           -4.32160944e-02,  9.21120793e-02,  4.70751822e-02,\n            5.48027456e-03, -2.79679373e-02,  1.06872872e-01,\n           -1.08980075e-01, -4.99117523e-02,  7.92659670e-02,\n            1.04331404e-01,  8.67274851e-02,  1.95408612e-02,\n           -2.88668647e-02,  9.20321792e-02, -2.47574747e-02,\n            1.62188709e-03,  6.29193485e-02],\n          [-2.63423696e-02, -1.12226337e-01,  2.96697766e-02,\n           -3.73010337e-03, -1.21789873e-02,  5.85541576e-02,\n           -5.10468706e-02, -6.24480173e-02, -1.87299252e-02,\n           -6.62457347e-02,  3.30633968e-02, -8.74231234e-02,\n           -1.24350473e-01,  4.90043908e-02,  4.33516055e-02,\n           -2.86372900e-02, -8.75335932e-03,  2.37546265e-02,\n           -1.02976605e-01,  8.72910023e-05, -1.18335232e-01,\n           -1.23059250e-01,  1.14118293e-01, -2.72205994e-02,\n            8.78396630e-02, -5.72392717e-02, -8.68679583e-02,\n           -3.81005034e-02, -8.19249824e-02, -1.22526065e-01,\n            2.04535872e-02,  1.33333877e-01],\n          [-7.07288310e-02, -1.34654537e-01,  9.83370245e-02,\n           -1.01519808e-01, -5.83579093e-02,  4.16095853e-02,\n           -8.79138708e-02, -1.16710365e-02,  1.28697500e-01,\n            1.14631876e-01,  4.92623448e-02,  5.65088242e-02,\n            6.64257258e-02,  8.65046531e-02,  1.20260224e-01,\n            1.23128399e-01, -4.96302173e-02, -1.27011299e-01,\n            8.63815546e-02, -1.52387470e-02,  8.38482082e-02,\n           -5.59402555e-02,  1.40777230e-03, -2.68640816e-02,\n            3.00520062e-02,  9.13773775e-02,  5.23406267e-02,\n           -4.13023457e-02,  2.90342271e-02, -3.39269489e-02,\n            1.21894404e-01,  7.82800466e-02]],\n \n         [[-1.05358630e-01,  1.32931039e-01,  1.19159207e-01,\n           -5.90582564e-02,  2.25591362e-02,  8.45279545e-02,\n            1.21474430e-01, -1.07930243e-01,  7.11949915e-02,\n            7.63647258e-03, -4.79002744e-02,  7.18976110e-02,\n            7.86770731e-02, -5.48927262e-02, -9.49563980e-02,\n           -3.49620059e-02, -4.60589826e-02, -1.78189501e-02,\n            1.13051876e-01,  1.07031614e-01,  2.76998580e-02,\n           -3.24718952e-02,  7.52869397e-02, -5.57634234e-02,\n           -5.23211434e-02, -9.09610093e-03, -8.17449540e-02,\n            2.56240219e-02,  1.01761073e-01, -5.53459600e-02,\n            5.73244691e-02, -2.83052474e-02],\n          [-1.06263444e-01,  2.70843059e-02,  1.06745765e-01,\n            4.36436683e-02,  7.66357183e-02,  3.70341241e-02,\n           -1.14201754e-02,  1.13905564e-01,  1.15002498e-01,\n           -1.30806938e-01,  1.05196312e-01,  6.74403757e-02,\n           -3.56329978e-03,  1.15069404e-01,  2.03305781e-02,\n           -1.67265460e-02, -1.27890110e-01, -5.93330413e-02,\n           -1.87475607e-02, -7.03802705e-02,  6.13111854e-02,\n            2.36692727e-02,  1.23560831e-01,  8.45448375e-02,\n           -7.81981423e-02, -9.39016342e-02,  8.42762291e-02,\n            3.22109610e-02,  8.32804292e-02,  1.28635123e-01,\n            7.63942599e-02, -1.21634766e-01],\n          [ 4.44242060e-02, -3.65185365e-02, -1.14916012e-01,\n            2.36633271e-02, -6.03418723e-02, -1.07598066e-01,\n           -1.23680264e-01, -9.93958116e-03, -6.81130588e-03,\n            1.09372094e-01, -6.05883300e-02, -1.33425415e-01,\n           -1.26656353e-01, -1.03272028e-01,  2.30332613e-02,\n           -8.43114704e-02,  7.67759979e-02,  6.22301847e-02,\n            8.34335089e-02, -2.24537402e-02,  8.43828470e-02,\n           -6.44086897e-02,  8.05418938e-02,  3.14792246e-02,\n            4.59583253e-02,  1.36731967e-01, -3.29890624e-02,\n           -3.62323672e-02, -1.36467859e-01, -2.54049450e-02,\n           -8.73396769e-02,  3.72146070e-02]],\n \n         [[ 7.76910782e-02,  1.25746861e-01, -1.65291131e-03,\n            2.58917361e-02, -5.56208119e-02,  7.31602758e-02,\n           -1.09220892e-02,  3.86004001e-02,  3.14004719e-02,\n           -1.17931060e-01,  1.12480238e-01,  8.84469599e-02,\n            1.14590123e-01, -9.66122150e-02,  6.17966652e-02,\n            1.16848946e-02, -1.35563537e-02,  5.18256575e-02,\n            1.37646332e-01,  7.59155601e-02, -4.62762862e-02,\n            1.94448233e-03,  8.97979438e-02,  8.35921019e-02,\n           -4.41353023e-03,  6.43056333e-02, -2.18892545e-02,\n           -1.34020954e-01, -7.98188373e-02,  1.11458302e-01,\n            1.24721900e-01,  4.66668308e-02],\n          [ 3.19376588e-04, -6.80736676e-02,  6.10003322e-02,\n           -1.27752766e-01, -4.60134745e-02, -2.70339027e-02,\n            2.65358537e-02,  7.98852444e-02,  1.03448227e-01,\n           -2.09648907e-02,  1.01346165e-01,  5.20366132e-02,\n           -1.23373687e-01, -7.48828426e-02, -8.22526142e-02,\n            2.57370919e-02,  1.07228875e-01,  5.23069948e-02,\n           -1.24854676e-01,  5.02546877e-02, -6.55874386e-02,\n           -8.11625719e-02,  5.31235337e-02, -7.14244097e-02,\n           -6.59043118e-02, -1.00379623e-01, -1.25752285e-01,\n           -6.85688853e-03,  1.32800654e-01,  1.25062302e-01,\n            1.30059794e-01,  1.17343619e-01],\n          [ 4.10885364e-02, -3.22908163e-03, -6.96983486e-02,\n           -8.34394991e-03,  1.14825264e-01, -5.71912304e-02,\n           -5.13462052e-02, -3.24429348e-02,  1.07272968e-01,\n           -1.22476771e-01, -6.97678775e-02,  8.99784565e-02,\n            9.65448171e-02,  2.35503614e-02,  8.98290277e-02,\n           -4.66361642e-02, -6.55890852e-02, -1.34124279e-01,\n           -4.21588272e-02, -2.29927823e-02, -1.30008206e-01,\n            1.91707164e-02, -8.84798989e-02, -8.93034041e-02,\n           -1.03914924e-01, -6.35398999e-02,  4.93064374e-02,\n           -6.79797605e-02, -1.10448256e-01, -1.93743333e-02,\n           -4.47051078e-02,  1.04388133e-01]]],\n \n \n        [[[ 1.12476483e-01,  8.45640898e-02, -4.43831682e-02,\n           -1.25128210e-01,  2.02946216e-02,  8.94245654e-02,\n           -1.16636485e-01, -9.31248218e-02, -1.04251638e-01,\n            2.93619931e-02, -6.17649779e-02, -8.40691328e-02,\n           -5.53320721e-02,  6.95211887e-02,  8.70718360e-02,\n           -9.03833508e-02,  5.59969544e-02,  1.69232786e-02,\n           -2.63419747e-02, -2.93588936e-02, -4.67606783e-02,\n           -1.21778823e-01, -1.15596130e-01, -7.52111673e-02,\n            7.32223988e-02,  5.78766465e-02,  2.99877673e-02,\n           -8.54666978e-02,  1.51685029e-02,  4.37712967e-02,\n            8.43524784e-02,  8.83743167e-03],\n          [-8.28847513e-02, -3.19167897e-02, -1.05666749e-01,\n            7.89275169e-02,  3.34243327e-02, -9.72548723e-02,\n            8.82281363e-03, -1.92953646e-03,  9.82740670e-02,\n            1.29281029e-01, -1.05820216e-01, -9.09448043e-02,\n            5.19645810e-02,  1.10457838e-02, -7.57335648e-02,\n           -1.08998500e-01, -1.30907863e-01,  1.70689821e-02,\n            9.24910009e-02, -7.41496235e-02,  9.28456485e-02,\n            7.93185830e-02,  8.15025866e-02,  1.34726778e-01,\n            1.25976935e-01,  1.27931967e-01, -3.76550704e-02,\n           -1.10723406e-01,  1.32152721e-01,  3.89140844e-02,\n           -1.32247016e-01, -1.35256410e-01],\n          [-5.45906574e-02, -1.21132731e-02, -4.93207797e-02,\n            9.99348462e-02, -6.89354464e-02,  4.77149189e-02,\n           -7.40964785e-02, -5.59155419e-02, -1.17067866e-01,\n            8.06259364e-02,  3.24625820e-02, -1.01477787e-01,\n           -1.53865889e-02, -1.19175851e-01, -7.73135275e-02,\n            1.42215639e-02, -9.13354754e-03, -1.10596098e-01,\n           -8.85902345e-03, -1.26121178e-01,  9.92172211e-02,\n           -3.23474407e-03,  2.47025937e-02,  1.65365785e-02,\n            4.47372198e-02, -8.79192352e-03, -2.91009545e-02,\n           -7.02880993e-02,  4.70744520e-02, -3.89271975e-03,\n            3.32411826e-02,  2.96396017e-02]],\n \n         [[ 2.48519182e-02,  8.92967284e-02,  7.18311071e-02,\n            6.00738376e-02,  4.50075120e-02,  2.27281302e-02,\n           -1.28294677e-01, -1.08711533e-01, -2.94749141e-02,\n            8.83512348e-02, -4.16955277e-02, -5.54543808e-02,\n           -9.53604132e-02, -7.50604942e-02, -9.60951746e-02,\n            6.27129078e-02, -1.04533836e-01, -5.53124249e-02,\n            7.25203305e-02,  3.97098213e-02,  4.68656421e-02,\n            8.79799724e-02,  4.45027798e-02,  6.41776621e-02,\n            1.10592321e-01,  1.26258239e-01, -8.58574137e-02,\n            7.09661692e-02,  2.59542912e-02,  6.35410547e-02,\n            1.26174822e-01, -6.79807812e-02],\n          [ 4.65433747e-02,  4.27428931e-02, -6.71310425e-02,\n           -4.62852046e-02, -3.91339809e-02,  1.29034594e-01,\n            5.22625446e-03, -1.14343666e-01, -1.20907702e-01,\n           -6.61821291e-02,  1.19240597e-01, -2.86344290e-02,\n           -4.37512323e-02,  2.11118162e-02,  2.96441168e-02,\n            8.71522129e-02,  1.92140192e-02, -1.06901899e-01,\n           -8.63804668e-02,  1.32897153e-01, -7.70553872e-02,\n           -8.66223201e-02,  8.48347247e-02, -1.13866910e-01,\n            2.48165429e-03, -2.12952197e-02, -5.89327216e-02,\n           -1.95423141e-02, -1.05452731e-01,  2.84362733e-02,\n           -1.55891851e-02, -3.36783528e-02],\n          [ 1.08922496e-01,  1.36044666e-01, -2.26940438e-02,\n           -2.89927945e-02, -8.30392092e-02, -6.20057732e-02,\n            6.29904866e-02,  5.47420532e-02, -2.94245407e-02,\n            1.16259202e-01, -2.01207474e-02,  8.49958360e-02,\n            1.07727483e-01, -4.71926853e-02, -7.36122876e-02,\n           -8.28613564e-02,  8.17338377e-02, -7.79339522e-02,\n           -1.21245235e-01,  9.98558104e-03,  3.59134525e-02,\n            5.10727912e-02, -8.21358711e-02,  8.35901350e-02,\n           -7.22533464e-02,  1.00377455e-01, -9.61583853e-02,\n           -1.51593462e-02, -9.31805596e-02,  3.30817848e-02,\n           -1.78955197e-02, -5.09643406e-02]],\n \n         [[ 1.11128137e-01,  7.34876096e-02,  1.06425673e-01,\n            2.75329947e-02,  6.08548969e-02, -3.93525660e-02,\n            7.52291977e-02,  1.66960657e-02,  6.50558621e-02,\n           -1.19564556e-01, -9.48327184e-02, -3.21892053e-02,\n           -5.20762801e-03, -8.05807188e-02, -9.28784311e-02,\n           -3.24737728e-02, -2.72257626e-03,  1.15518346e-01,\n            6.87417090e-02, -1.14349753e-01, -9.56271365e-02,\n            1.04746923e-01, -1.32394567e-01, -3.25533673e-02,\n            1.37759641e-01,  4.77904677e-02, -2.44598091e-03,\n           -1.33758798e-01, -6.65830746e-02, -1.26309395e-02,\n           -8.69963467e-02, -9.73803103e-02],\n          [-2.52569690e-02, -3.81002426e-02, -1.40250847e-02,\n           -2.98371315e-02,  6.72687590e-03, -1.16076343e-01,\n            7.18563497e-02,  1.02671385e-01, -2.27678493e-02,\n            1.35474652e-02,  8.11172724e-02, -4.60330173e-02,\n            3.30147892e-02, -1.12141147e-01, -7.46641532e-02,\n           -1.28828004e-01,  3.31474990e-02,  1.65827572e-03,\n           -1.29649937e-01, -9.77799743e-02, -6.09566271e-03,\n           -8.23378712e-02, -1.29066706e-01, -1.33509517e-01,\n            3.41619849e-02,  9.83388722e-03, -5.12398258e-02,\n            1.14522085e-01,  1.21263668e-01,  5.03791571e-02,\n            4.35869992e-02, -1.21444806e-01],\n          [-4.86757085e-02,  2.18948722e-03,  7.02685863e-02,\n           -1.03153378e-01, -1.37648001e-01, -1.33275568e-01,\n           -7.55397826e-02, -1.06614836e-01,  2.95281559e-02,\n            2.31261551e-03, -3.62849459e-02,  6.00769967e-02,\n           -1.23717517e-01, -1.10931925e-01, -6.88581541e-02,\n            1.16430923e-01,  8.13533217e-02,  1.28487155e-01,\n           -8.55210572e-02, -3.27128246e-02, -1.26589522e-01,\n            2.72931606e-02,  2.20165700e-02, -5.97417355e-03,\n           -1.34926736e-01, -3.04612443e-02, -4.16431427e-02,\n           -1.95460618e-02,  2.92580724e-02,  5.63992411e-02,\n            1.00025922e-01,  9.49269533e-02]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_94/beta:0' shape=(32,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_94/moving_mean:0' shape=(32,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_94/moving_variance:0' shape=(32,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n       dtype=float32)>,\n <tf.Variable 'conv2d_95/kernel:0' shape=(3, 3, 32, 32) dtype=float32, numpy=\n array([[[[ 0.02083421,  0.01950035,  0.0829467 , ...,  0.02432963,\n            0.04799059, -0.0536811 ],\n          [-0.03422876, -0.09138315,  0.01848956, ...,  0.02078024,\n           -0.09588066, -0.08970787],\n          [ 0.03006738,  0.07499245, -0.09445447, ..., -0.08431354,\n           -0.00696138, -0.09916043],\n          ...,\n          [-0.07129398,  0.09266348, -0.04314954, ..., -0.03487143,\n           -0.0694112 , -0.08552272],\n          [ 0.032337  ,  0.08649652,  0.04192856, ..., -0.09293159,\n           -0.00413538, -0.02413961],\n          [-0.04059747,  0.06520286,  0.066493  , ...,  0.09215014,\n            0.00456601,  0.02361743]],\n \n         [[ 0.06694601, -0.09623883, -0.08527856, ..., -0.08006153,\n            0.01785144,  0.10062255],\n          [ 0.00616302, -0.04605448, -0.03501023, ..., -0.07686732,\n            0.09091783, -0.07761329],\n          [-0.00143614,  0.0062196 , -0.0190022 , ...,  0.01195381,\n           -0.0427302 ,  0.083187  ],\n          ...,\n          [-0.05167877, -0.05092222, -0.05372315, ...,  0.06723686,\n            0.024445  ,  0.09112476],\n          [ 0.09264854, -0.02268875, -0.04535223, ...,  0.02555679,\n           -0.01779294,  0.04757717],\n          [-0.04776702, -0.06798498, -0.04867315, ..., -0.06749646,\n            0.09514111,  0.09454244]],\n \n         [[-0.05303259, -0.0487907 ,  0.01342072, ..., -0.07946911,\n           -0.10205164,  0.06198099],\n          [ 0.03228582,  0.02557851,  0.0683198 , ..., -0.08928884,\n           -0.00904758,  0.01931763],\n          [-0.094346  ,  0.06533174,  0.0494936 , ...,  0.09767355,\n            0.01757574, -0.05994172],\n          ...,\n          [ 0.09221782, -0.04676216,  0.0479811 , ..., -0.06636362,\n            0.09319559, -0.00192663],\n          [ 0.03493455, -0.08688265,  0.04193026, ..., -0.00019263,\n           -0.01693426,  0.04417612],\n          [-0.02595389,  0.06082158,  0.01608899, ...,  0.07945332,\n           -0.0918726 ,  0.04601449]]],\n \n \n        [[[-0.09134556,  0.00369392, -0.02694049, ..., -0.03900553,\n           -0.03107728, -0.0786707 ],\n          [ 0.04315962, -0.09561075, -0.03342471, ...,  0.00193889,\n           -0.03646705,  0.07838614],\n          [-0.02770515,  0.08699887,  0.00744215, ..., -0.08653074,\n           -0.00015503,  0.08842795],\n          ...,\n          [-0.02378529, -0.07634564,  0.00324227, ..., -0.05679601,\n            0.08820675, -0.06650802],\n          [ 0.01767327,  0.08244991,  0.09200434, ...,  0.07388809,\n           -0.06739403, -0.04961332],\n          [ 0.04931404,  0.05801763,  0.02718127, ..., -0.09943528,\n            0.08340931, -0.08493967]],\n \n         [[ 0.09038649, -0.01925176,  0.01520194, ...,  0.04594125,\n           -0.07966105,  0.01284541],\n          [ 0.09990503, -0.098844  ,  0.09394374, ..., -0.05634533,\n            0.09913848, -0.0268278 ],\n          [-0.09720557,  0.08297341,  0.0211385 , ..., -0.04507108,\n            0.04221269, -0.07502878],\n          ...,\n          [-0.09238014,  0.09966314,  0.05532986, ..., -0.01673152,\n            0.08756165,  0.1000056 ],\n          [ 0.05552644, -0.08015704, -0.0498924 , ...,  0.04170462,\n           -0.01674926,  0.09397766],\n          [ 0.07458477,  0.01813602, -0.09306666, ..., -0.00067832,\n            0.04973263,  0.07983701]],\n \n         [[ 0.04452881,  0.00533757,  0.0570289 , ..., -0.02629137,\n           -0.02716289,  0.09560309],\n          [-0.05826174,  0.02200223,  0.07375239, ...,  0.06113692,\n           -0.06647738, -0.03017042],\n          [-0.02424733,  0.06907046,  0.04278277, ..., -0.03397936,\n           -0.07532297,  0.06534216],\n          ...,\n          [-0.00054536,  0.07362857,  0.08591174, ..., -0.08483151,\n           -0.08164766,  0.05547486],\n          [ 0.05826727, -0.0728071 , -0.0903638 , ..., -0.02387372,\n           -0.04733768, -0.05995313],\n          [ 0.04288258,  0.08239399, -0.08938617, ..., -0.00918879,\n            0.09054379,  0.0878156 ]]],\n \n \n        [[[ 0.02928624,  0.05655757, -0.08951285, ..., -0.0474828 ,\n            0.0374829 ,  0.09780736],\n          [ 0.06484205, -0.03127789, -0.03586984, ..., -0.00630724,\n           -0.012425  , -0.06627454],\n          [-0.03490116,  0.05963674,  0.07438703, ..., -0.04161407,\n           -0.05114964, -0.08605558],\n          ...,\n          [-0.07196777, -0.04394583,  0.06197311, ..., -0.02913401,\n            0.00197391,  0.05300622],\n          [-0.00164393,  0.09037098, -0.07635327, ...,  0.09334952,\n            0.07687072,  0.01721945],\n          [ 0.04398887,  0.05863777,  0.084139  , ...,  0.06811619,\n            0.05638047, -0.02059582]],\n \n         [[-0.05436845, -0.06187448, -0.08409807, ...,  0.0536609 ,\n           -0.0892754 ,  0.07315534],\n          [-0.07457718, -0.04875595,  0.01678077, ...,  0.08969988,\n            0.02081134,  0.0938182 ],\n          [-0.07672881,  0.03900409, -0.09031773, ...,  0.03545381,\n            0.03212199,  0.06693627],\n          ...,\n          [-0.08466684, -0.08827143, -0.01097876, ...,  0.08351848,\n            0.00224323, -0.09408215],\n          [ 0.04470773,  0.01107042, -0.03635317, ...,  0.0567161 ,\n            0.01222058, -0.03565059],\n          [ 0.08592322, -0.00289318, -0.06960888, ...,  0.034648  ,\n           -0.04724577, -0.0672725 ]],\n \n         [[ 0.08850119,  0.00393246, -0.05296852, ...,  0.09284903,\n           -0.08241507, -0.07363226],\n          [-0.00378612, -0.0357834 , -0.03606261, ..., -0.00429603,\n           -0.09910483,  0.00324988],\n          [-0.04150623, -0.09184916, -0.04688271, ..., -0.05102476,\n           -0.09769818, -0.06098383],\n          ...,\n          [-0.08799797,  0.05316821, -0.02420092, ..., -0.00592538,\n            0.09613882,  0.09775943],\n          [-0.00199099,  0.0107821 , -0.06281568, ...,  0.03475399,\n            0.00550757, -0.09105017],\n          [ 0.00375734, -0.09909923, -0.06977944, ..., -0.08051   ,\n           -0.08084217, -0.08293473]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_95/beta:0' shape=(32,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_95/moving_mean:0' shape=(32,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_95/moving_variance:0' shape=(32,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n       dtype=float32)>,\n <tf.Variable 'conv2d_96/kernel:0' shape=(3, 3, 32, 64) dtype=float32, numpy=\n array([[[[ 4.8570193e-02, -2.2967320e-02,  6.5159984e-02, ...,\n            6.7309044e-02, -6.9534361e-02, -8.2814895e-02],\n          [-4.8091691e-02, -4.7706425e-02,  1.8315576e-02, ...,\n            4.8732184e-02, -6.8863712e-02, -3.6592506e-02],\n          [ 1.6663447e-03, -5.7234108e-02, -3.9024353e-03, ...,\n            4.0526189e-02,  4.3499030e-02, -7.8949213e-02],\n          ...,\n          [-5.8773201e-02,  1.8663764e-02,  3.0748568e-02, ...,\n            1.8114649e-02, -5.1524103e-02,  4.4239469e-02],\n          [ 3.4539960e-02,  3.7812650e-02,  2.5845625e-02, ...,\n           -7.6984569e-02,  4.6534315e-03,  1.5780926e-02],\n          [ 1.5429035e-03, -5.7862341e-02, -2.0345010e-02, ...,\n           -6.1904274e-02,  3.4779228e-02, -2.2284985e-03]],\n \n         [[ 3.7331045e-02,  6.1528087e-03,  5.6784488e-02, ...,\n            3.5576224e-03,  8.0029972e-02, -7.6378271e-02],\n          [ 6.7505680e-02, -7.8415275e-03,  7.2769530e-02, ...,\n           -4.3147843e-02, -8.2222722e-02, -8.1940018e-02],\n          [ 2.8728008e-02, -1.5314721e-02, -5.7899516e-02, ...,\n            3.2660089e-02, -4.2888980e-02, -2.7401667e-02],\n          ...,\n          [-5.9828520e-02, -7.9273269e-02,  4.2007647e-02, ...,\n            5.3268887e-02,  7.9967953e-02, -3.1441689e-02],\n          [ 2.9352367e-02,  3.3661500e-03,  7.8231096e-03, ...,\n            6.4205326e-02,  6.6688679e-02,  3.8638338e-03],\n          [-7.0579216e-02,  1.1339106e-02, -3.3204928e-03, ...,\n           -3.3445977e-02,  8.2198478e-02,  3.2116987e-02]],\n \n         [[ 7.0852853e-02, -8.3119117e-02,  4.3979414e-02, ...,\n           -2.4097145e-02,  7.1860291e-02, -8.2483135e-02],\n          [-1.9241571e-02,  1.9581541e-03,  5.0909840e-02, ...,\n           -6.1961215e-02,  2.7047060e-02,  1.0900952e-02],\n          [ 7.5794406e-02, -8.7714791e-03, -3.9661866e-02, ...,\n           -3.3095103e-02,  1.8846594e-02, -3.9555393e-02],\n          ...,\n          [-1.7314218e-02, -3.3712029e-02, -4.7082245e-02, ...,\n           -6.1907768e-02,  6.8677790e-02,  4.8105486e-02],\n          [-1.4889859e-02, -6.7463204e-02,  7.5306423e-02, ...,\n            7.3345087e-02,  7.6132044e-03,  4.7027744e-02],\n          [-4.4192672e-02,  2.0862721e-02, -8.0034241e-02, ...,\n            8.7507367e-03, -8.1588827e-02, -5.2376967e-02]]],\n \n \n        [[[-2.8046291e-02,  3.1945467e-02,  1.1360742e-02, ...,\n           -3.0583702e-02, -2.1269917e-02, -2.4361335e-02],\n          [ 6.9890864e-02,  4.1921102e-02, -1.3228692e-02, ...,\n            6.8671532e-02,  6.8692721e-02,  4.6586402e-02],\n          [ 4.5078523e-02,  5.8297001e-02,  6.5447092e-03, ...,\n           -6.5885387e-02,  1.8723167e-02,  1.5712939e-02],\n          ...,\n          [-6.5251470e-02,  5.2656360e-02,  5.3621911e-02, ...,\n            8.1300959e-03,  7.6715536e-02,  6.8857767e-02],\n          [-7.6050960e-02, -2.0865202e-03, -6.6903293e-02, ...,\n            5.6326635e-02, -7.4988566e-02, -2.3843985e-02],\n          [-7.8072354e-02,  3.2809258e-02,  6.9689490e-02, ...,\n           -3.1644702e-03,  6.5394245e-02,  1.7330870e-03]],\n \n         [[ 4.3716110e-02,  6.8073250e-02, -5.1919721e-02, ...,\n            1.8207766e-02, -5.4710232e-02, -7.3830962e-02],\n          [-4.2527936e-02,  2.5111973e-02,  7.9934962e-02, ...,\n           -7.8541100e-02,  4.5401193e-02, -1.6746022e-02],\n          [ 6.9270320e-02, -3.1038743e-02,  2.4328291e-02, ...,\n           -6.4826965e-02,  2.1353878e-02,  2.4773836e-02],\n          ...,\n          [-2.5785606e-02,  3.8682841e-02,  2.4009570e-03, ...,\n           -6.4149819e-02, -7.7171624e-02, -1.2586176e-02],\n          [-7.1253523e-02,  3.3601224e-02, -8.3067417e-02, ...,\n           -8.1295393e-02,  1.3450764e-02,  2.8059758e-02],\n          [ 3.0945741e-02, -8.2969606e-02,  7.6327272e-02, ...,\n           -6.1438262e-02, -1.0859631e-02, -5.1932018e-02]],\n \n         [[ 6.2956177e-02,  4.9708761e-02, -3.5443466e-02, ...,\n           -1.2860395e-02,  3.7875175e-03,  5.3162731e-02],\n          [ 5.2797578e-02, -6.0301702e-02, -6.1050117e-02, ...,\n           -4.7807157e-02,  2.6335917e-02,  7.6436721e-02],\n          [-2.0036556e-02, -6.7797028e-02, -4.0644765e-02, ...,\n           -5.2134693e-02, -1.8993057e-02,  3.0926980e-02],\n          ...,\n          [ 4.5521356e-02,  2.7768411e-02, -2.0046353e-02, ...,\n            7.1288355e-02, -5.1786464e-02,  2.4632834e-02],\n          [-5.4250799e-02,  6.0479857e-02,  2.8608046e-02, ...,\n            2.1393478e-02, -3.4419075e-03,  4.5936532e-02],\n          [ 7.2616361e-02, -6.4156353e-02, -2.9396042e-03, ...,\n           -5.8254503e-02,  3.6696397e-02,  5.7811879e-02]]],\n \n \n        [[[ 1.7982222e-02,  3.4876667e-02, -3.5111032e-02, ...,\n           -6.9739640e-02,  1.4794886e-02, -5.7268798e-02],\n          [ 6.6147663e-02, -1.7788075e-02,  7.1272627e-03, ...,\n           -2.4794102e-02,  3.0126967e-02, -5.8415852e-02],\n          [ 5.3680427e-02, -3.2588027e-02, -6.5486118e-02, ...,\n            1.9485138e-02, -7.5197577e-02,  6.4474858e-02],\n          ...,\n          [ 5.2032091e-02,  4.0027082e-02,  4.4208534e-02, ...,\n           -5.2707456e-02,  5.8100201e-02, -7.9337023e-02],\n          [ 3.1399727e-02, -5.3910732e-02, -5.4245532e-02, ...,\n           -4.8244219e-02, -6.2587067e-02, -1.4338590e-02],\n          [ 7.9608522e-02,  6.8028457e-02,  7.8846730e-02, ...,\n            7.6987468e-02, -1.5324391e-02, -1.5000425e-02]],\n \n         [[ 7.9959176e-02,  3.8077116e-02, -7.8076422e-02, ...,\n           -4.0016871e-02, -9.3194619e-03,  4.9261786e-02],\n          [ 2.8536297e-02, -3.7671488e-02,  5.6433596e-02, ...,\n           -3.3326071e-02,  5.3494133e-02,  9.7499862e-03],\n          [ 6.2772132e-02, -7.6965153e-02,  3.4431674e-02, ...,\n            4.7019325e-02, -3.7610076e-02, -1.6554631e-02],\n          ...,\n          [-7.9012796e-02,  1.4901303e-02,  1.8188596e-02, ...,\n           -1.8610001e-02,  4.0073000e-02,  1.5511490e-02],\n          [ 2.7203165e-02,  5.0348736e-02,  5.5913053e-02, ...,\n           -5.8894157e-02, -5.8683120e-02, -8.4911212e-03],\n          [-4.7492027e-02,  1.9088186e-02, -6.3875020e-02, ...,\n            3.6789551e-03, -1.8686928e-02, -4.5289934e-02]],\n \n         [[-1.5731908e-02,  3.4658872e-02, -4.8582375e-02, ...,\n           -9.0420246e-05,  2.7887940e-02, -7.9344288e-03],\n          [ 7.3378839e-02, -1.9265555e-02, -7.8372836e-02, ...,\n            7.2410248e-02,  4.8254155e-02, -1.2797356e-02],\n          [-5.9837900e-02, -7.5240731e-02,  3.0726515e-02, ...,\n           -6.4411841e-02, -6.6678844e-02, -4.0477276e-02],\n          ...,\n          [-3.2109201e-02, -1.7212488e-02, -7.6128468e-02, ...,\n           -6.1584711e-02, -8.0560051e-02,  6.0335971e-02],\n          [-5.4943562e-02, -6.7324817e-02, -6.8760216e-02, ...,\n            1.1206709e-02, -4.3605804e-02,  4.1016564e-03],\n          [-2.1886528e-02,  1.0124944e-02, -7.4305341e-02, ...,\n           -2.4801813e-02, -7.0816301e-02, -8.1740461e-02]]]],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_96/beta:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_96/moving_mean:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_96/moving_variance:0' shape=(64,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_97/kernel:0' shape=(1, 1, 64, 80) dtype=float32, numpy=\n array([[[[ 0.04880551, -0.08025187, -0.02810563, ..., -0.07071704,\n           -0.09349298, -0.08629348],\n          [ 0.10403121, -0.10275324,  0.0949966 , ..., -0.20058665,\n            0.09482652, -0.15495579],\n          [ 0.11225548,  0.10753182, -0.01352295, ..., -0.14933398,\n           -0.1623963 ,  0.17480749],\n          ...,\n          [ 0.11370683,  0.200075  , -0.05922033, ...,  0.19664589,\n           -0.17039564,  0.0930869 ],\n          [-0.10212968, -0.06329706,  0.19962174, ...,  0.18953633,\n            0.01989652,  0.19127607],\n          [-0.2010902 ,  0.09115785,  0.16133243, ...,  0.15720451,\n           -0.13026723, -0.10894057]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_97/beta:0' shape=(80,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_97/moving_mean:0' shape=(80,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_97/moving_variance:0' shape=(80,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_98/kernel:0' shape=(3, 3, 80, 192) dtype=float32, numpy=\n array([[[[ 2.71424316e-02, -3.92118022e-02,  1.24558918e-02, ...,\n            4.90236692e-02, -4.51402739e-03,  6.87486678e-03],\n          [-2.45394185e-03, -3.37712243e-02,  1.97606049e-02, ...,\n           -2.96809673e-02, -3.40189561e-02, -3.16516384e-02],\n          [-1.70523077e-02, -1.60371959e-02, -2.56446730e-02, ...,\n            2.59104781e-02,  1.69790573e-02, -9.94577631e-03],\n          ...,\n          [ 3.34058367e-02,  4.49239202e-02, -3.77007574e-02, ...,\n           -4.86971438e-03, -2.30639614e-02, -4.57953960e-02],\n          [-1.66902132e-02,  3.14355902e-02, -1.22109465e-02, ...,\n            5.72134554e-03,  4.43972610e-02, -4.22643498e-03],\n          [ 1.71522424e-03, -2.52676122e-02, -2.27615330e-02, ...,\n           -3.79669368e-02,  9.36722755e-03,  2.29102559e-02]],\n \n         [[ 4.56452034e-02,  1.53963603e-02,  3.98028605e-02, ...,\n           -7.21323490e-03,  4.44213785e-02,  4.17470746e-02],\n          [-4.62189503e-02,  4.89638932e-02, -4.47183624e-02, ...,\n            6.42983988e-03, -3.97005863e-02,  2.06910074e-03],\n          [ 2.70299651e-02,  6.93752989e-03,  5.75945899e-03, ...,\n            4.89928983e-02,  4.58219163e-02,  7.97548145e-03],\n          ...,\n          [-3.35671902e-02,  1.44336931e-02, -3.30593809e-02, ...,\n            4.52088565e-03, -3.23869623e-02,  3.54997627e-02],\n          [ 7.44432211e-03, -2.81238053e-02, -1.61033422e-02, ...,\n            3.12580056e-02,  1.90591030e-02, -3.44315730e-02],\n          [ 4.17403840e-02, -4.43517044e-03, -1.32922865e-02, ...,\n            4.44062985e-02,  2.22788379e-03, -2.51727235e-02]],\n \n         [[ 1.14921853e-02,  3.99212874e-02,  7.84216076e-03, ...,\n            4.50324751e-02,  1.55384503e-02,  8.32863152e-05],\n          [ 6.00278378e-04,  1.55310668e-02, -1.77429542e-02, ...,\n           -3.28242779e-03,  3.58163901e-02,  1.56399608e-03],\n          [-1.81998536e-02, -3.60378362e-02, -2.75578275e-02, ...,\n           -2.62099188e-02, -3.42100561e-02,  2.24648528e-02],\n          ...,\n          [-4.18626182e-02, -2.36172732e-02,  3.27857547e-02, ...,\n           -3.62098850e-02, -3.92192155e-02, -4.08066437e-03],\n          [ 1.47617720e-02, -2.93462202e-02,  2.37705745e-02, ...,\n            8.89592618e-03, -1.09451041e-02, -8.72495398e-03],\n          [-4.23602760e-02, -3.50471213e-02,  6.15958497e-03, ...,\n            2.47191750e-02, -1.96954254e-02, -4.85660620e-02]]],\n \n \n        [[[-4.73367646e-02, -4.34301645e-02, -3.25014889e-02, ...,\n           -6.77170232e-03,  7.57910684e-03,  3.87528948e-02],\n          [-1.37496591e-02, -1.69063359e-02,  2.68942602e-02, ...,\n            3.80262770e-02,  3.38046215e-02,  3.24560590e-02],\n          [-7.54824281e-03,  9.25659388e-03,  2.73408107e-02, ...,\n            1.95000432e-02,  4.39770333e-02,  2.37123854e-02],\n          ...,\n          [ 4.02325429e-02,  4.50140126e-02,  4.91313674e-02, ...,\n           -8.03381205e-04, -1.86665282e-02,  1.02907792e-02],\n          [ 8.34922493e-03, -1.13774687e-02,  3.66195627e-02, ...,\n           -2.72303876e-02, -2.44969744e-02,  2.46787928e-02],\n          [-5.33873588e-03,  2.79301964e-02, -9.73008946e-03, ...,\n           -4.28518653e-02,  3.29802372e-02,  2.30450183e-04]],\n \n         [[ 4.53549586e-02, -1.21180639e-02, -2.14317050e-02, ...,\n           -3.46067250e-02,  2.82409899e-02,  1.01681538e-02],\n          [ 4.24956344e-02, -9.58301872e-03, -1.52809359e-02, ...,\n           -3.79557237e-02, -2.33925115e-02,  3.63329798e-03],\n          [-2.92625222e-02, -3.37480567e-02,  4.38677482e-02, ...,\n           -4.81698662e-03, -1.71833858e-03,  1.55377388e-03],\n          ...,\n          [ 2.82404087e-02, -1.51088871e-02,  1.03857629e-02, ...,\n           -1.21171214e-02, -3.53273973e-02, -3.24108526e-02],\n          [ 1.24518201e-02,  8.93165544e-03,  3.29315625e-02, ...,\n            3.16223465e-02,  1.89698897e-02,  3.44780870e-02],\n          [ 3.21821384e-02, -3.30357291e-02,  2.97017060e-02, ...,\n           -2.52585225e-02,  4.17681746e-02, -3.98886055e-02]],\n \n         [[ 3.82438563e-02, -3.01453508e-02,  3.55281122e-02, ...,\n            4.42554317e-02,  2.58793123e-02,  3.15479375e-02],\n          [-7.08882511e-03, -3.16017568e-02,  2.94481404e-02, ...,\n           -3.89793701e-02, -2.20794212e-02,  7.63887912e-03],\n          [-4.92212363e-02, -4.42108139e-02, -2.39454955e-03, ...,\n           -8.85077938e-03,  4.23549972e-02,  1.31917112e-02],\n          ...,\n          [-1.76783167e-02,  9.07671079e-03, -2.07736343e-03, ...,\n           -1.20841525e-02, -5.95472381e-03,  1.77015476e-02],\n          [ 2.13590078e-02,  2.92726867e-02,  6.05825335e-04, ...,\n           -1.72025673e-02, -3.29473913e-02,  3.57786939e-03],\n          [-3.24891210e-02,  1.20482109e-02,  3.75796854e-03, ...,\n           -3.45930569e-02,  4.41819914e-02,  3.94793190e-02]]],\n \n \n        [[[-4.32867184e-02,  3.89734767e-02,  3.81616615e-02, ...,\n            2.10506059e-02,  3.36434506e-02,  1.35308318e-02],\n          [ 2.78011300e-02, -1.47577114e-02, -4.44969870e-02, ...,\n            4.05381583e-02, -2.26488803e-02, -5.59516624e-03],\n          [-1.37616992e-02,  3.04311104e-02,  5.06136566e-03, ...,\n            1.44976936e-02,  1.00142360e-02, -4.68986668e-02],\n          ...,\n          [-4.08685394e-02, -8.94075632e-03, -1.86957531e-02, ...,\n            2.26140730e-02,  3.03260423e-02,  2.89627872e-02],\n          [ 3.63612510e-02, -3.66157591e-02,  8.17362592e-03, ...,\n           -2.65253708e-03,  4.79577854e-03,  2.91831903e-02],\n          [ 4.72229309e-02, -3.79793309e-02, -1.10220872e-02, ...,\n           -1.81810148e-02, -4.26758528e-02, -2.40608826e-02]],\n \n         [[-2.48967819e-02,  3.96896526e-03,  6.30395487e-03, ...,\n           -4.15378921e-02, -2.51289327e-02, -4.18037772e-02],\n          [-3.78405340e-02,  1.37288012e-02,  2.49474756e-02, ...,\n           -2.56420877e-02,  2.72703059e-02,  3.73914950e-02],\n          [-3.77057977e-02, -4.70942259e-02, -6.45522028e-04, ...,\n            1.91666298e-02,  9.44500044e-03, -1.19731650e-02],\n          ...,\n          [-8.50559771e-03,  1.33886524e-02,  3.81024741e-02, ...,\n            1.69165470e-02, -4.59020734e-02, -4.47965264e-02],\n          [-4.91874553e-02,  2.25859545e-02, -3.35506424e-02, ...,\n            3.73830684e-02, -2.74227019e-02,  1.82690211e-02],\n          [ 2.47960351e-02,  4.83506434e-02, -3.59825976e-02, ...,\n            4.04497646e-02,  1.66100673e-02,  2.22830065e-02]],\n \n         [[-1.87416747e-03,  2.32972242e-02,  3.80281024e-02, ...,\n            4.20668758e-02, -1.93115640e-02, -4.51714993e-02],\n          [-3.24131660e-02,  1.78763084e-02,  2.72929259e-02, ...,\n            4.35616709e-02, -4.29497994e-02, -2.00525988e-02],\n          [ 3.29431631e-02,  3.36504318e-02,  1.65679194e-02, ...,\n           -5.70498407e-04, -3.91422212e-02,  4.85921316e-02],\n          ...,\n          [ 2.16554068e-02,  9.19165090e-03,  3.64318155e-02, ...,\n           -2.15076022e-02, -4.03884090e-02,  1.91634782e-02],\n          [-1.26603283e-02,  2.97009759e-02, -4.07016873e-02, ...,\n            1.60196833e-02, -4.77981269e-02,  1.06446482e-02],\n          [ 2.07551681e-02,  2.92842649e-02, -3.91344354e-03, ...,\n           -1.82838831e-02,  1.09598599e-02, -3.12997326e-02]]]],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_98/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_98/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_98/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_102/kernel:0' shape=(1, 1, 192, 64) dtype=float32, numpy=\n array([[[[-0.06355838,  0.07758714,  0.09625526, ...,  0.11843015,\n            0.06698339, -0.04933139],\n          [-0.09487092,  0.11271678, -0.09888656, ...,  0.14429455,\n           -0.05732918, -0.09696592],\n          [ 0.10419516, -0.07692415, -0.08565421, ..., -0.04594972,\n           -0.06714533, -0.04990339],\n          ...,\n          [-0.1356459 , -0.1513803 ,  0.10842438, ...,  0.00549044,\n           -0.12193063, -0.01928969],\n          [ 0.12619762,  0.04437615, -0.0559449 , ..., -0.13939373,\n           -0.1511723 , -0.14982754],\n          [-0.03899934,  0.01901254,  0.10373728, ...,  0.00321797,\n            0.13137777,  0.11251546]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_102/beta:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_102/moving_mean:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_102/moving_variance:0' shape=(64,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_100/kernel:0' shape=(1, 1, 192, 48) dtype=float32, numpy=\n array([[[[ 0.14021893,  0.11747988, -0.07131988, ..., -0.13544446,\n           -0.05364705,  0.02967429],\n          [-0.08956619,  0.10188319, -0.1460269 , ...,  0.13139726,\n           -0.0273772 , -0.08501059],\n          [-0.00242461,  0.11514591, -0.05969185, ..., -0.03802887,\n            0.07053626,  0.11812969],\n          ...,\n          [ 0.03830443, -0.10787678, -0.0425084 , ..., -0.09019197,\n            0.06364651, -0.01923418],\n          [ 0.1343896 , -0.15309355, -0.0093596 , ..., -0.12744683,\n           -0.08940164, -0.10251555],\n          [-0.11541533,  0.00178862,  0.15745749, ...,  0.11638315,\n            0.00338766, -0.10161059]]]], dtype=float32)>,\n <tf.Variable 'conv2d_103/kernel:0' shape=(3, 3, 64, 96) dtype=float32, numpy=\n array([[[[ 5.94964921e-02,  3.48711014e-02, -1.99547298e-02, ...,\n           -3.17953452e-02, -2.84522213e-02, -3.40339057e-02],\n          [-5.90561144e-02,  5.64459637e-02, -2.00432539e-03, ...,\n            4.16685194e-02, -5.93030602e-02, -2.98245177e-02],\n          [-2.37440504e-02, -4.82527465e-02,  4.11378294e-02, ...,\n           -2.54155248e-02, -3.25450897e-02,  1.48927942e-02],\n          ...,\n          [-4.16873246e-02,  6.45222291e-02,  1.40324235e-04, ...,\n            4.61925343e-02,  6.35837242e-02,  1.83642060e-02],\n          [-5.12879305e-02, -3.45727056e-03, -1.05976984e-02, ...,\n           -2.01611705e-02, -3.20879817e-02, -1.42763369e-02],\n          [-6.44955337e-02, -4.84543815e-02,  3.51124406e-02, ...,\n           -4.41675410e-02,  4.16482165e-02, -8.80604237e-03]],\n \n         [[-7.26692006e-03, -1.60502791e-02,  3.82795632e-02, ...,\n            2.35977024e-03, -1.42899156e-03, -2.93441117e-04],\n          [-6.38832003e-02,  4.02185172e-02, -5.60887493e-02, ...,\n            4.78653386e-02,  5.44523150e-02, -8.57948884e-03],\n          [-2.35937834e-02, -3.19791920e-02, -4.24216837e-02, ...,\n            4.66775447e-02, -4.61550467e-02,  4.45468724e-03],\n          ...,\n          [ 5.84905371e-02, -8.07979703e-03,  1.68569088e-02, ...,\n            5.75366914e-02, -4.85740602e-03, -1.48200989e-03],\n          [ 4.52207103e-02, -5.25799394e-02, -2.56903730e-02, ...,\n            6.13877997e-02, -2.17464156e-02, -2.31721178e-02],\n          [ 1.20543465e-02,  3.97831723e-02, -4.78191040e-02, ...,\n           -4.69437465e-02,  4.44076359e-02, -4.39534336e-03]],\n \n         [[-3.09296176e-02,  3.98291275e-02, -2.25876085e-02, ...,\n            8.84160399e-05,  4.56587523e-02,  2.98841372e-02],\n          [-1.27893202e-02,  2.46826485e-02, -2.40862891e-02, ...,\n           -2.99225226e-02,  4.58488166e-02,  4.68967631e-02],\n          [ 2.41932645e-02,  2.85881311e-02,  3.76186669e-02, ...,\n            9.38010216e-03,  2.79918164e-02, -2.73122191e-02],\n          ...,\n          [ 2.52465457e-02,  5.19268885e-02, -6.25825301e-02, ...,\n           -5.94166666e-03, -1.16209090e-02, -2.35559717e-02],\n          [ 2.03780457e-02, -3.04025039e-03,  4.39722091e-03, ...,\n           -4.86500934e-02, -4.35027257e-02, -5.32844886e-02],\n          [-2.35308073e-02,  2.07011700e-02,  3.38375494e-02, ...,\n           -3.75206470e-02, -2.25136913e-02,  1.26727596e-02]]],\n \n \n        [[[ 5.83512411e-02, -7.07907230e-03, -2.18950510e-02, ...,\n            3.94163653e-02,  3.91764194e-03, -4.59810346e-02],\n          [ 3.94227579e-02, -1.78081840e-02, -6.30781427e-02, ...,\n           -2.61183828e-02, -3.80601808e-02,  1.31356716e-02],\n          [-1.23023875e-02,  6.02514297e-02,  6.16275147e-02, ...,\n           -3.45977917e-02, -6.33010939e-02, -4.29758430e-02],\n          ...,\n          [-2.76725404e-02, -1.13592967e-02,  2.10989490e-02, ...,\n            4.98432666e-03,  1.27973408e-02,  2.73842588e-02],\n          [-5.73953651e-02,  5.33701628e-02,  5.64051643e-02, ...,\n            2.13942006e-02, -1.25663243e-02,  5.45030087e-02],\n          [ 3.36391106e-02, -5.87003939e-02, -4.33125123e-02, ...,\n            2.27899551e-02, -9.79900360e-04, -4.84978259e-02]],\n \n         [[ 5.10543436e-02,  1.36664063e-02, -3.54298726e-02, ...,\n           -1.32535733e-02, -5.68415597e-02,  4.97403741e-02],\n          [-3.78200561e-02, -4.29339334e-02, -3.49283479e-02, ...,\n            5.88126630e-02,  5.06588742e-02, -4.86428663e-03],\n          [ 3.93369272e-02,  1.48146451e-02,  5.93717098e-02, ...,\n            2.62228772e-02,  5.38221151e-02,  1.61976367e-02],\n          ...,\n          [-5.89242391e-02,  3.19620445e-02, -2.80244760e-02, ...,\n           -4.01759669e-02, -1.99021585e-02,  3.33061367e-02],\n          [-3.36856022e-02, -4.13515642e-02, -3.06017697e-02, ...,\n           -3.82694080e-02,  4.81310561e-02, -2.78606974e-02],\n          [-2.66750008e-02, -3.27392817e-02,  2.32109576e-02, ...,\n            5.91260940e-03,  7.43713230e-03, -2.29175240e-02]],\n \n         [[-1.87947825e-02,  3.14138010e-02,  5.85095435e-02, ...,\n            5.36463484e-02,  4.66595441e-02,  3.53912935e-02],\n          [ 5.29954210e-02, -2.62964740e-02, -2.42595486e-02, ...,\n            9.73112881e-03,  5.14950007e-02,  5.20529300e-02],\n          [ 1.35098100e-02, -5.07824980e-02,  3.48568484e-02, ...,\n           -2.14933604e-02,  2.11077556e-02, -1.64917968e-02],\n          ...,\n          [-6.30874708e-02, -4.70755622e-02,  3.80216911e-02, ...,\n           -3.42235081e-02, -1.52788907e-02, -6.41670823e-03],\n          [-1.71220899e-02,  4.75919694e-02, -5.57896644e-02, ...,\n           -4.32106592e-02,  4.56853136e-02, -2.88406163e-02],\n          [ 1.15065128e-02, -8.98652151e-03,  3.90470549e-02, ...,\n           -1.47579461e-02,  1.07306689e-02,  2.83550844e-02]]],\n \n \n        [[[-3.48577425e-02,  3.63845527e-02, -2.18061730e-03, ...,\n            3.50721180e-04, -5.85389994e-02,  2.05617398e-03],\n          [ 2.84100696e-02,  5.46724200e-02, -2.91192643e-02, ...,\n           -5.98903224e-02,  6.43763021e-02, -4.52164933e-02],\n          [ 3.02683339e-02,  5.59647381e-03, -5.06576411e-02, ...,\n            2.95124426e-02,  1.23745352e-02,  4.63163033e-02],\n          ...,\n          [-4.61270213e-02,  1.62426382e-02, -2.07281634e-02, ...,\n           -3.69765982e-02,  6.04999810e-03, -3.19938585e-02],\n          [ 3.29404697e-02,  2.49312371e-02, -2.14232281e-02, ...,\n           -3.64301503e-02, -6.25187680e-02,  4.48163599e-02],\n          [ 1.27136186e-02,  3.96756753e-02,  3.93993482e-02, ...,\n            3.56409326e-02,  9.30728763e-03, -5.21056093e-02]],\n \n         [[-5.05656078e-02, -1.15902983e-02,  2.81729400e-02, ...,\n           -4.03244011e-02,  6.13127723e-02, -4.64307405e-02],\n          [ 2.84329057e-03, -6.18792139e-02,  4.36253399e-02, ...,\n           -5.20894974e-02,  7.36270845e-03,  1.71280429e-02],\n          [-5.38712889e-02, -2.10843608e-02, -2.90204138e-02, ...,\n           -5.37979975e-03,  3.36410627e-02, -2.63192356e-02],\n          ...,\n          [-1.98645741e-02, -1.49367750e-03, -5.20630702e-02, ...,\n            3.33901197e-02,  5.51106930e-02, -5.36498427e-02],\n          [ 4.50253114e-02, -5.44291548e-02,  3.80009487e-02, ...,\n            4.10494953e-03,  1.05371401e-02,  4.39120829e-02],\n          [ 5.64875603e-02,  1.30441934e-02, -1.38777830e-02, ...,\n           -6.60547987e-03, -4.00400572e-02,  2.57101655e-03]],\n \n         [[-3.69773991e-02,  4.20082957e-02, -5.70235774e-03, ...,\n           -2.77696513e-02,  3.38135213e-02,  5.87444752e-03],\n          [-4.23439518e-02,  2.18629763e-02,  5.57441562e-02, ...,\n            6.84259087e-03, -3.20390873e-02,  1.52485594e-02],\n          [-9.10319015e-03, -4.51888405e-02,  5.16324341e-02, ...,\n           -5.54906242e-02, -4.24416587e-02,  2.48685256e-02],\n          ...,\n          [-5.70937544e-02, -3.78485098e-02, -5.95268607e-03, ...,\n            1.62977800e-02,  4.15440276e-02, -2.29826979e-02],\n          [-4.92548868e-02,  3.59282866e-02,  5.46620786e-02, ...,\n           -1.44781582e-02,  4.58166227e-02,  1.96560621e-02],\n          [ 6.21237233e-02,  5.98768368e-02,  5.43445423e-02, ...,\n            6.04112670e-02, -5.89463226e-02,  1.07295737e-02]]]],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_100/beta:0' shape=(48,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_100/moving_mean:0' shape=(48,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_100/moving_variance:0' shape=(48,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_103/beta:0' shape=(96,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_103/moving_mean:0' shape=(96,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_103/moving_variance:0' shape=(96,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_99/kernel:0' shape=(1, 1, 192, 64) dtype=float32, numpy=\n array([[[[ 0.00370313,  0.11861272,  0.04742579, ..., -0.08702574,\n           -0.05808794, -0.14978233],\n          [-0.0946563 ,  0.09233035, -0.03886575, ...,  0.11977671,\n            0.01286469,  0.02752969],\n          [ 0.08732657,  0.00698034, -0.12909752, ...,  0.15186514,\n            0.14123489,  0.11114462],\n          ...,\n          [-0.06395142, -0.10552968,  0.01575963, ...,  0.14417566,\n            0.04018092, -0.10743149],\n          [-0.09966089, -0.06401642, -0.07177773, ..., -0.09050421,\n           -0.13046592, -0.02922713],\n          [ 0.03757721, -0.04308178,  0.07884122, ..., -0.00626881,\n           -0.01982777, -0.00726198]]]], dtype=float32)>,\n <tf.Variable 'conv2d_101/kernel:0' shape=(5, 5, 48, 64) dtype=float32, numpy=\n array([[[[ 2.17173509e-02,  4.06589322e-02, -1.25518218e-02, ...,\n           -1.48792267e-02,  1.34094134e-02, -2.93360949e-02],\n          [ 2.39330530e-03,  2.78869085e-02, -3.33207957e-02, ...,\n           -4.56546657e-02,  5.04672155e-03,  3.45044173e-02],\n          [ 2.39423700e-02,  2.22369283e-03, -2.34383922e-02, ...,\n            2.15926506e-02, -5.71309403e-03,  1.22302473e-02],\n          ...,\n          [ 3.80662270e-02, -1.78832784e-02,  9.32057202e-03, ...,\n           -1.17054097e-02, -4.54249829e-02, -3.84394452e-02],\n          [ 1.32181495e-02,  2.35714577e-02,  1.54457614e-02, ...,\n           -2.35740226e-02,  1.84109174e-02, -4.50581238e-02],\n          [ 1.41475201e-02, -2.60753874e-02, -3.24523449e-03, ...,\n           -4.40099873e-02,  4.59420718e-02,  4.13340218e-02]],\n \n         [[-2.43082680e-02, -1.02542266e-02, -9.15589184e-03, ...,\n            4.30453978e-02,  6.76649436e-03, -2.49424428e-02],\n          [ 2.58802958e-02,  2.20186599e-02,  1.05179027e-02, ...,\n            2.40480788e-02,  2.34158225e-02, -8.23091716e-04],\n          [-1.50896311e-02,  2.28207819e-02,  2.92434208e-02, ...,\n           -1.33895129e-02, -1.86710078e-02, -2.53537558e-02],\n          ...,\n          [ 3.29537727e-02,  1.05543248e-02,  4.14812379e-02, ...,\n           -9.53660160e-03,  1.00817531e-03,  5.84667921e-03],\n          [ 2.05395557e-02, -2.56089568e-02, -2.25890242e-02, ...,\n           -3.10626775e-02, -1.63748860e-04,  2.02901177e-02],\n          [ 4.46030982e-02, -3.70892547e-02,  4.36262302e-02, ...,\n            3.11169662e-02,  4.15730961e-02,  6.04795665e-03]],\n \n         [[ 1.00947805e-02, -3.22374478e-02,  1.80406161e-02, ...,\n            4.98256460e-03, -1.39105693e-03, -1.82922296e-02],\n          [-4.46585193e-03, -3.20442319e-02, -2.09640227e-02, ...,\n           -1.51797011e-02, -1.35098472e-02,  1.89827941e-02],\n          [-4.45053428e-02,  2.40548439e-02, -4.41747308e-02, ...,\n            2.62487493e-02,  2.06257068e-02, -2.29267459e-02],\n          ...,\n          [ 4.11748402e-02,  3.84886749e-02, -1.41190737e-03, ...,\n            4.47118022e-02, -4.11934592e-02, -9.83044505e-04],\n          [-4.45235632e-02, -2.20275801e-02,  3.36528681e-02, ...,\n            1.50285661e-04,  2.71506719e-02, -2.72378754e-02],\n          [ 3.53734195e-03,  8.19067284e-03, -3.31773087e-02, ...,\n           -1.47534646e-02, -1.04265623e-02, -2.90096644e-02]],\n \n         [[ 4.39062081e-02,  4.15996425e-02, -2.53208671e-02, ...,\n            6.59874827e-03,  2.47110426e-03,  1.19215734e-02],\n          [-4.56709042e-03, -3.65596600e-02,  2.99984328e-02, ...,\n            1.90868042e-02,  7.96043873e-03, -2.03724932e-02],\n          [-8.50196183e-03, -4.04513665e-02, -3.77926528e-02, ...,\n           -1.64381862e-02, -2.32863054e-03,  4.38698567e-02],\n          ...,\n          [-3.79719324e-02, -2.37305462e-03,  1.64346136e-02, ...,\n           -1.46966726e-02,  3.22646275e-03,  1.89958923e-02],\n          [ 8.72579589e-03,  2.44494714e-02,  2.84807794e-02, ...,\n           -2.90357210e-02,  1.59565583e-02,  2.25962512e-02],\n          [ 4.41971011e-02, -2.14256961e-02,  4.21592109e-02, ...,\n           -1.14406198e-02, -9.27003473e-03, -2.59742811e-02]],\n \n         [[-4.44772765e-02,  2.73983590e-02,  9.18699428e-03, ...,\n            2.83978023e-02,  3.44482325e-02, -3.90006788e-02],\n          [ 2.84503289e-02,  4.49958853e-02,  2.21771114e-02, ...,\n           -6.74067065e-03, -1.34407915e-02,  2.84885131e-02],\n          [-1.01409778e-02,  6.45713881e-03, -1.25689618e-02, ...,\n           -2.69804131e-02, -4.31294404e-02, -2.72985995e-02],\n          ...,\n          [ 1.40999109e-02, -1.43249221e-02, -7.00985268e-03, ...,\n           -3.69811617e-02, -3.05323675e-02,  3.40558328e-02],\n          [ 1.09857246e-02, -4.26787138e-02, -1.23105161e-02, ...,\n           -1.02009960e-02,  4.00247090e-02,  4.25837971e-02],\n          [ 3.44966240e-02,  3.14689986e-02,  4.62841205e-02, ...,\n           -3.78421284e-02,  2.37091072e-02,  4.53244410e-02]]],\n \n \n        [[[-8.19256157e-03, -6.44820929e-03,  8.58458132e-03, ...,\n            4.95284423e-03,  2.19510607e-02,  4.26545627e-02],\n          [ 4.61818986e-02, -1.35646537e-02,  4.16113921e-02, ...,\n            2.71069817e-02, -1.62551925e-03, -4.21397947e-02],\n          [ 3.80483232e-02,  3.67973112e-02, -1.84388962e-02, ...,\n           -7.52355158e-03, -3.62555683e-03,  4.47143428e-02],\n          ...,\n          [-3.26644890e-02,  1.70553140e-02, -4.13836315e-02, ...,\n           -3.52115035e-02, -2.63730120e-02, -4.62370478e-02],\n          [ 1.11726187e-02, -2.30916552e-02, -2.65056826e-02, ...,\n           -4.29286957e-02, -3.28133516e-02,  2.71174796e-02],\n          [-7.78600574e-04, -4.50202450e-02,  3.53360735e-02, ...,\n            9.83829796e-03, -4.49772701e-02,  3.15419175e-02]],\n \n         [[ 2.32750513e-02,  8.41482729e-03,  1.04564615e-02, ...,\n           -2.05678735e-02, -2.70486996e-03, -2.62729973e-02],\n          [-2.90520899e-02,  1.17407292e-02,  3.88954096e-02, ...,\n           -2.00881995e-02,  1.55747347e-02,  3.60481329e-02],\n          [-4.38663997e-02, -4.55763154e-02,  2.02069841e-02, ...,\n           -2.32331995e-02,  1.32665671e-02,  1.38774328e-02],\n          ...,\n          [-2.22043693e-03, -3.13996822e-02,  1.45199411e-02, ...,\n           -4.14718017e-02,  2.22325660e-02, -3.45596671e-03],\n          [-3.83102819e-02, -4.27720733e-02, -3.69488671e-02, ...,\n           -1.26714930e-02, -4.53482568e-02,  2.44135894e-02],\n          [ 4.78759408e-03, -4.36777286e-02,  1.25942789e-02, ...,\n           -1.42295137e-02,  2.57326253e-02,  2.26642974e-02]],\n \n         [[ 2.95059793e-02,  1.33287013e-02, -1.44233033e-02, ...,\n           -9.68135893e-03,  6.71560690e-03,  3.58700566e-02],\n          [ 2.37889253e-02, -4.16053683e-02, -2.55602859e-02, ...,\n           -3.01400479e-02, -4.01586965e-02, -4.01994325e-02],\n          [-4.37046476e-02,  1.20928213e-02,  1.56752467e-02, ...,\n            1.53316185e-02,  2.42579766e-02, -4.17070054e-02],\n          ...,\n          [ 7.01563433e-03,  1.35986358e-02,  4.37346958e-02, ...,\n           -3.35676521e-02,  6.90883398e-03, -2.12602019e-02],\n          [-2.09345669e-02,  2.72380002e-02, -2.97281053e-02, ...,\n            2.80812755e-03,  3.69704999e-02,  3.95754687e-02],\n          [ 3.58302034e-02,  3.67262401e-02, -3.33179012e-02, ...,\n            3.79938297e-02, -3.79465818e-02,  2.71690600e-02]],\n \n         [[ 4.00563218e-02,  1.52157620e-03, -6.14881888e-03, ...,\n            1.82512514e-02, -3.27671655e-02, -3.74552384e-02],\n          [ 2.92733684e-03, -6.42705336e-03, -6.62684813e-03, ...,\n           -5.27723506e-03, -4.85157222e-03, -1.57653820e-02],\n          [ 2.54794545e-02,  2.71870978e-02,  5.82276285e-03, ...,\n            1.74143948e-02, -2.88373940e-02, -8.23788717e-03],\n          ...,\n          [ 2.63107941e-03,  1.92887150e-02, -3.43231745e-02, ...,\n           -2.80615315e-03,  1.72023810e-02,  2.66249813e-02],\n          [ 3.85882594e-02, -2.84185205e-02,  3.31785195e-02, ...,\n            3.80152948e-02, -3.19480821e-02,  4.99410927e-03],\n          [ 4.61710356e-02, -4.53520305e-02, -6.15673140e-03, ...,\n            3.01910453e-02, -1.43025517e-02,  1.91097446e-02]],\n \n         [[-1.61628108e-02,  2.25202776e-02, -3.40718254e-02, ...,\n           -2.85431128e-02,  1.89297386e-02, -2.55417433e-02],\n          [-2.31630616e-02,  1.29213408e-02, -3.24403122e-03, ...,\n            1.47824138e-02,  6.49991632e-03, -4.10640649e-02],\n          [-3.48577239e-02, -4.17029634e-02, -1.89492628e-02, ...,\n            1.00240111e-03,  9.64925438e-03,  2.60038674e-03],\n          ...,\n          [ 3.98674048e-02,  2.04490311e-02, -1.50116906e-02, ...,\n           -1.27330311e-02,  2.62320153e-02, -3.91638987e-02],\n          [-1.24504417e-03,  1.11963674e-02, -2.22372096e-02, ...,\n            2.19628401e-02, -3.86587903e-03,  2.70912461e-02],\n          [ 1.20935813e-02, -4.38287631e-02, -2.57554017e-02, ...,\n           -2.39610765e-02,  2.48306617e-03,  2.40271203e-02]]],\n \n \n        [[[-1.14700645e-02,  1.83699392e-02,  1.46915838e-02, ...,\n           -8.54979455e-03,  4.29380685e-04,  3.43528278e-02],\n          [-3.31884772e-02, -4.13752981e-02, -3.21912169e-02, ...,\n            1.70368664e-02,  1.27903558e-02, -3.08085810e-02],\n          [-3.71384025e-02, -5.03336638e-03, -2.85087228e-02, ...,\n            1.26378872e-02, -3.72869633e-02, -2.53952537e-02],\n          ...,\n          [-2.03286763e-02,  4.28284593e-02, -1.92009322e-02, ...,\n            3.62191238e-02, -6.26429543e-03, -3.59717384e-02],\n          [-6.31894916e-03, -3.66363339e-02, -2.09377222e-02, ...,\n           -3.79145183e-02, -9.64408740e-03,  3.88155840e-02],\n          [ 1.12014785e-02,  4.55463640e-02, -1.30608752e-02, ...,\n            3.93834710e-03,  2.38988735e-02,  4.57669385e-02]],\n \n         [[ 8.18864256e-03, -3.76189016e-02,  1.08119175e-02, ...,\n           -3.87285240e-02,  2.50398628e-02, -9.14646685e-03],\n          [ 1.19224265e-02, -3.50784138e-03,  1.18598267e-02, ...,\n           -2.23193988e-02,  3.77265401e-02, -4.54491302e-02],\n          [ 1.55737847e-02,  1.86353512e-02, -2.09086090e-02, ...,\n            4.32744734e-02,  1.46125816e-02,  6.43456727e-03],\n          ...,\n          [-9.75385681e-03, -2.84668598e-02,  2.22345069e-03, ...,\n           -3.65878604e-02,  1.83741562e-02,  2.71011628e-02],\n          [-1.72994081e-02, -9.92800668e-03,  4.39050309e-02, ...,\n           -1.37601458e-02, -1.84866078e-02,  6.11176714e-03],\n          [ 1.46512426e-02, -4.12361696e-02,  4.39207666e-02, ...,\n            4.45076935e-02, -2.62424592e-02,  8.00964981e-03]],\n \n         [[-3.19717638e-02, -1.93734672e-02,  2.59683616e-02, ...,\n           -2.89908685e-02, -3.39541957e-03,  4.45405580e-02],\n          [-3.55193689e-02,  1.33352466e-02,  2.51196884e-02, ...,\n            1.06952600e-02,  1.85486563e-02,  4.30079810e-02],\n          [ 3.55999582e-02,  1.74346380e-02,  1.99716724e-02, ...,\n           -1.67967323e-02, -3.14843282e-03,  2.98106298e-03],\n          ...,\n          [ 6.19665161e-03,  3.41417082e-02, -1.87791660e-02, ...,\n            4.00783829e-02, -4.56578657e-02,  3.40487026e-02],\n          [ 3.87072153e-02, -3.49652320e-02,  1.98995285e-02, ...,\n            3.86364795e-02, -1.08550154e-02,  7.18088821e-03],\n          [-3.93146798e-02,  6.09209016e-03,  7.89067522e-03, ...,\n            2.54942738e-02,  9.10370052e-03, -3.67104635e-02]],\n \n         [[-2.82041561e-02, -9.52213258e-03, -3.24331746e-02, ...,\n           -1.82178654e-02, -3.62396426e-02,  1.88137777e-02],\n          [-7.38439336e-03, -3.74536514e-02,  6.57983124e-04, ...,\n           -4.52515744e-02, -3.29348221e-02,  6.98875263e-03],\n          [ 3.22233699e-02,  2.93572508e-02,  2.52804495e-02, ...,\n            4.25453596e-02, -1.36341415e-02,  3.71336900e-02],\n          ...,\n          [-3.89207304e-02,  3.25226672e-02,  2.07574666e-03, ...,\n            1.50460564e-02, -2.66837925e-02, -1.98037922e-03],\n          [-9.93047655e-03, -1.62972156e-02,  6.42093644e-03, ...,\n           -3.75801176e-02, -2.80749723e-02, -6.11470267e-03],\n          [-1.31121092e-02, -3.06412540e-02,  4.57923822e-02, ...,\n            4.47829627e-02, -3.30297910e-02, -1.66746024e-02]],\n \n         [[ 5.74439764e-05, -5.45286015e-03,  2.01065354e-02, ...,\n           -3.52651402e-02,  2.60596462e-02,  3.11530419e-02],\n          [ 3.91361080e-02, -3.06273699e-02,  1.50505491e-02, ...,\n            5.27834892e-03,  7.05955178e-03,  1.48215406e-02],\n          [ 3.11823227e-02,  5.27085364e-03, -3.40390131e-02, ...,\n           -1.56447068e-02,  5.42791560e-03, -1.59061309e-02],\n          ...,\n          [-3.85506600e-02, -3.12849432e-02,  4.51138131e-02, ...,\n            2.80922763e-02, -3.66109908e-02,  3.28131951e-02],\n          [-3.98634002e-02, -1.30386464e-02, -1.32607929e-02, ...,\n            3.62499095e-02,  1.77634507e-03, -3.25621665e-03],\n          [ 3.50871123e-02,  2.10713558e-02,  4.39452641e-02, ...,\n           -1.93779264e-02,  1.29483119e-02, -3.75893116e-02]]],\n \n \n        [[[ 1.94696970e-02,  2.79288031e-02,  1.29164718e-02, ...,\n           -3.19104344e-02, -8.95659253e-03,  5.26420027e-03],\n          [ 4.07753997e-02, -1.99630987e-02,  1.02471933e-03, ...,\n            4.29678746e-02, -2.85195056e-02,  1.56115741e-02],\n          [ 3.35101299e-02, -2.82974038e-02, -1.77913215e-02, ...,\n           -4.35176194e-02, -4.46814783e-02, -2.59627812e-02],\n          ...,\n          [ 9.81171429e-03,  3.73181440e-02, -3.00068576e-02, ...,\n            1.53379664e-02,  2.46787816e-03,  2.85614692e-02],\n          [-3.51975970e-02, -4.41871807e-02, -2.80815605e-02, ...,\n           -1.76767502e-02,  3.99249755e-02, -1.29704848e-02],\n          [ 1.98147483e-02,  3.98240425e-02, -3.11069563e-02, ...,\n            3.95948254e-02, -4.21694741e-02,  4.15418111e-02]],\n \n         [[-2.66521834e-02, -1.17585957e-02,  2.16799565e-02, ...,\n           -1.26455128e-02, -4.40220945e-02, -1.05763860e-02],\n          [ 4.19070311e-02, -1.76571924e-02,  4.57883961e-02, ...,\n           -3.98471430e-02, -3.89715508e-02,  1.55623741e-02],\n          [-1.34561956e-03, -4.32645902e-03,  3.27889509e-02, ...,\n           -1.74288228e-02, -1.16841458e-02,  3.56752537e-02],\n          ...,\n          [ 2.32264362e-02, -6.38227537e-03, -2.31183525e-02, ...,\n            3.60210203e-02, -3.69444638e-02, -6.76841661e-03],\n          [-3.20053473e-03, -2.57388875e-03,  3.74810509e-02, ...,\n           -3.95438075e-03, -2.91848816e-02,  4.05800529e-02],\n          [-3.48343700e-03,  1.29248723e-02,  3.83631028e-02, ...,\n           -7.57634267e-03, -1.40653551e-02, -3.27925049e-02]],\n \n         [[-2.30590850e-02, -3.77689563e-02,  1.27420612e-02, ...,\n           -3.66988219e-02, -4.32530716e-02,  3.20115276e-02],\n          [ 4.08319198e-02,  2.52864473e-02, -1.91735271e-02, ...,\n           -4.33854014e-02,  3.70572396e-02,  1.00119822e-02],\n          [-2.41444279e-02, -2.54210364e-02,  1.83444880e-02, ...,\n            9.06481966e-03, -1.62193403e-02, -1.28521062e-02],\n          ...,\n          [-1.99715868e-02,  1.15225799e-02,  1.28658041e-02, ...,\n           -2.69677211e-02,  1.94385909e-02, -5.92155382e-03],\n          [-3.72876488e-02, -2.88064685e-02,  3.25340517e-02, ...,\n            4.17375006e-02,  4.56681885e-02,  1.81218721e-02],\n          [-2.76744515e-02, -1.81843136e-02,  4.24349569e-02, ...,\n            1.34962723e-02, -2.55617537e-02,  4.11146916e-02]],\n \n         [[-4.10132483e-03,  3.58916931e-02,  3.16109098e-02, ...,\n           -3.43448408e-02,  6.10906631e-03,  2.06624605e-02],\n          [-3.23584341e-02,  1.07165426e-04,  3.22689824e-02, ...,\n            1.84592269e-02,  9.40547511e-03,  1.05973333e-04],\n          [ 1.86979137e-02,  1.17285661e-02, -3.25668044e-02, ...,\n            1.56726614e-02,  1.06649324e-02,  1.39975436e-02],\n          ...,\n          [ 1.55289546e-02, -4.55637909e-02,  1.30450837e-02, ...,\n            3.59085761e-02,  8.00814852e-03,  8.59200954e-03],\n          [ 5.44159114e-03, -7.32463971e-03,  7.97069073e-03, ...,\n           -8.51656497e-03, -2.96771899e-03, -1.92470755e-02],\n          [ 4.55163084e-02, -2.31875479e-03,  3.47523205e-02, ...,\n            2.00075768e-02, -2.53841635e-02, -1.98601931e-02]],\n \n         [[-1.82888638e-02,  1.59488246e-03, -8.00924376e-03, ...,\n            6.03495538e-03,  2.38241218e-02,  1.40311383e-02],\n          [ 2.34430172e-02, -3.60240191e-02,  3.56657170e-02, ...,\n           -4.12336551e-02, -3.53434123e-02, -4.16614451e-02],\n          [-1.55736096e-02,  1.47950649e-03, -3.62105183e-02, ...,\n           -4.67130169e-03,  1.63304545e-02,  4.28900681e-02],\n          ...,\n          [-3.44058610e-02, -3.19788083e-02, -3.94070894e-03, ...,\n            7.47206807e-03, -3.78471166e-02,  1.18632689e-02],\n          [-4.74062189e-03, -1.16210431e-03,  1.86902322e-02, ...,\n            1.82168595e-02,  7.26262480e-03,  2.04349943e-02],\n          [ 3.03290598e-02, -8.12426582e-03,  2.16126703e-02, ...,\n            6.19385391e-04, -4.32767235e-02,  7.21788406e-03]]],\n \n \n        [[[ 1.35726556e-02, -1.06496364e-02, -6.49924204e-03, ...,\n            3.91973928e-03,  4.29330505e-02,  1.31410472e-02],\n          [-7.74624944e-03,  9.67681408e-05, -2.20766924e-02, ...,\n           -4.18299958e-02,  1.95291974e-02, -1.93220470e-02],\n          [-1.39769167e-03, -2.48098057e-02, -1.03977807e-02, ...,\n           -3.13780271e-02, -2.71611046e-02,  2.63778605e-02],\n          ...,\n          [-3.81875411e-03,  2.06903927e-02,  3.82794775e-02, ...,\n           -3.49692814e-02,  4.27103899e-02, -2.73136981e-02],\n          [-4.56272066e-02, -2.23250948e-02,  3.59907784e-02, ...,\n            2.13004537e-02, -7.75704533e-03, -2.67135147e-02],\n          [-4.54592332e-03, -2.58646198e-02, -4.50060442e-02, ...,\n            4.32211161e-03, -3.70947383e-02,  2.50692777e-02]],\n \n         [[ 4.48250510e-02, -3.07597984e-02, -3.87442112e-03, ...,\n            1.18569881e-02,  6.90746680e-03, -3.95109244e-02],\n          [ 1.45419054e-02,  2.27778815e-02, -1.51439421e-02, ...,\n           -2.92550419e-02, -2.60628723e-02, -9.48788598e-03],\n          [ 4.56301458e-02,  3.60034890e-02, -2.00125445e-02, ...,\n            2.59742923e-02, -4.17615473e-02, -4.52737473e-02],\n          ...,\n          [ 3.30022536e-02,  4.50517870e-02, -1.78183056e-02, ...,\n           -3.53814662e-03, -1.20432526e-02, -1.62490737e-02],\n          [-7.13554770e-03, -7.60736689e-03,  3.95641662e-02, ...,\n           -4.40186150e-02, -3.85825671e-02, -2.56070364e-02],\n          [ 1.39329806e-02, -8.22612271e-03,  2.69894861e-02, ...,\n           -1.07899234e-02,  2.58756690e-02, -2.16310229e-02]],\n \n         [[ 9.90360230e-03, -2.52830442e-02, -3.51589248e-02, ...,\n           -4.55480628e-02, -1.18843056e-02,  4.52557318e-02],\n          [-4.36891727e-02, -8.39904696e-03, -4.16734628e-02, ...,\n            2.13489272e-02, -1.20353736e-02, -2.37797573e-03],\n          [ 2.12432034e-02,  2.38611363e-02, -1.66466460e-02, ...,\n           -2.67987605e-02,  3.35019268e-02, -2.38559749e-02],\n          ...,\n          [ 4.56840210e-02,  3.24827246e-02, -2.46112421e-03, ...,\n           -2.71296613e-02,  8.68256390e-03, -2.81586852e-02],\n          [ 4.57941703e-02,  4.24175970e-02,  1.81552432e-02, ...,\n           -1.05000027e-02, -2.80262120e-02, -4.21841852e-02],\n          [ 2.40481533e-02, -2.57149339e-03,  2.12401785e-02, ...,\n           -2.07007676e-03, -2.65083425e-02,  3.93366106e-02]],\n \n         [[-1.79379769e-02, -1.71339344e-02,  1.71221010e-02, ...,\n            4.55670059e-04,  3.15622948e-02,  1.69234090e-02],\n          [ 4.36926074e-02,  3.61959599e-02, -3.60342860e-03, ...,\n           -2.55859010e-02,  4.33116741e-02, -2.12838091e-02],\n          [ 1.32804066e-02,  5.75005263e-03, -1.12659000e-02, ...,\n            1.63179003e-02, -2.80541684e-02,  9.33142006e-03],\n          ...,\n          [-1.13299340e-02,  4.13254686e-02, -4.06822562e-03, ...,\n            4.55820747e-02,  3.52092832e-03, -4.07913923e-02],\n          [ 3.22491564e-02, -1.38528645e-02, -3.98742594e-02, ...,\n            1.49837881e-03, -2.07435116e-02, -4.33181971e-02],\n          [-1.25807263e-02,  5.87601215e-04,  3.34911682e-02, ...,\n            4.03011255e-02, -3.79212201e-03,  4.14321832e-02]],\n \n         [[ 2.68422998e-02, -1.84991453e-02,  1.92621350e-03, ...,\n            3.09110917e-02,  2.06587724e-02,  1.99824236e-02],\n          [ 5.63906878e-03, -3.72490883e-02, -1.06479973e-04, ...,\n            3.96273844e-02,  4.48147096e-02,  2.56754458e-04],\n          [ 2.72882916e-02,  3.88322733e-02,  1.04637556e-02, ...,\n           -3.62543985e-02,  1.17732771e-02,  2.38391571e-02],\n          ...,\n          [-4.61892039e-03,  1.51325613e-02,  4.29585576e-03, ...,\n           -2.82178074e-03, -4.18355577e-02, -9.01166722e-03],\n          [-1.63462497e-02,  4.30823229e-02,  2.62791477e-02, ...,\n           -8.62698629e-03,  1.38278343e-02, -2.42860615e-02],\n          [ 1.53246112e-02,  8.94273072e-03,  1.79697536e-02, ...,\n           -3.90477031e-02,  1.58162601e-02,  1.64485015e-02]]]],\n       dtype=float32)>,\n <tf.Variable 'conv2d_104/kernel:0' shape=(3, 3, 96, 96) dtype=float32, numpy=\n array([[[[-0.01181834,  0.04596787, -0.03443307, ..., -0.05654095,\n            0.00345122, -0.01548818],\n          [ 0.0399566 ,  0.00330532, -0.05324139, ..., -0.05354646,\n           -0.02147337,  0.05021499],\n          [ 0.01987328, -0.02556601,  0.02367119, ..., -0.02456255,\n           -0.0229296 , -0.01900536],\n          ...,\n          [-0.04617543, -0.01449503, -0.00166154, ...,  0.05791971,\n           -0.02277406,  0.05816578],\n          [ 0.01216752,  0.01991026, -0.02287075, ..., -0.04453045,\n           -0.02050326, -0.0240255 ],\n          [-0.00103767, -0.02430498,  0.04468104, ..., -0.05393597,\n           -0.02001191, -0.01667043]],\n \n         [[-0.0059763 ,  0.02114672, -0.03534335, ...,  0.03060852,\n           -0.04525876, -0.02487111],\n          [-0.02691475, -0.01411904,  0.05508195, ...,  0.00043185,\n           -0.03035509,  0.05431907],\n          [-0.00835865,  0.03417739, -0.05286888, ..., -0.05300009,\n            0.00153031, -0.05667557],\n          ...,\n          [ 0.02865883, -0.02515134, -0.05874922, ..., -0.04846435,\n            0.05417134, -0.02757729],\n          [-0.01138063,  0.05208318, -0.00527574, ..., -0.04658119,\n           -0.04512048,  0.04550507],\n          [ 0.02929539, -0.01052946, -0.02454942, ...,  0.05773544,\n           -0.04320989, -0.05610726]],\n \n         [[ 0.02953251,  0.01838107,  0.01011154, ...,  0.04435727,\n            0.00480184, -0.03688626],\n          [-0.03873991, -0.04251672,  0.01162378, ..., -0.00664279,\n            0.02629023, -0.04858638],\n          [-0.02834635,  0.03580442, -0.03463931, ...,  0.00240887,\n            0.03816588, -0.0366129 ],\n          ...,\n          [-0.03051381,  0.0553933 ,  0.05874057, ...,  0.0266243 ,\n            0.03665929, -0.03931992],\n          [-0.01545408, -0.03006087,  0.00728123, ..., -0.02801532,\n            0.0575775 , -0.0507575 ],\n          [ 0.03423874, -0.04191097,  0.03417816, ..., -0.05260268,\n            0.04175412, -0.00352487]]],\n \n \n        [[[-0.02045666,  0.03912503,  0.00032314, ...,  0.04206922,\n           -0.02603693, -0.01344109],\n          [-0.02719819,  0.02138697,  0.0053417 , ...,  0.00856819,\n           -0.00851255,  0.03378176],\n          [-0.00542757,  0.01797831, -0.0189755 , ...,  0.00346843,\n            0.04673158,  0.04107142],\n          ...,\n          [-0.03872836, -0.03214623, -0.01607285, ...,  0.02799905,\n            0.02470894,  0.05748317],\n          [ 0.02894754, -0.05750662,  0.02070346, ...,  0.02705807,\n           -0.0467893 ,  0.00082449],\n          [-0.01855602,  0.0081371 ,  0.03211486, ...,  0.02129346,\n            0.0342385 , -0.00250469]],\n \n         [[-0.0545107 , -0.04065287,  0.05758489, ..., -0.02089492,\n            0.00893779,  0.01346679],\n          [-0.04288276,  0.04775896, -0.01321882, ...,  0.05573134,\n            0.03566075,  0.02987852],\n          [-0.04592855,  0.03541988,  0.00829784, ..., -0.03274557,\n            0.04739233,  0.02024615],\n          ...,\n          [ 0.03653837, -0.03070197,  0.04715366, ...,  0.05658231,\n           -0.05519513, -0.02957888],\n          [-0.00852188, -0.00266031, -0.01622895, ...,  0.01983825,\n           -0.02465437, -0.00302092],\n          [ 0.02821807,  0.01300482,  0.03418094, ..., -0.04272669,\n            0.01204862, -0.04300267]],\n \n         [[-0.02718541, -0.00241688,  0.05761231, ..., -0.04695215,\n            0.01558108,  0.05831157],\n          [-0.05679598, -0.04705953, -0.04343727, ..., -0.00551081,\n           -0.03853468, -0.02688359],\n          [ 0.03210932,  0.0444033 ,  0.02474556, ...,  0.0449443 ,\n            0.01539082,  0.03072416],\n          ...,\n          [-0.00496554,  0.03053028,  0.00229714, ...,  0.01337366,\n            0.0122782 , -0.00317762],\n          [ 0.03841729, -0.02831566, -0.0459564 , ...,  0.01254142,\n            0.04187166,  0.03382119],\n          [ 0.04451458, -0.00706315, -0.01735121, ..., -0.04816344,\n           -0.05439404,  0.03869706]]],\n \n \n        [[[ 0.00476618,  0.05123976, -0.05759196, ..., -0.03197838,\n           -0.04001524, -0.01800918],\n          [-0.04603396,  0.04645855,  0.00499983, ..., -0.00118881,\n            0.03067173, -0.05057355],\n          [ 0.00390717, -0.04127621, -0.03590158, ...,  0.01217483,\n           -0.01583838,  0.04063531],\n          ...,\n          [-0.05512458, -0.0424746 , -0.01982106, ..., -0.04424986,\n            0.04676624,  0.02679526],\n          [ 0.05145523,  0.01188451,  0.0229958 , ...,  0.04107377,\n            0.04575085, -0.02480523],\n          [ 0.04518381,  0.01839513,  0.04714772, ..., -0.04442982,\n            0.02776804,  0.02125445]],\n \n         [[-0.05398459,  0.03061492, -0.03472485, ...,  0.00687229,\n            0.02549559,  0.021078  ],\n          [-0.01197854, -0.04232881,  0.04034183, ...,  0.03895133,\n           -0.0442995 ,  0.0496386 ],\n          [-0.05611385, -0.0114512 , -0.05744851, ...,  0.01797998,\n            0.03265956, -0.01261323],\n          ...,\n          [ 0.03025373,  0.05736901, -0.03291453, ..., -0.021297  ,\n            0.03179321,  0.04889316],\n          [ 0.02369015, -0.02381456,  0.03584228, ..., -0.03227847,\n            0.01813281,  0.05643478],\n          [ 0.00113587,  0.05637622, -0.02676899, ..., -0.05501373,\n           -0.02995013, -0.00193672]],\n \n         [[ 0.03458731,  0.01489909,  0.035481  , ...,  0.02473671,\n           -0.00909008,  0.03892512],\n          [-0.05292236,  0.02360624, -0.04725774, ..., -0.03117813,\n           -0.02078351, -0.01538218],\n          [-0.00717102,  0.01565753,  0.04672575, ...,  0.02649402,\n            0.04589641,  0.05295982],\n          ...,\n          [ 0.0534802 ,  0.01273497, -0.0223838 , ...,  0.02784613,\n            0.04035291, -0.04845864],\n          [-0.04775973,  0.02213086, -0.0100494 , ...,  0.02893849,\n           -0.03750823,  0.05681977],\n          [-0.05436519,  0.04756248, -0.02681427, ..., -0.0143437 ,\n           -0.02909079,  0.03469985]]]], dtype=float32)>,\n <tf.Variable 'conv2d_105/kernel:0' shape=(1, 1, 192, 32) dtype=float32, numpy=\n array([[[[ 0.12966338, -0.02199635,  0.02479504, ...,  0.05270649,\n           -0.03587414,  0.09288174],\n          [ 0.00078127, -0.03533711,  0.15850082, ..., -0.04439152,\n           -0.11335668,  0.15069738],\n          [-0.0966245 ,  0.12514576, -0.126961  , ...,  0.05677889,\n           -0.05757612,  0.1351122 ],\n          ...,\n          [ 0.1532346 , -0.09226194,  0.00929348, ...,  0.08230445,\n            0.01566814,  0.03502205],\n          [-0.11808103,  0.02617101, -0.07153598, ...,  0.01733369,\n            0.07755472,  0.12052098],\n          [ 0.05086309, -0.05142307,  0.13907662, ..., -0.02976437,\n           -0.16263808, -0.15106146]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_99/beta:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_99/moving_mean:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_99/moving_variance:0' shape=(64,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_101/beta:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_101/moving_mean:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_101/moving_variance:0' shape=(64,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_104/beta:0' shape=(96,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_104/moving_mean:0' shape=(96,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_104/moving_variance:0' shape=(96,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_105/beta:0' shape=(32,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_105/moving_mean:0' shape=(32,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_105/moving_variance:0' shape=(32,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n       dtype=float32)>,\n <tf.Variable 'conv2d_109/kernel:0' shape=(1, 1, 256, 64) dtype=float32, numpy=\n array([[[[ 0.07080881, -0.08427389, -0.00367723, ..., -0.1269559 ,\n           -0.0133118 , -0.07459525],\n          [ 0.00832552, -0.04566225, -0.07252022, ...,  0.09608991,\n            0.1001485 , -0.05809353],\n          [-0.00460242, -0.02530503, -0.12834111, ...,  0.07754809,\n            0.12739229, -0.02070422],\n          ...,\n          [ 0.03798048, -0.09552813, -0.0266858 , ..., -0.03117708,\n            0.08577362, -0.09970829],\n          [-0.06706161,  0.06862199,  0.1114693 , ..., -0.08505369,\n            0.11024508,  0.12187648],\n          [-0.02495763,  0.12698138, -0.05943404, ..., -0.00486836,\n            0.10949641, -0.04021558]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_109/beta:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_109/moving_mean:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_109/moving_variance:0' shape=(64,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_107/kernel:0' shape=(1, 1, 256, 48) dtype=float32, numpy=\n array([[[[ 0.12729536,  0.11052246, -0.10582907, ..., -0.0083801 ,\n            0.02291769, -0.13053392],\n          [ 0.00142381,  0.03419711,  0.09308951, ...,  0.06863089,\n           -0.11105843, -0.03824352],\n          [ 0.06747575, -0.11914718,  0.03684223, ...,  0.00843661,\n           -0.00136428, -0.08276169],\n          ...,\n          [ 0.02199216, -0.0361651 , -0.01297137, ...,  0.1036472 ,\n            0.12886797,  0.03965664],\n          [-0.11952852,  0.03681624, -0.02913509, ...,  0.08791263,\n            0.09174921,  0.015637  ],\n          [-0.00882766, -0.03951918, -0.08346605, ...,  0.0737038 ,\n            0.02498624,  0.113856  ]]]], dtype=float32)>,\n <tf.Variable 'conv2d_110/kernel:0' shape=(3, 3, 64, 96) dtype=float32, numpy=\n array([[[[ 0.02331761, -0.02537303, -0.02842116, ..., -0.01145505,\n            0.05132858,  0.01736925],\n          [-0.05177823, -0.04055618, -0.04695287, ..., -0.0329468 ,\n            0.01492777,  0.04627276],\n          [ 0.02601236, -0.00727588,  0.02271139, ..., -0.05018382,\n           -0.05375265, -0.03716831],\n          ...,\n          [-0.04380012,  0.03160752,  0.03612468, ...,  0.01481312,\n            0.05587069, -0.00455212],\n          [ 0.00450528, -0.05829223,  0.03345095, ..., -0.05250833,\n           -0.04454553,  0.01218752],\n          [-0.04477078,  0.0058054 ,  0.05386723, ..., -0.04062926,\n            0.02600735, -0.05698735]],\n \n         [[ 0.0165168 ,  0.01504318,  0.04790004, ..., -0.00497298,\n           -0.03527531, -0.02850947],\n          [ 0.02243907, -0.04549739, -0.05043253, ...,  0.05477659,\n           -0.0420745 ,  0.01842327],\n          [ 0.05129527, -0.04128682,  0.03835059, ..., -0.01321779,\n           -0.04519325, -0.02658452],\n          ...,\n          [ 0.03923833, -0.04804418,  0.00324494, ..., -0.05967616,\n           -0.02140772,  0.05127299],\n          [ 0.00220441, -0.05327059,  0.00402595, ..., -0.05941453,\n            0.00550963, -0.04735259],\n          [-0.05199271,  0.0633593 ,  0.05360754, ...,  0.05643695,\n           -0.01803463, -0.03367825]],\n \n         [[-0.06273571,  0.04523396,  0.02376994, ..., -0.05577498,\n            0.01024722, -0.02464491],\n          [ 0.00329354, -0.02115474, -0.04667242, ..., -0.04824742,\n           -0.03885202,  0.0245494 ],\n          [ 0.00899137, -0.01214898, -0.03094121, ..., -0.01095464,\n           -0.05134486, -0.02766352],\n          ...,\n          [-0.02256933, -0.06030563, -0.00774717, ...,  0.02747832,\n            0.01173335, -0.00500556],\n          [ 0.00372431,  0.04411954, -0.04057875, ..., -0.04102838,\n           -0.02100092, -0.02847898],\n          [-0.03351612, -0.01249727, -0.01489982, ...,  0.04155116,\n           -0.00624406, -0.03688978]]],\n \n \n        [[[ 0.00921576, -0.02707073,  0.03601586, ...,  0.06075934,\n           -0.06230719,  0.00967722],\n          [ 0.02161136,  0.00204517,  0.03563347, ..., -0.01968498,\n            0.04904326, -0.03627418],\n          [-0.05468501,  0.04122122, -0.0453336 , ..., -0.05920744,\n           -0.01423207,  0.05196059],\n          ...,\n          [ 0.04189973, -0.05264213, -0.0481135 , ...,  0.0060076 ,\n           -0.01026657,  0.06394235],\n          [ 0.02504203,  0.0593278 , -0.0246406 , ..., -0.05308034,\n            0.0041488 ,  0.03077895],\n          [-0.00897253, -0.05560677,  0.03111828, ...,  0.03460861,\n            0.05270457, -0.0165932 ]],\n \n         [[-0.03348234,  0.01331384,  0.02100019, ..., -0.05119319,\n            0.04911953,  0.04869888],\n          [-0.00153162, -0.01624131, -0.04564854, ..., -0.00802065,\n           -0.04641957,  0.01690762],\n          [-0.03947962,  0.03193992,  0.06045369, ..., -0.03916297,\n            0.06023426,  0.04612591],\n          ...,\n          [ 0.01644466, -0.0566211 , -0.04763809, ..., -0.04355573,\n            0.04474595,  0.06367464],\n          [-0.05404735,  0.05856016,  0.03164637, ..., -0.05564012,\n            0.00049044, -0.04902895],\n          [-0.0205999 ,  0.02007885, -0.05570116, ..., -0.0006166 ,\n            0.02133299, -0.05595463]],\n \n         [[ 0.00128416,  0.01505545,  0.0581978 , ...,  0.06238956,\n            0.05443228, -0.01606667],\n          [-0.04576281,  0.05466888, -0.01359506, ..., -0.03112379,\n           -0.04399126, -0.01149065],\n          [-0.01181016,  0.05206909,  0.01772833, ...,  0.02192089,\n           -0.04297058,  0.0612453 ],\n          ...,\n          [-0.03596511,  0.01260667,  0.03835665, ..., -0.0488392 ,\n            0.0154564 ,  0.00405281],\n          [ 0.0024971 , -0.03310898,  0.05811632, ..., -0.04143452,\n           -0.00780552,  0.04331574],\n          [-0.02245621,  0.06329433, -0.04975384, ...,  0.00840914,\n            0.02481607, -0.04504766]]],\n \n \n        [[[ 0.04680127,  0.00093835,  0.05620587, ...,  0.04849219,\n           -0.01922887, -0.01726854],\n          [-0.03004298,  0.01918063,  0.01899728, ...,  0.04055838,\n           -0.05944018,  0.04361016],\n          [-0.0076615 , -0.04577972,  0.04727389, ..., -0.02140829,\n            0.06225372,  0.02956682],\n          ...,\n          [ 0.05023769, -0.04679376,  0.02057012, ...,  0.01348896,\n           -0.02308692, -0.06445149],\n          [-0.03924579,  0.00454836, -0.03241268, ...,  0.002174  ,\n           -0.01389121, -0.00396187],\n          [-0.0029653 ,  0.03756877, -0.02992455, ..., -0.03172854,\n            0.05907778, -0.0630839 ]],\n \n         [[ 0.05048668,  0.03540919, -0.02326904, ...,  0.01622551,\n            0.03730457, -0.04745021],\n          [-0.00284224,  0.03253706,  0.02175237, ...,  0.00655916,\n            0.06129437, -0.04357977],\n          [ 0.05858417, -0.04795785, -0.00097738, ..., -0.05366194,\n            0.00692882,  0.04661921],\n          ...,\n          [ 0.01103288, -0.02895976,  0.04162566, ...,  0.00165312,\n            0.01355257, -0.02181764],\n          [ 0.03719191, -0.04940401, -0.05543622, ...,  0.0222116 ,\n            0.00088612, -0.01036327],\n          [-0.00193974, -0.04163218, -0.05948906, ...,  0.03532561,\n            0.06205019,  0.01897826]],\n \n         [[-0.03879377, -0.06147366,  0.05537671, ...,  0.00615217,\n           -0.04491573,  0.00290816],\n          [ 0.0581451 , -0.00460141,  0.01322421, ..., -0.00791885,\n            0.05394094,  0.01835056],\n          [-0.03133225,  0.00296575, -0.00488235, ...,  0.04244452,\n            0.0564387 , -0.00525968],\n          ...,\n          [-0.04975417, -0.00387495, -0.03749562, ...,  0.01943417,\n            0.00818475, -0.00231633],\n          [ 0.02479881, -0.01378804,  0.05443266, ...,  0.02145416,\n            0.0040465 ,  0.03983571],\n          [-0.04938883,  0.03072487,  0.01864071, ...,  0.02639258,\n            0.05097235, -0.01678704]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_107/beta:0' shape=(48,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_107/moving_mean:0' shape=(48,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_107/moving_variance:0' shape=(48,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_110/beta:0' shape=(96,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_110/moving_mean:0' shape=(96,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_110/moving_variance:0' shape=(96,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_106/kernel:0' shape=(1, 1, 256, 64) dtype=float32, numpy=\n array([[[[-1.02896020e-01,  9.57727432e-04,  1.04850262e-01, ...,\n           -2.70460173e-02, -1.28628239e-01, -7.68060908e-02],\n          [-4.65769768e-02,  5.56505620e-02,  1.17083222e-01, ...,\n           -1.35128871e-01,  7.18476027e-02,  6.65096790e-02],\n          [-3.55210975e-02,  1.34647965e-01,  1.34183913e-01, ...,\n           -2.94342637e-02, -1.18185729e-02, -7.43143260e-02],\n          ...,\n          [-4.21920493e-02,  2.33800709e-02,  6.90221488e-02, ...,\n            1.14245445e-01,  1.32512152e-02, -2.47492865e-02],\n          [-1.19911924e-01, -6.37027621e-03, -8.26795474e-02, ...,\n           -1.12647951e-01,  4.54477519e-02, -1.09218858e-01],\n          [ 9.74176228e-02,  4.94271517e-05, -4.08992693e-02, ...,\n           -8.99351388e-02,  1.15067303e-01,  6.81953132e-03]]]],\n       dtype=float32)>,\n <tf.Variable 'conv2d_108/kernel:0' shape=(5, 5, 48, 64) dtype=float32, numpy=\n array([[[[-1.08553469e-02,  2.32848711e-02, -1.06221437e-02, ...,\n            1.84330232e-02,  3.68853994e-02, -4.53633443e-03],\n          [ 3.41881104e-02, -1.46289542e-03,  3.48649435e-02, ...,\n           -2.46629734e-02, -2.68924404e-02, -1.14198290e-02],\n          [-2.33730115e-02, -3.89535837e-02, -1.77893043e-03, ...,\n            1.14910565e-02, -2.97526401e-02,  3.19609456e-02],\n          ...,\n          [-4.34845686e-03, -2.22209524e-02, -4.03183624e-02, ...,\n            4.11100648e-02, -3.15115973e-03, -1.59226544e-02],\n          [-9.16394964e-03,  1.36350244e-02,  1.92448907e-02, ...,\n            2.50907987e-03,  1.16126277e-02,  2.64943503e-02],\n          [ 1.92855708e-02, -2.72330418e-02, -1.56772658e-02, ...,\n           -3.80097106e-02, -1.71339568e-02, -2.45729703e-02]],\n \n         [[ 3.51647548e-02, -1.79544874e-02, -1.60549954e-03, ...,\n           -2.12156586e-02,  1.71209313e-02, -3.83487977e-02],\n          [ 3.40229645e-03, -6.73741102e-04, -3.18249986e-02, ...,\n            2.10219957e-02, -6.43219426e-03,  2.71212496e-02],\n          [-1.73149146e-02, -2.86295395e-02,  6.68191165e-03, ...,\n            3.59588079e-02, -5.52863628e-03, -1.43641979e-03],\n          ...,\n          [ 1.88226625e-03,  3.73564102e-02, -3.70716713e-02, ...,\n            3.56158502e-02, -3.05913016e-02, -2.10516211e-02],\n          [ 3.20609100e-02,  3.31461988e-02,  2.41107978e-02, ...,\n           -7.41197169e-03,  3.70507687e-03,  2.70036347e-02],\n          [ 6.98007643e-03, -3.37835290e-02, -3.80582921e-02, ...,\n            1.81914903e-02,  9.18380544e-03,  7.32578710e-03]],\n \n         [[-2.73726005e-02,  3.49481888e-02, -4.40468378e-02, ...,\n           -3.40330452e-02,  4.50968929e-02,  1.85258649e-02],\n          [-4.05545272e-02,  1.46037638e-02,  1.04729608e-02, ...,\n            3.32091339e-02,  8.83966684e-04, -4.40915674e-03],\n          [-4.52505164e-02,  1.20906457e-02,  4.58391346e-02, ...,\n            4.26277034e-02,  9.53051075e-03, -3.25309113e-03],\n          ...,\n          [ 4.62561063e-02,  2.42926814e-02,  1.06101595e-02, ...,\n            2.54467316e-02,  6.45946711e-03, -2.05699820e-02],\n          [ 3.04392390e-02,  3.61591205e-03,  4.01989333e-02, ...,\n           -4.84482944e-03,  3.99869867e-02,  1.93696134e-02],\n          [-4.57673259e-02, -2.17461586e-03,  6.04734942e-03, ...,\n            2.29290500e-03, -4.23859991e-02,  4.22801115e-02]],\n \n         [[ 2.03271396e-02,  3.04316320e-02,  1.20068341e-02, ...,\n           -1.29270926e-03, -1.64091699e-02,  2.29371823e-02],\n          [ 5.90983033e-03, -4.23808470e-02,  3.97887267e-02, ...,\n           -2.92275045e-02, -2.53942162e-02,  4.10355665e-02],\n          [-4.25485149e-02,  1.48119703e-02, -1.21349581e-02, ...,\n            4.36203144e-02,  4.84689325e-03,  3.59019898e-02],\n          ...,\n          [-2.64361091e-02,  6.39448315e-03,  2.64528431e-02, ...,\n            3.18184979e-02, -3.49969417e-03,  2.47535296e-02],\n          [-3.94636989e-02,  1.30045786e-02, -3.17657366e-03, ...,\n            3.95414867e-02, -7.29064643e-03,  1.93037055e-02],\n          [ 2.40208767e-02, -1.47005990e-02, -3.38109583e-03, ...,\n            4.07099985e-02,  6.95334375e-03, -2.87298858e-02]],\n \n         [[-4.45571393e-02, -4.54298146e-02, -1.54567976e-02, ...,\n           -5.08675352e-03,  2.05984674e-02,  9.11092013e-03],\n          [ 1.12504810e-02,  2.11589597e-02,  2.58985795e-02, ...,\n           -4.51178327e-02,  3.12837102e-02,  1.75399706e-03],\n          [ 1.50230788e-02,  1.98275708e-02,  1.56354047e-02, ...,\n            4.48647700e-02,  4.01260592e-02,  9.11273062e-04],\n          ...,\n          [-1.82611849e-02, -2.58817896e-03, -1.66732669e-02, ...,\n            2.00589187e-02,  1.41532496e-02,  2.25661807e-02],\n          [ 3.43911611e-02, -4.88572940e-03,  4.39506210e-02, ...,\n            4.81265783e-03,  2.83325836e-03, -4.16502766e-02],\n          [-3.37378159e-02, -3.57598066e-03, -5.66222519e-03, ...,\n           -4.08106409e-02, -4.46257368e-03, -1.40239000e-02]]],\n \n \n        [[[ 1.86456256e-02,  6.83517754e-03,  4.48991358e-03, ...,\n            3.12659182e-02, -4.05064300e-02, -2.11699437e-02],\n          [ 8.07274133e-04,  2.32025422e-02, -7.18170404e-03, ...,\n           -8.71247426e-03, -5.49665466e-03, -2.29855478e-02],\n          [ 4.59388457e-02,  3.93873788e-02, -1.38547421e-02, ...,\n            7.01533630e-03,  5.77539578e-03, -3.67065370e-02],\n          ...,\n          [-2.65240036e-02, -3.95344198e-02, -1.39720365e-03, ...,\n            5.21604717e-03,  2.97107175e-03,  2.59343795e-02],\n          [-3.30394283e-02, -3.99145000e-02,  2.58042030e-02, ...,\n            8.36588442e-04,  1.30303614e-02, -6.56491145e-03],\n          [-5.82432002e-03,  3.59116457e-02, -3.52941826e-03, ...,\n            1.08316205e-02, -2.42141634e-03,  2.05958001e-02]],\n \n         [[-3.65332179e-02,  2.06824429e-02, -1.83173716e-02, ...,\n           -1.09758787e-02, -2.26258207e-02,  3.64526846e-02],\n          [-5.97277284e-03,  9.84452292e-03,  7.43297487e-03, ...,\n            1.83688141e-02,  8.99127126e-03, -1.57906767e-02],\n          [-2.06264891e-02,  4.59768660e-02,  2.78813802e-02, ...,\n            2.94213556e-02,  1.37667023e-02, -6.65759668e-03],\n          ...,\n          [ 4.49410938e-02, -3.63850817e-02, -3.89764458e-03, ...,\n           -2.60721203e-02, -3.77179347e-02, -4.27591614e-02],\n          [-4.11862843e-02, -4.24622968e-02, -2.88138296e-02, ...,\n           -2.55472511e-02,  4.23366241e-02,  1.51283368e-02],\n          [-1.85916983e-02,  1.25776939e-02,  2.06071101e-02, ...,\n           -2.88552288e-02, -4.02607098e-02,  8.76813382e-03]],\n \n         [[ 1.55921280e-03,  2.91347094e-02, -2.26592720e-02, ...,\n            4.58681248e-02,  9.77788493e-03, -4.42423858e-02],\n          [-2.79705208e-02, -2.01520696e-02,  4.53217365e-02, ...,\n           -1.22370943e-03, -1.31574795e-02, -4.09700423e-02],\n          [-3.52639258e-02,  3.45419534e-02,  3.43150832e-02, ...,\n            3.65335830e-02,  3.92343886e-02,  3.98483165e-02],\n          ...,\n          [ 4.53349315e-02,  3.37118097e-02, -3.71624380e-02, ...,\n           -1.34685040e-02, -1.66401118e-02,  3.33095454e-02],\n          [ 9.17824358e-03,  1.39728338e-02,  3.77549417e-02, ...,\n           -4.54695374e-02, -2.09268294e-02,  2.29459964e-02],\n          [ 1.94838308e-02, -3.55512314e-02, -4.54996154e-03, ...,\n            4.32493202e-02,  4.46931906e-02,  7.60453939e-03]],\n \n         [[ 2.17908658e-02, -7.94624537e-03,  4.31001820e-02, ...,\n           -4.94520739e-03,  9.99110192e-03, -2.21639145e-02],\n          [-3.05810049e-02, -3.20363790e-03, -4.52239811e-02, ...,\n           -2.04276089e-02, -5.14089689e-03,  2.93040238e-02],\n          [-1.78916436e-02, -2.09130440e-02, -3.06669027e-02, ...,\n           -4.60773371e-02, -3.91787663e-02, -2.00786535e-02],\n          ...,\n          [ 3.70062552e-02,  3.95752378e-02, -2.81751286e-02, ...,\n            1.11410879e-02,  2.46336348e-02, -6.23652712e-03],\n          [-2.19307840e-04, -1.12021714e-03, -3.92311215e-02, ...,\n            3.33483145e-03,  9.99355316e-03, -3.19183804e-02],\n          [-4.14730385e-02,  5.02739102e-04, -1.24202333e-02, ...,\n            4.18590419e-02,  7.78123736e-03,  1.37263834e-02]],\n \n         [[ 1.75742619e-02,  4.48745824e-02,  3.77046131e-02, ...,\n            1.68166347e-02, -1.07431710e-02,  4.72061336e-03],\n          [ 3.97117548e-02, -3.88918817e-03,  3.96161266e-02, ...,\n            6.35965168e-03,  4.03462313e-02,  7.02959672e-03],\n          [-2.95838118e-02,  3.46150510e-02,  6.36693090e-04, ...,\n            8.20457935e-05,  5.28268516e-04, -4.23003137e-02],\n          ...,\n          [ 2.93756388e-02,  2.11507939e-02,  3.10457386e-02, ...,\n           -3.21273059e-02, -6.24899939e-03, -1.16249882e-02],\n          [-1.77796669e-02, -3.18621174e-02,  1.21432468e-02, ...,\n           -4.28110212e-02, -2.16922425e-02,  3.55627201e-02],\n          [-2.86658183e-02, -2.82556638e-02, -1.95660125e-02, ...,\n           -1.02682784e-03, -4.12533432e-02, -1.05323158e-02]]],\n \n \n        [[[-5.55536896e-03, -1.86947249e-02,  2.20145993e-02, ...,\n           -2.76480298e-02,  1.75062679e-02, -3.59386839e-02],\n          [ 1.32278502e-02, -2.14078054e-02, -5.57769462e-03, ...,\n           -2.68543195e-02, -3.21386494e-02,  8.01720098e-03],\n          [ 4.52951342e-03,  2.17863657e-02,  3.92198972e-02, ...,\n           -2.16593966e-02,  9.88273323e-03, -2.88631972e-02],\n          ...,\n          [ 3.38652842e-02, -1.64968353e-02, -4.25111242e-02, ...,\n            3.92449610e-02, -1.44622400e-02,  8.62859562e-03],\n          [-1.53175369e-03, -4.07072082e-02,  2.77617835e-02, ...,\n           -1.54255312e-02,  3.82711776e-02,  1.27476566e-02],\n          [-1.59057900e-02,  6.95107132e-03,  1.59922279e-02, ...,\n            4.83219326e-03,  1.60523877e-02,  4.47248183e-02]],\n \n         [[-3.99197750e-02,  1.50724575e-02, -4.50321883e-02, ...,\n           -3.01510394e-02, -2.02829521e-02, -1.87493786e-02],\n          [ 1.52345411e-02,  4.38456498e-02, -2.86281724e-02, ...,\n           -3.98676619e-02,  3.73720713e-02, -3.02786455e-02],\n          [-4.24705520e-02, -2.38702334e-02, -3.08740828e-02, ...,\n           -1.41242556e-02, -3.67910676e-02, -4.47125137e-02],\n          ...,\n          [ 1.33459195e-02,  2.12503113e-02,  1.56298392e-02, ...,\n            1.59664266e-02,  8.95978510e-03,  3.68957855e-02],\n          [-2.26446595e-02, -2.49347463e-03,  1.04755163e-05, ...,\n            1.11929253e-02,  1.08504035e-02,  1.55758709e-02],\n          [ 2.86750011e-02, -4.94275615e-03, -3.89325172e-02, ...,\n           -5.67288697e-03,  2.39084177e-02,  1.77313574e-02]],\n \n         [[ 1.26686879e-02,  3.08591127e-03,  4.49073054e-02, ...,\n            2.83693634e-02, -2.34677941e-02,  5.85414469e-04],\n          [ 3.90492938e-02,  3.92253585e-02, -1.88218448e-02, ...,\n            3.62558030e-02, -3.28791291e-02,  4.12799083e-02],\n          [ 4.19427566e-02, -4.40910272e-02, -2.03411710e-02, ...,\n            2.13771351e-02,  5.76939061e-03,  5.18428162e-03],\n          ...,\n          [-2.46159025e-02, -2.31453478e-02, -2.33027749e-02, ...,\n            1.73702724e-02, -1.54954921e-02, -4.54608612e-02],\n          [ 2.31309570e-02, -1.84689481e-02,  4.86025959e-03, ...,\n           -2.61917692e-02, -4.20169793e-02, -8.96739960e-03],\n          [-1.82080753e-02,  2.42540799e-02,  3.95445116e-02, ...,\n           -1.25800334e-02,  4.36782278e-02, -1.70353018e-02]],\n \n         [[ 3.68110351e-02,  2.23551132e-02,  1.23140477e-02, ...,\n           -1.09058730e-02,  2.36753412e-02, -6.59197196e-03],\n          [ 5.61897084e-03,  2.27439888e-02, -2.14396361e-02, ...,\n           -4.00947854e-02,  4.01219316e-02,  3.44615169e-02],\n          [-4.62335609e-02, -7.13585690e-03,  4.53763455e-03, ...,\n           -1.12511553e-02, -5.43645769e-03, -3.19497362e-02],\n          ...,\n          [-4.83575836e-03,  2.23846696e-02,  1.98202766e-02, ...,\n            1.31125040e-02,  2.47739665e-02,  3.84670310e-02],\n          [-3.45758721e-02, -1.94629971e-02,  1.09488629e-02, ...,\n           -1.60261653e-02,  1.54370628e-02, -2.35631615e-02],\n          [-3.65164876e-03, -9.48127732e-03, -2.29857247e-02, ...,\n           -7.00477511e-03,  3.72195207e-02,  3.59639563e-02]],\n \n         [[ 3.10283788e-02,  2.82212161e-02,  2.22331397e-02, ...,\n           -4.31731343e-04,  3.97366472e-02,  2.03717165e-02],\n          [-1.21627934e-02,  2.74465568e-02,  2.88487934e-02, ...,\n           -3.97049040e-02, -2.47973222e-02,  2.72713192e-02],\n          [-4.61973585e-02, -3.33867371e-02,  4.28673662e-02, ...,\n           -1.48522779e-02,  3.33164372e-02, -8.70320573e-03],\n          ...,\n          [-7.48472661e-03,  5.73432818e-03,  1.14978217e-02, ...,\n            1.06449127e-02, -7.76812434e-04,  1.85567886e-03],\n          [-2.93573849e-02,  3.77854817e-02,  3.73965837e-02, ...,\n           -1.25680231e-02,  8.89762491e-03, -4.49940339e-02],\n          [-3.80294211e-02,  5.01722097e-05,  4.24601100e-02, ...,\n           -6.03904948e-03, -2.64825728e-02,  2.74588726e-02]]],\n \n \n        [[[ 3.02330516e-02, -3.80749814e-02,  4.21691425e-02, ...,\n            1.50915831e-02,  3.61614265e-02,  2.64234841e-05],\n          [-2.67746132e-02,  1.93281732e-02, -1.39229707e-02, ...,\n           -4.09619771e-02,  8.37228075e-03, -2.57938430e-02],\n          [ 1.49653479e-02, -4.40231301e-02, -2.45442409e-02, ...,\n            3.96718271e-02,  9.34774429e-03,  3.31820957e-02],\n          ...,\n          [ 1.45842507e-02, -1.55448914e-03,  2.16941647e-02, ...,\n            5.52091002e-03,  1.22526400e-02, -3.73043492e-02],\n          [-1.13041289e-02,  1.15829036e-02,  1.12093799e-02, ...,\n            3.09852101e-02, -4.25728410e-03, -2.01578308e-02],\n          [-3.01532913e-02,  3.59285735e-02,  3.60271521e-02, ...,\n            2.35107802e-02, -1.50777102e-02,  3.99065875e-02]],\n \n         [[-3.10458802e-02,  1.83584280e-02, -1.22109018e-02, ...,\n           -1.94185078e-02, -5.77536225e-03, -1.00515038e-03],\n          [-2.67302562e-02, -3.03761102e-02, -3.11654955e-02, ...,\n           -2.34456100e-02, -4.09656167e-02, -1.24976560e-02],\n          [ 4.01897989e-02, -1.73104666e-02, -5.39619848e-03, ...,\n            2.26773731e-02,  3.05736102e-02,  1.65049024e-02],\n          ...,\n          [ 4.20759805e-02,  2.99873203e-03,  4.51477878e-02, ...,\n            1.99568234e-02,  3.22923698e-02, -2.70380024e-02],\n          [-3.48113589e-02, -3.27986851e-02, -1.63138248e-02, ...,\n           -1.31641366e-02, -3.01246624e-02,  9.19206068e-03],\n          [-3.49669419e-02, -1.94678195e-02,  8.09296593e-03, ...,\n            2.06748880e-02,  2.69566216e-02,  2.86014266e-02]],\n \n         [[ 1.34191364e-02,  4.55474742e-02, -3.74114588e-02, ...,\n           -1.03743263e-02, -3.98966670e-02,  2.17444934e-02],\n          [ 4.38006558e-02,  1.62997209e-02, -2.89215036e-02, ...,\n           -2.77337302e-02, -3.31631266e-02, -1.56318154e-02],\n          [ 2.33027227e-02,  3.09151821e-02, -3.64286900e-02, ...,\n            2.00596042e-02,  9.22071189e-03,  4.05678116e-02],\n          ...,\n          [ 3.54575776e-02, -4.56091054e-02, -1.89045984e-02, ...,\n            2.06428356e-02,  3.52940001e-02, -1.96711700e-02],\n          [-4.57268246e-02, -5.60358539e-03, -3.37960757e-02, ...,\n           -2.72228997e-02,  1.37180835e-03,  3.07570361e-02],\n          [-3.75110507e-02,  3.67588736e-02,  1.62775926e-02, ...,\n           -9.33412462e-03,  1.76188536e-02,  1.51610598e-02]],\n \n         [[ 1.34837665e-02, -3.44890207e-02,  3.98251154e-02, ...,\n            8.63384455e-04, -2.87198536e-02, -3.30925249e-02],\n          [ 1.91283785e-02,  2.21292786e-02,  3.84796746e-02, ...,\n            5.46379760e-03,  7.72121921e-03, -4.05361503e-02],\n          [-4.03914265e-02, -4.52394336e-02, -9.13242996e-03, ...,\n            2.16219164e-02, -3.59555483e-02, -9.56458971e-03],\n          ...,\n          [-3.18437405e-02,  2.99409665e-02,  1.01110041e-02, ...,\n            2.99840309e-02,  4.43737619e-02, -4.32319157e-02],\n          [ 2.64986567e-02, -1.03733577e-02,  2.36917399e-02, ...,\n            3.86547558e-02, -8.64092261e-03,  3.21767367e-02],\n          [-3.98887321e-03,  4.04893123e-02, -1.50561668e-02, ...,\n            3.82268541e-02, -2.02992205e-02, -2.66984049e-02]],\n \n         [[-2.71722302e-02, -3.47506031e-02, -3.55872363e-02, ...,\n           -4.23152111e-02,  4.60554473e-02,  2.49437802e-02],\n          [ 4.56508212e-02, -1.35361254e-02,  1.39177367e-02, ...,\n            4.56092469e-02,  4.09936644e-02, -4.18281220e-02],\n          [ 4.58547287e-02,  3.69267948e-02,  3.60586606e-02, ...,\n           -4.51522991e-02, -6.29812106e-03,  3.61644365e-02],\n          ...,\n          [-3.04985624e-02,  2.89835595e-02,  3.93563993e-02, ...,\n            1.22308433e-02, -3.88800725e-03,  3.01114656e-02],\n          [-9.33023915e-03, -2.39437819e-02, -3.00164931e-02, ...,\n           -2.35562194e-02, -2.82968748e-02, -7.01970980e-03],\n          [ 7.86574557e-03,  4.00826968e-02,  2.39173956e-02, ...,\n           -4.08047251e-02,  9.11779702e-04, -3.73033658e-02]]],\n \n \n        [[[-1.38975196e-02, -3.17007937e-02,  4.23291139e-02, ...,\n            4.31431346e-02, -3.93687934e-02,  3.94404419e-02],\n          [ 3.15449424e-02, -4.81940061e-03,  4.48031090e-02, ...,\n           -1.82547048e-03,  4.08286564e-02, -1.23215541e-02],\n          [ 2.12438777e-03, -2.95659322e-02, -3.71350236e-02, ...,\n           -4.62129079e-02, -1.76761765e-02,  4.57120650e-02],\n          ...,\n          [ 7.16332719e-03, -3.35624442e-02, -1.35163590e-02, ...,\n            1.90893076e-02, -1.83873884e-02, -2.44859681e-02],\n          [-3.96772884e-02,  2.44121216e-02, -1.29356198e-02, ...,\n            2.00195648e-02, -1.99212823e-02, -1.39301755e-02],\n          [ 2.29289196e-02,  8.77156854e-04, -3.49302664e-02, ...,\n           -3.88325118e-02,  1.57590248e-02, -2.91165765e-02]],\n \n         [[-4.78183106e-03, -1.36546046e-02, -2.24890765e-02, ...,\n           -7.02648610e-03, -2.77116895e-02, -3.60941589e-02],\n          [ 4.07371931e-02,  1.73703395e-02,  1.40510052e-02, ...,\n           -2.52705738e-02, -3.39584276e-02, -6.72935694e-03],\n          [-9.06808674e-03,  3.34474184e-02,  1.87471509e-03, ...,\n           -2.51899622e-02,  2.68316828e-02,  3.25319208e-02],\n          ...,\n          [-1.36766769e-02,  2.86618806e-02, -4.38702852e-03, ...,\n           -4.88888472e-04, -1.74203366e-02, -2.53194552e-02],\n          [ 1.64840333e-02, -1.56333502e-02, -3.64369228e-02, ...,\n            1.26589648e-02,  3.97500433e-02,  1.41783580e-02],\n          [ 1.42974854e-02, -2.16563176e-02,  2.23808736e-03, ...,\n            4.15416621e-02, -8.85166973e-03,  1.43462792e-02]],\n \n         [[-4.14819568e-02,  3.76418047e-02,  4.42540981e-02, ...,\n            2.70364918e-02,  5.10115549e-03, -1.69819053e-02],\n          [-1.04836114e-02,  1.85449384e-02, -7.59642944e-03, ...,\n           -1.65470298e-02, -3.63329127e-02,  2.64683329e-02],\n          [-3.56931537e-02, -1.97755098e-02, -2.36339290e-02, ...,\n            4.52453829e-02,  1.61828324e-02,  1.55300125e-02],\n          ...,\n          [-3.19579691e-02, -3.14766057e-02,  2.95434482e-02, ...,\n            4.56498452e-02,  3.91304232e-02, -1.94983128e-02],\n          [ 6.64566457e-03, -2.92689707e-02, -3.65742184e-02, ...,\n           -1.61386412e-02,  7.37247244e-03,  1.14655755e-02],\n          [ 2.45657377e-02, -1.73216127e-02, -4.31965217e-02, ...,\n           -5.40051237e-03,  1.11093223e-02, -3.03059276e-02]],\n \n         [[-2.98965573e-02, -9.67254117e-03,  2.29955576e-02, ...,\n            1.71855502e-02,  1.42285302e-02, -4.06740084e-02],\n          [ 1.81379579e-02,  5.65427914e-03, -3.51815373e-02, ...,\n            3.01672779e-02,  2.91834287e-02, -1.34851038e-03],\n          [ 1.71820782e-02,  1.78937428e-02, -1.38256699e-02, ...,\n            6.55908138e-04, -1.99795663e-02, -6.29840791e-03],\n          ...,\n          [-2.86336690e-02,  2.91297100e-02, -7.36410543e-03, ...,\n            2.41074525e-02,  4.52108718e-02, -4.16487455e-03],\n          [ 1.21164694e-02,  1.64884366e-02, -1.76166892e-02, ...,\n           -2.48540398e-02,  1.76124312e-02,  1.75336413e-02],\n          [-5.19704074e-04,  1.09656155e-02, -4.10764255e-02, ...,\n           -2.82554310e-02, -1.22951977e-02,  1.26498826e-02]],\n \n         [[-3.78098711e-02, -4.34925891e-02, -1.27554052e-02, ...,\n            1.90805234e-02, -6.59225881e-03, -3.82025428e-02],\n          [ 1.47113167e-02,  1.48103796e-02, -3.80313545e-02, ...,\n           -1.27142593e-02, -6.10757619e-03, -1.06952824e-02],\n          [-3.78342830e-02,  3.01237591e-02,  3.78583632e-02, ...,\n           -4.61891815e-02,  1.58093721e-02, -2.73638815e-02],\n          ...,\n          [ 2.51489505e-03,  1.92258134e-03,  2.96216272e-02, ...,\n           -4.17347401e-02, -2.45230626e-02,  3.65668125e-02],\n          [-3.05959154e-02,  5.58838993e-03, -3.49736847e-02, ...,\n            3.78802307e-02, -2.46927068e-02,  2.40405761e-02],\n          [ 2.05107071e-02,  1.13749951e-02, -3.65698151e-02, ...,\n           -1.92729346e-02, -3.39029990e-02, -3.91873308e-02]]]],\n       dtype=float32)>,\n <tf.Variable 'conv2d_111/kernel:0' shape=(3, 3, 96, 96) dtype=float32, numpy=\n array([[[[-4.70909700e-02,  1.90388411e-03, -5.33666201e-02, ...,\n           -5.99944964e-03, -5.73956221e-02,  3.88756879e-02],\n          [-1.96767747e-02, -8.21628794e-03, -5.47142811e-02, ...,\n            4.57138382e-02,  2.64451392e-02,  2.38256119e-02],\n          [-1.38033740e-02, -1.90631673e-03,  1.71195753e-02, ...,\n           -2.36202739e-02,  1.23143531e-02, -2.97101848e-02],\n          ...,\n          [-3.60275060e-02,  2.57458128e-02, -2.52791196e-02, ...,\n            4.53747176e-02, -1.47351436e-02, -4.65499870e-02],\n          [ 3.43638659e-03, -2.14150660e-02,  4.73468415e-02, ...,\n           -4.89139482e-02,  5.71172424e-02,  3.50387767e-03],\n          [ 3.23717706e-02,  6.36852905e-03,  5.67634143e-02, ...,\n           -2.35170722e-02,  5.40599115e-02,  4.69920523e-02]],\n \n         [[ 3.80629860e-02,  5.62322401e-02, -3.00159603e-02, ...,\n           -5.12876995e-02, -4.17512879e-02, -3.16002592e-02],\n          [ 5.32902665e-02,  3.71210761e-02, -1.17169097e-02, ...,\n            3.05436663e-02, -7.56943226e-03,  4.85566631e-03],\n          [ 6.05841354e-03, -2.79710367e-02, -1.81678310e-03, ...,\n            5.15978448e-02,  4.32803445e-02, -3.22802141e-02],\n          ...,\n          [-3.66184488e-02,  5.25513664e-03, -2.45220065e-02, ...,\n            2.75588669e-02, -4.02855575e-02, -2.96226144e-03],\n          [ 2.15382874e-03,  4.42392044e-02,  3.33521105e-02, ...,\n           -5.32641038e-02, -5.84176555e-03,  1.28153004e-02],\n          [-8.58358666e-03, -4.54764441e-03,  4.87403832e-02, ...,\n           -4.13937829e-02, -1.10816993e-02,  4.11828943e-02]],\n \n         [[-1.37965865e-02, -4.95813116e-02, -6.00934029e-03, ...,\n           -5.77807426e-02,  2.00800225e-03, -3.61732095e-02],\n          [-2.12192796e-02,  1.96655951e-02,  5.53576536e-02, ...,\n           -5.36825396e-02,  3.62102576e-02,  1.97684206e-02],\n          [-2.16037147e-02, -4.16446254e-02, -1.56408921e-02, ...,\n            2.04522349e-02, -4.90072742e-02,  3.71519960e-02],\n          ...,\n          [-5.84671199e-02, -2.76205577e-02,  1.04984455e-02, ...,\n           -5.86518794e-02,  4.75181676e-02, -3.84264626e-02],\n          [ 2.81124935e-03, -5.23889698e-02,  1.52643360e-02, ...,\n           -1.55836865e-02, -1.26935206e-02,  5.28975539e-02],\n          [ 1.60907842e-02,  5.10953851e-02, -2.03098916e-02, ...,\n           -4.96475957e-02, -2.22439691e-03, -2.49867514e-03]]],\n \n \n        [[[ 2.24665441e-02, -5.39278761e-02,  2.39597671e-02, ...,\n            5.14561310e-03,  5.53336404e-02,  3.85297500e-02],\n          [-3.47260088e-02,  5.82237206e-02,  4.53600697e-02, ...,\n            3.46932076e-02,  4.71095368e-03, -6.98450580e-03],\n          [-4.53880541e-02, -4.53403220e-03, -4.45228368e-02, ...,\n           -8.34641233e-03, -5.23522869e-03, -1.89182162e-02],\n          ...,\n          [-4.65830155e-02,  5.81971668e-02,  3.50513868e-02, ...,\n            6.28270209e-05, -2.13994868e-02,  3.49671580e-02],\n          [ 2.55857520e-02, -4.73205298e-02, -3.44138145e-02, ...,\n           -4.72366996e-02, -1.94911174e-02, -3.10354643e-02],\n          [ 3.48610766e-02, -8.44725221e-03, -1.29378177e-02, ...,\n            2.11687870e-02,  5.42124249e-02, -4.73059751e-02]],\n \n         [[ 1.93280987e-02, -1.19588189e-02,  4.48293276e-02, ...,\n           -3.30461785e-02,  2.13683508e-02,  3.47051024e-03],\n          [ 1.14325024e-02,  2.85326727e-02, -3.90856117e-02, ...,\n           -2.07026713e-02,  2.02005729e-03, -2.71461532e-02],\n          [ 1.01891123e-02,  3.24614346e-04,  7.86908343e-03, ...,\n            1.26923807e-02,  7.18099251e-03,  4.51570041e-02],\n          ...,\n          [ 2.05153041e-02, -1.39743090e-04,  3.36765014e-02, ...,\n           -2.58171074e-02,  2.37692483e-02,  2.15069763e-02],\n          [ 4.57624607e-02,  2.92272232e-02,  5.55716567e-02, ...,\n            1.58816911e-02, -3.17621157e-02,  2.08128244e-03],\n          [ 5.56512550e-03,  3.20938416e-02, -8.66310298e-03, ...,\n            2.57291310e-02, -2.39641927e-02,  2.38433145e-02]],\n \n         [[ 2.40737610e-02, -4.31107059e-02, -5.15584238e-02, ...,\n           -5.60136549e-02,  5.35484590e-02,  5.11896946e-02],\n          [-2.54073851e-02, -4.83591482e-03, -4.86782752e-02, ...,\n            3.87003608e-02, -1.46235377e-02,  1.68838166e-02],\n          [ 4.90772240e-02, -2.93288678e-02, -2.66016573e-02, ...,\n           -6.82027265e-03, -4.57833633e-02, -3.03542875e-02],\n          ...,\n          [-4.13374305e-02,  6.79761544e-03,  2.32297517e-02, ...,\n            1.54194795e-02, -4.70415577e-02, -2.93229260e-02],\n          [ 1.81225948e-02, -3.57374102e-02, -5.13149686e-02, ...,\n            2.61326171e-02,  3.75533588e-02, -4.29561511e-02],\n          [ 2.41161771e-02, -4.01323698e-02, -1.74754038e-02, ...,\n           -5.42519726e-02, -2.59099007e-02,  4.89207171e-02]]],\n \n \n        [[[ 1.99144818e-02,  5.37692644e-02,  5.52449934e-02, ...,\n            2.81199850e-02,  4.29933108e-02, -1.38062276e-02],\n          [-3.47156972e-02,  1.44023933e-02,  4.63455543e-03, ...,\n           -9.03587788e-03, -5.13889231e-02, -2.20730901e-02],\n          [-5.42161167e-02, -3.97090316e-02, -4.68379259e-03, ...,\n            2.01415159e-02,  4.21863385e-02, -4.42961827e-02],\n          ...,\n          [ 1.55007802e-02,  9.04353335e-03, -5.86893335e-02, ...,\n           -4.54486199e-02,  4.77036871e-02,  3.56573723e-02],\n          [ 4.45223711e-02, -2.56063864e-02, -2.21048295e-02, ...,\n           -1.10711195e-02, -5.09014949e-02,  4.41298448e-02],\n          [-5.31276613e-02,  6.96098432e-03, -1.98150463e-02, ...,\n            1.44235902e-02, -2.16039419e-02,  4.39945497e-02]],\n \n         [[-5.31438477e-02,  4.98768315e-03,  4.86360155e-02, ...,\n           -2.17206739e-02, -1.64223388e-02, -2.36162916e-03],\n          [-2.08080523e-02,  5.83048724e-02,  4.21434604e-02, ...,\n           -2.03374140e-02,  4.49200831e-02, -4.78342995e-02],\n          [-4.97138388e-02,  5.68563379e-02,  2.61650868e-02, ...,\n           -2.38385424e-03,  2.66919918e-02, -1.72335953e-02],\n          ...,\n          [ 6.82895258e-03, -5.58395870e-02,  8.45872983e-03, ...,\n            3.47942747e-02, -1.36317797e-02, -2.30784491e-02],\n          [-2.90705506e-02,  5.36703281e-02, -4.54489291e-02, ...,\n            1.08268820e-02,  4.23576422e-02, -5.29858097e-02],\n          [-3.62800062e-03, -3.50743830e-02, -4.17409465e-02, ...,\n            3.52459066e-02,  4.71427925e-02, -2.56299339e-02]],\n \n         [[-5.50547689e-02, -5.47216982e-02, -1.04651339e-02, ...,\n            4.94768433e-02, -2.44949050e-02, -4.81985472e-02],\n          [ 1.43721700e-04,  1.76318847e-02,  1.82198696e-02, ...,\n           -4.13468592e-02, -2.74146721e-02, -6.42471015e-04],\n          [-3.17511857e-02, -1.03362203e-02,  4.07183953e-02, ...,\n            5.14914952e-02, -4.85276058e-03,  3.89846303e-02],\n          ...,\n          [-4.83214185e-02,  5.01445346e-02,  3.76311950e-02, ...,\n            2.01460682e-02, -1.27745979e-02, -4.17375192e-02],\n          [-3.02129257e-02, -4.26594093e-02, -4.60852906e-02, ...,\n           -3.26306820e-02, -4.96027805e-02, -2.79647987e-02],\n          [-5.14286533e-02,  3.29527669e-02,  5.41897900e-02, ...,\n           -5.21909632e-02, -2.47809850e-02, -2.43710652e-02]]]],\n       dtype=float32)>,\n <tf.Variable 'conv2d_112/kernel:0' shape=(1, 1, 256, 64) dtype=float32, numpy=\n array([[[[ 0.0534236 , -0.11960805,  0.03632781, ..., -0.00625075,\n            0.00968412, -0.06672113],\n          [ 0.04596598,  0.09652081,  0.08587554, ..., -0.07201031,\n           -0.00015289, -0.01690993],\n          [-0.08638722, -0.06367871,  0.00272411, ..., -0.12050121,\n            0.12110138, -0.05788083],\n          ...,\n          [-0.10759429, -0.04956223, -0.11066942, ...,  0.04033543,\n           -0.00174572,  0.02061459],\n          [-0.03289839,  0.02842003, -0.13575967, ..., -0.05609617,\n           -0.01993059, -0.11175313],\n          [ 0.11238785, -0.05341469, -0.06982525, ...,  0.01394284,\n            0.12430811,  0.02944419]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_106/beta:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_106/moving_mean:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_106/moving_variance:0' shape=(64,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_108/beta:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_108/moving_mean:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_108/moving_variance:0' shape=(64,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_111/beta:0' shape=(96,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_111/moving_mean:0' shape=(96,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_111/moving_variance:0' shape=(96,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_112/beta:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_112/moving_mean:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_112/moving_variance:0' shape=(64,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_116/kernel:0' shape=(1, 1, 288, 64) dtype=float32, numpy=\n array([[[[ 0.09807967, -0.08274103,  0.05387963, ...,  0.05892596,\n            0.00218935, -0.12044332],\n          [ 0.09667918,  0.00759184, -0.05914087, ..., -0.11931996,\n            0.07447161,  0.08431925],\n          [-0.12237142,  0.06707272, -0.0280306 , ...,  0.07769974,\n           -0.11712351,  0.11014554],\n          ...,\n          [ 0.02538078, -0.01482986, -0.10667478, ...,  0.02885398,\n           -0.09125857, -0.0536807 ],\n          [-0.11136402, -0.09637852, -0.06931651, ..., -0.07962221,\n            0.04975785,  0.03208698],\n          [ 0.03982818,  0.01999618, -0.00910144, ...,  0.0390659 ,\n           -0.09120105, -0.05062544]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_116/beta:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_116/moving_mean:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_116/moving_variance:0' shape=(64,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_114/kernel:0' shape=(1, 1, 288, 48) dtype=float32, numpy=\n array([[[[ 0.01715617,  0.08206119,  0.12233381, ..., -0.0029459 ,\n           -0.03341151,  0.09418999],\n          [-0.05448006,  0.04684064,  0.00765042, ..., -0.05176062,\n            0.01407649,  0.07884072],\n          [ 0.00423403,  0.09865433,  0.11521696, ...,  0.08617747,\n           -0.0313956 , -0.09367025],\n          ...,\n          [-0.11722679,  0.07022727,  0.02754837, ..., -0.09424166,\n           -0.05113664,  0.00187193],\n          [-0.01082447,  0.10110116,  0.12214176, ...,  0.04978243,\n           -0.08240964,  0.01409714],\n          [-0.01421833, -0.09915052,  0.12336679, ..., -0.08307371,\n            0.07114288,  0.0733375 ]]]], dtype=float32)>,\n <tf.Variable 'conv2d_117/kernel:0' shape=(3, 3, 64, 96) dtype=float32, numpy=\n array([[[[-6.03856742e-02, -3.20544317e-02,  4.54989895e-02, ...,\n            4.36535627e-02,  4.24251482e-02,  4.55694944e-02],\n          [-2.06412561e-02,  1.33894458e-02, -3.54269184e-02, ...,\n            3.54586691e-02,  4.29467112e-02,  5.79051077e-02],\n          [ 8.90614092e-03, -4.54523601e-02, -2.07333490e-02, ...,\n           -6.13912791e-02,  4.71106023e-02, -1.15167946e-02],\n          ...,\n          [ 3.07827070e-02,  4.05466110e-02,  5.40320575e-03, ...,\n            4.90741953e-02, -4.72556502e-02, -4.05276716e-02],\n          [ 3.31794173e-02, -2.72962600e-02,  1.69941410e-02, ...,\n            5.70524335e-02,  4.38365191e-02, -4.72148992e-02],\n          [ 3.55869606e-02, -2.23382488e-02, -5.10070510e-02, ...,\n           -6.11819923e-02,  2.19331533e-02,  2.69743800e-03]],\n \n         [[ 5.98276854e-02,  2.54695788e-02, -1.63153820e-02, ...,\n           -2.35042609e-02, -7.62462616e-03, -5.56583330e-03],\n          [ 6.38133213e-02,  8.91115516e-03, -2.25511044e-02, ...,\n            4.19193581e-02, -5.62510528e-02,  2.67752782e-02],\n          [-4.90856431e-02, -2.25569084e-02,  2.06583664e-02, ...,\n            6.06925711e-02, -5.41567244e-02, -3.80402058e-02],\n          ...,\n          [ 1.76937878e-02,  9.61725414e-03, -5.35146892e-02, ...,\n           -5.22282682e-02, -2.09044069e-02, -4.66439053e-02],\n          [ 1.65486634e-02, -3.81418578e-02, -5.02133369e-02, ...,\n           -1.79953538e-02, -2.84292437e-02, -2.67237239e-02],\n          [-1.91934407e-02,  6.35196194e-02,  2.70684436e-02, ...,\n           -1.41751952e-02,  2.88326293e-02,  2.67418250e-02]],\n \n         [[ 1.22625083e-02, -2.19916366e-02, -6.10121191e-02, ...,\n            3.33761871e-02,  2.79435068e-02, -3.68091576e-02],\n          [-3.61166745e-02, -5.69138154e-02,  3.76898423e-02, ...,\n           -6.12269454e-02, -6.32091612e-02, -1.00358576e-03],\n          [-1.64549686e-02, -5.23299798e-02, -9.75033268e-03, ...,\n            1.45977736e-03, -4.44890931e-02,  8.95655900e-03],\n          ...,\n          [ 6.12763241e-02,  4.73536551e-03, -5.60208820e-02, ...,\n           -2.60374695e-03, -1.73164792e-02, -3.08264904e-02],\n          [-1.91568583e-02, -1.74720064e-02, -5.02349883e-02, ...,\n           -7.87763298e-03,  1.29667968e-02, -2.48750038e-02],\n          [-4.56930734e-02, -6.23525754e-02, -3.10679525e-03, ...,\n            1.33049563e-02,  4.64839414e-02,  2.60134786e-03]]],\n \n \n        [[[-3.86814848e-02, -4.03777435e-02,  7.12448359e-03, ...,\n            3.24456543e-02,  3.84380817e-02,  3.68001387e-02],\n          [ 1.57687962e-02,  4.39323336e-02,  2.69493535e-02, ...,\n           -1.02786049e-02,  5.98561093e-02,  2.06026435e-02],\n          [-4.36043739e-03, -1.13797039e-02, -5.57293519e-02, ...,\n            9.99122858e-06,  3.47690359e-02,  3.01304534e-02],\n          ...,\n          [-2.85740457e-02, -5.46092764e-02,  5.57007864e-02, ...,\n           -2.99793705e-02,  6.42785653e-02,  3.68724018e-03],\n          [ 3.26941609e-02, -5.70006743e-02, -6.17068298e-02, ...,\n           -2.20210478e-02, -4.54965308e-02,  3.31927389e-02],\n          [ 3.55432332e-02,  1.84078515e-02, -2.79797539e-02, ...,\n           -4.08400074e-02, -5.93124181e-02, -4.10065427e-02]],\n \n         [[-5.58479615e-02, -4.13806513e-02, -3.84733677e-02, ...,\n           -1.31946132e-02, -1.72015913e-02, -5.63870072e-02],\n          [ 2.35178471e-02,  6.04490340e-02,  1.02201402e-02, ...,\n           -6.14395365e-03, -5.48169166e-02, -2.33465470e-02],\n          [ 5.66236377e-02,  3.17311361e-02, -9.92345437e-03, ...,\n           -1.83417797e-02, -2.59978957e-02,  1.47087127e-02],\n          ...,\n          [-4.43391651e-02,  8.54427367e-03,  2.65673175e-02, ...,\n            1.00986362e-02,  2.63257921e-02, -5.85180223e-02],\n          [-3.30715775e-02,  5.47235012e-02,  6.03562519e-02, ...,\n            6.24659881e-02,  3.30730081e-02, -2.72364542e-02],\n          [ 2.13922039e-02,  4.95761335e-02,  4.94107977e-02, ...,\n            4.96391207e-02,  2.35774070e-02,  2.58009806e-02]],\n \n         [[-3.30135599e-02, -2.32962519e-02,  3.55822295e-02, ...,\n           -4.66430746e-02,  2.73961425e-02, -3.73947546e-02],\n          [ 3.36849242e-02,  3.14532742e-02,  2.29614452e-02, ...,\n            5.27852252e-02, -5.53304143e-02, -2.86751129e-02],\n          [-2.14518085e-02, -4.03495803e-02, -4.01372910e-02, ...,\n           -3.20794396e-02,  3.51577997e-03,  6.16539270e-03],\n          ...,\n          [-1.84175745e-02,  2.24296451e-02,  3.06920484e-02, ...,\n           -4.79182750e-02, -9.56890360e-03,  3.84805724e-02],\n          [ 1.92893222e-02,  4.84039187e-02, -1.62422061e-02, ...,\n            1.18286535e-02,  6.99578226e-03, -5.52341528e-02],\n          [ 2.56434977e-02,  9.48157907e-03, -5.06453440e-02, ...,\n           -4.65846695e-02, -5.94799966e-02, -4.67440486e-03]]],\n \n \n        [[[ 3.00050080e-02, -5.03805317e-02, -3.28732952e-02, ...,\n           -2.14352347e-02,  5.43087423e-02, -4.11562845e-02],\n          [ 1.02939308e-02, -4.65595052e-02,  2.75859758e-02, ...,\n            2.01025829e-02,  1.75383389e-02,  5.83131090e-02],\n          [ 4.73841578e-02,  5.43574095e-02,  5.29209822e-02, ...,\n            3.05810869e-02,  5.15295863e-02, -4.53457870e-02],\n          ...,\n          [ 3.54405418e-02, -3.96625623e-02, -6.29270896e-02, ...,\n            9.82240587e-03, -4.13960889e-02,  5.95421344e-03],\n          [-8.06643814e-03, -5.86234443e-02,  2.16090456e-02, ...,\n           -2.21733786e-02,  2.80486196e-02,  4.68696654e-03],\n          [-2.15539970e-02, -5.99072352e-02, -4.00485843e-02, ...,\n            1.71475410e-02, -4.10439819e-02, -5.01119643e-02]],\n \n         [[ 5.21659702e-02,  8.99042934e-03, -2.72624455e-02, ...,\n           -4.60208952e-03,  1.59297884e-02,  6.87059760e-03],\n          [ 4.77672741e-02, -5.68428226e-02, -2.13400014e-02, ...,\n           -4.14113551e-02, -3.32703702e-02, -5.80781177e-02],\n          [ 3.38793471e-02, -4.96251658e-02,  6.06524944e-03, ...,\n            2.24111378e-02,  5.00925407e-02, -4.06827703e-02],\n          ...,\n          [-5.67366630e-02, -3.08738910e-02, -2.71430053e-02, ...,\n            4.70748171e-02,  4.87961620e-02, -1.09345689e-02],\n          [-4.12741080e-02, -5.63616119e-02, -6.02126606e-02, ...,\n           -1.51683465e-02,  6.43057600e-02, -4.65386361e-02],\n          [-5.11955321e-02, -4.40081134e-02,  1.30610317e-02, ...,\n           -3.05735730e-02, -1.91941187e-02, -4.40360308e-02]],\n \n         [[-5.73307276e-02,  4.70860228e-02, -4.06678542e-02, ...,\n           -5.34760579e-03,  3.21856290e-02,  6.96748495e-04],\n          [-3.38740982e-02,  2.53313780e-02,  3.54515761e-03, ...,\n           -6.16644323e-02,  3.60246599e-02, -3.20332721e-02],\n          [-4.69571799e-02, -5.97474873e-02, -3.07241492e-02, ...,\n            3.02457213e-02,  3.71746942e-02,  8.23834538e-03],\n          ...,\n          [-5.53689227e-02,  3.74045596e-02, -2.69080177e-02, ...,\n            2.21524313e-02,  1.47246271e-02, -3.16762254e-02],\n          [ 5.73145598e-03,  6.36784732e-03, -1.47620253e-02, ...,\n            4.79604155e-02, -3.89247090e-02,  2.17699036e-02],\n          [ 3.33087370e-02, -5.35207242e-02, -2.99685672e-02, ...,\n            1.56494975e-02,  5.07088080e-02,  1.93397477e-02]]]],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_114/beta:0' shape=(48,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_114/moving_mean:0' shape=(48,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_114/moving_variance:0' shape=(48,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_117/beta:0' shape=(96,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_117/moving_mean:0' shape=(96,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_117/moving_variance:0' shape=(96,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_113/kernel:0' shape=(1, 1, 288, 64) dtype=float32, numpy=\n array([[[[-0.05334536, -0.10071374,  0.06867261, ...,  0.02398592,\n           -0.0484495 ,  0.00273325],\n          [-0.07427114,  0.08224072, -0.07100269, ..., -0.13008267,\n            0.07404006,  0.03207481],\n          [-0.03705242, -0.11983378,  0.00330396, ...,  0.10844734,\n            0.06628351,  0.07405004],\n          ...,\n          [ 0.10395013,  0.01147045, -0.12552424, ...,  0.12539564,\n           -0.07932451,  0.11257985],\n          [ 0.05122153, -0.10407464,  0.10012972, ..., -0.11093844,\n            0.05715394, -0.09431113],\n          [-0.0691525 , -0.00049601, -0.04403179, ..., -0.01938848,\n            0.0323616 , -0.07349566]]]], dtype=float32)>,\n <tf.Variable 'conv2d_115/kernel:0' shape=(5, 5, 48, 64) dtype=float32, numpy=\n array([[[[ 1.19757429e-02,  3.80734242e-02, -3.40390950e-04, ...,\n           -1.38916709e-02,  3.29263918e-02, -1.08877942e-02],\n          [ 2.32340731e-02,  4.29712720e-02, -3.70123498e-02, ...,\n            4.57483903e-03,  1.17384344e-02, -2.38448065e-02],\n          [ 3.78871001e-02,  7.37969205e-03,  1.09486952e-02, ...,\n            3.28000076e-02,  4.41763885e-02,  2.26436555e-03],\n          ...,\n          [ 2.39377581e-02,  1.29272118e-02, -2.22226307e-02, ...,\n           -2.66122203e-02,  1.91263668e-02, -4.14627418e-02],\n          [ 1.57951787e-02,  4.29447331e-02, -2.85927225e-02, ...,\n           -3.29638794e-02,  8.40085372e-03,  1.18210539e-02],\n          [ 1.12074986e-03, -2.80436929e-02,  1.56990401e-02, ...,\n           -4.34268229e-02, -1.82205811e-02, -4.45696190e-02]],\n \n         [[-7.43711367e-03,  1.85695775e-02,  2.03197785e-02, ...,\n            5.88681549e-04,  2.48869546e-02,  1.60399601e-02],\n          [ 2.28376575e-02, -3.71631980e-02,  1.84444599e-02, ...,\n           -3.09891291e-02, -1.84967611e-02,  2.16474570e-02],\n          [-1.37162432e-02,  4.42326926e-02, -1.09810233e-02, ...,\n            3.12577747e-02,  4.12968509e-02, -2.28715297e-02],\n          ...,\n          [ 3.26313786e-02, -9.48382542e-03, -4.32552360e-02, ...,\n           -4.54152934e-02,  3.76016609e-02, -4.12708148e-02],\n          [ 6.57330826e-03, -3.90606187e-02,  4.26765271e-02, ...,\n           -2.39670277e-04,  2.67021991e-02, -2.22892910e-02],\n          [-3.67717855e-02,  1.18152909e-02, -2.60839742e-02, ...,\n           -4.38288525e-02, -4.46278714e-02,  4.32647727e-02]],\n \n         [[ 8.22987407e-03, -4.06627394e-02, -3.83562930e-02, ...,\n           -8.25333968e-03, -1.20202079e-03,  1.11574754e-02],\n          [ 4.03628834e-02,  9.01572406e-04,  2.51684152e-02, ...,\n            9.35591012e-03,  2.76090913e-02,  2.84506753e-03],\n          [ 1.75759606e-02, -3.67259048e-02,  1.93922855e-02, ...,\n            2.52989717e-02, -1.38940662e-02, -2.36272179e-02],\n          ...,\n          [ 4.54935804e-03, -3.01381703e-02,  3.79245095e-02, ...,\n            3.50062512e-02,  3.98333482e-02,  1.06072538e-02],\n          [ 1.35295130e-02,  4.51363884e-02,  3.24701145e-03, ...,\n            3.37975435e-02,  1.48150623e-02, -1.15425885e-02],\n          [-4.09049504e-02, -1.09719373e-02,  1.15825310e-02, ...,\n            1.70550980e-02,  3.57943811e-02,  3.99479009e-02]],\n \n         [[ 2.73872912e-03,  2.16060542e-02,  2.51071118e-02, ...,\n           -2.06888579e-02,  2.12072916e-02, -2.91746501e-02],\n          [-4.11962941e-02,  1.00869313e-02,  2.78784297e-02, ...,\n           -3.42612714e-02,  1.16218962e-02, -3.18969712e-02],\n          [-3.24972719e-03, -1.54838040e-02, -8.58483464e-03, ...,\n           -2.24642660e-02, -6.85163215e-03, -2.92249024e-03],\n          ...,\n          [ 2.76425220e-02,  1.33762024e-02, -4.15402092e-02, ...,\n            2.35841088e-02, -1.35366619e-03, -4.01755609e-02],\n          [-4.41475362e-02,  2.70694494e-03,  1.40545592e-02, ...,\n           -2.72673331e-02,  4.33503352e-02, -2.21813526e-02],\n          [ 1.99000128e-02,  4.46068868e-03, -3.26467454e-02, ...,\n            8.33548605e-03, -1.48147978e-02,  2.25479268e-02]],\n \n         [[-1.70805845e-02, -8.47232714e-03,  1.37781687e-02, ...,\n            3.89303751e-02, -1.29887499e-02,  1.20219961e-02],\n          [ 1.23850144e-02,  2.37149633e-02, -3.57566364e-02, ...,\n            2.72464044e-02,  3.36292721e-02,  2.05867253e-02],\n          [-1.26000419e-02,  4.07326259e-02,  6.75017014e-03, ...,\n            4.15307395e-02,  6.23063371e-03, -4.39844690e-02],\n          ...,\n          [-3.06668486e-02,  3.25415395e-02,  1.15764812e-02, ...,\n            1.87907852e-02, -2.86889505e-02,  9.38389823e-03],\n          [-1.35073513e-02, -1.29170716e-03, -1.40507519e-03, ...,\n           -3.72458398e-02, -2.07677688e-02,  1.62546895e-02],\n          [ 3.06095555e-03,  9.73336399e-03, -5.38930297e-04, ...,\n           -4.10267711e-02, -2.62727439e-02, -3.58363986e-02]]],\n \n \n        [[[-3.50325219e-02, -3.27832997e-04, -1.99312251e-02, ...,\n           -1.51220784e-02,  3.76150869e-02, -1.43490732e-03],\n          [ 4.05846126e-02,  3.96757685e-02, -2.93118134e-02, ...,\n            2.62587704e-02, -2.73562539e-02, -1.59720089e-02],\n          [ 2.24252418e-03, -2.24006511e-02, -3.63885164e-02, ...,\n            2.41435319e-03, -2.32499540e-02, -3.99054959e-03],\n          ...,\n          [ 5.27142733e-03,  2.73766927e-02, -1.66216120e-03, ...,\n            6.65725395e-03,  4.00695764e-02,  3.40074636e-02],\n          [-2.35394333e-02,  3.07126828e-02, -2.84206178e-02, ...,\n           -4.43322994e-02,  1.64560601e-03, -3.31643820e-02],\n          [ 3.93392704e-02,  1.45032257e-03,  3.88502292e-02, ...,\n            2.82697566e-02,  1.60185955e-02, -8.42284411e-04]],\n \n         [[ 3.37454192e-02,  4.19148169e-02,  2.38356106e-02, ...,\n           -3.46392989e-02,  2.86902674e-02,  3.00758369e-02],\n          [-3.73519026e-02, -9.89369303e-03,  4.00583446e-03, ...,\n           -3.69175337e-02,  3.97738628e-02,  1.29615515e-03],\n          [-1.46905221e-02, -3.28945145e-02,  5.40653989e-03, ...,\n           -1.78741664e-03,  2.82501318e-02, -2.63208095e-02],\n          ...,\n          [ 3.75313573e-02,  7.29770958e-03, -1.95333008e-02, ...,\n            2.47889124e-02, -3.12141888e-02,  2.91520245e-02],\n          [-3.71135026e-02, -6.73645362e-03, -3.20062041e-04, ...,\n            4.40708175e-03, -4.48622145e-02,  3.60800736e-02],\n          [ 2.69372389e-03, -2.36559659e-04, -1.82347372e-03, ...,\n           -2.56667770e-02, -3.56626809e-02, -3.44159827e-03]],\n \n         [[-3.35258320e-02,  3.58551405e-02, -1.32758245e-02, ...,\n            1.99475698e-02, -1.37360319e-02,  3.16284783e-02],\n          [-3.65168378e-02, -1.10391751e-02,  4.29938547e-02, ...,\n           -3.86464149e-02,  3.60134505e-02,  2.97517143e-02],\n          [ 4.24549468e-02, -4.13013548e-02,  1.50870681e-02, ...,\n            2.73178481e-02,  6.30063936e-03, -1.41072832e-02],\n          ...,\n          [ 2.14605033e-03,  4.06706668e-02, -4.42517772e-02, ...,\n            4.16763015e-02,  3.81892733e-02,  2.43293606e-02],\n          [ 1.05478242e-03, -9.24225524e-03,  3.68756317e-02, ...,\n           -1.21041983e-02, -4.42799181e-04,  1.40101574e-02],\n          [-1.10022128e-02,  3.41339447e-02, -3.35781686e-02, ...,\n            1.86449476e-02, -2.05468051e-02, -5.60518727e-03]],\n \n         [[-2.75180861e-03, -3.74680385e-03, -2.76975073e-02, ...,\n            1.34176761e-03,  2.11069919e-02,  6.36131689e-03],\n          [-2.89404858e-02,  2.74908058e-02,  8.19994509e-03, ...,\n            1.50570497e-02, -2.35826522e-02, -3.46451998e-06],\n          [ 4.88990173e-03, -1.07607320e-02, -3.17994170e-02, ...,\n           -8.41002539e-03,  3.96156050e-02, -4.20406200e-02],\n          ...,\n          [ 1.23231858e-03,  3.65454368e-02,  3.22051011e-02, ...,\n            1.04591995e-02, -5.80134243e-03, -4.37464193e-02],\n          [-4.93030623e-03,  2.24455781e-02,  2.89617851e-03, ...,\n            1.50095150e-02, -2.14873478e-02, -2.20709872e-02],\n          [ 3.83020453e-02,  1.65583976e-02, -8.65539163e-03, ...,\n           -3.97266001e-02,  2.56749615e-03,  1.84952058e-02]],\n \n         [[-1.73152778e-02,  4.12466750e-03, -1.16290934e-02, ...,\n            1.17405951e-02,  4.23662104e-02, -3.51281092e-02],\n          [-1.02464110e-03, -1.16490051e-02, -3.69815156e-02, ...,\n            3.38191204e-02,  9.14753973e-03, -4.58059572e-02],\n          [ 3.89833860e-02, -2.19447725e-02, -2.48544924e-02, ...,\n           -3.51350754e-02,  2.31971107e-02, -4.83205914e-03],\n          ...,\n          [ 1.30154379e-02,  2.69090496e-02,  1.59765892e-02, ...,\n           -1.53530091e-02,  8.75669718e-03, -3.83388884e-02],\n          [-3.82474810e-02,  8.19021091e-03,  1.49568468e-02, ...,\n           -5.28722256e-03, -5.55893406e-03,  4.14547287e-02],\n          [ 1.49524882e-02, -3.28039154e-02, -1.96709372e-02, ...,\n           -3.95821109e-02,  4.99499217e-03, -2.24554911e-02]]],\n \n \n        [[[-9.59804282e-03,  2.07036026e-02, -3.10683399e-02, ...,\n           -3.72031406e-02, -4.70275432e-03,  2.58786790e-02],\n          [-3.86214480e-02,  3.81600372e-02,  1.25397481e-02, ...,\n           -2.53660064e-02, -2.98759844e-02,  1.59051269e-02],\n          [-1.34564638e-02,  2.51115151e-02, -4.20963541e-02, ...,\n            2.98453383e-02, -2.81540602e-02, -1.81776043e-02],\n          ...,\n          [ 3.00707668e-03,  5.23833930e-03, -3.05539332e-02, ...,\n            4.50286157e-02, -3.18774469e-02, -2.74901725e-02],\n          [-1.67360101e-02, -3.90070006e-02,  1.10701844e-03, ...,\n           -7.52596930e-03,  4.38760482e-02, -2.97766551e-02],\n          [-4.05011512e-02,  2.20520012e-02, -8.86522233e-03, ...,\n           -2.40081158e-02, -7.87911937e-03,  3.26828994e-02]],\n \n         [[-2.38698591e-02,  2.02659927e-02,  2.04930790e-02, ...,\n           -2.63561700e-02,  3.28035839e-02, -2.25334335e-02],\n          [-4.12554629e-02, -3.18581648e-02,  4.47228923e-03, ...,\n            3.11708115e-02, -3.75869125e-03,  4.47383039e-02],\n          [ 7.54151121e-03,  7.86587596e-03,  2.49237828e-02, ...,\n            3.35857533e-02, -5.37142158e-03, -3.54917124e-02],\n          ...,\n          [ 3.58915143e-02,  1.99866630e-02, -1.99923459e-02, ...,\n           -5.16511500e-05,  2.18454786e-02,  2.74117775e-02],\n          [-1.53339375e-02, -3.59454155e-02,  1.06061846e-02, ...,\n           -2.41646245e-02,  2.32011266e-02,  2.39465944e-02],\n          [-5.94443083e-03,  3.89497988e-02, -2.85413917e-02, ...,\n            4.18226831e-02, -3.16849016e-02, -4.03756537e-02]],\n \n         [[-8.32267106e-03,  1.19873770e-02,  1.41145997e-02, ...,\n            1.44799240e-02, -4.12227958e-02,  2.22547017e-02],\n          [ 3.77552025e-02,  2.85966881e-02, -2.63081603e-02, ...,\n            3.17482837e-02, -2.65844520e-02, -4.42318879e-02],\n          [-4.95269150e-03, -9.99377295e-03,  4.52845059e-02, ...,\n            2.86290459e-02,  3.62215526e-02,  3.14068012e-02],\n          ...,\n          [ 4.17614467e-02, -1.84107739e-02, -4.53052670e-03, ...,\n           -4.03183401e-02,  5.62119111e-03, -1.37956403e-02],\n          [ 1.05945617e-02, -3.52165140e-02,  4.05723415e-02, ...,\n           -7.36707449e-03,  1.37184039e-02, -2.68258788e-02],\n          [-4.53950055e-02, -1.94973983e-02, -3.03483866e-02, ...,\n           -2.38349605e-02,  2.29593255e-02,  2.34479420e-02]],\n \n         [[-2.39883699e-02,  2.99235769e-02, -3.25685143e-02, ...,\n           -1.68510545e-02, -4.43894379e-02,  3.49825285e-02],\n          [ 3.65246423e-02, -9.66962427e-04, -6.41399622e-03, ...,\n            3.56086455e-02, -1.97674651e-02,  2.62099318e-02],\n          [ 4.20505889e-02, -1.81010980e-02, -1.30031891e-02, ...,\n           -4.35128063e-03,  1.11743622e-02, -2.06328910e-02],\n          ...,\n          [-9.46180522e-03,  3.75068374e-02,  7.64549524e-03, ...,\n           -1.78273004e-02, -1.80193055e-02, -4.24034707e-02],\n          [ 2.22001970e-03,  1.82373784e-02,  9.00416076e-03, ...,\n           -2.50998922e-02,  3.68034504e-02, -7.42294267e-03],\n          [ 4.60625105e-02, -3.96592990e-02,  3.40413786e-02, ...,\n            3.74813937e-02,  5.99782541e-03,  3.31169479e-02]],\n \n         [[ 1.92506053e-02,  2.53142677e-02,  4.51019295e-02, ...,\n           -1.65745094e-02, -2.45157219e-02,  1.48197301e-02],\n          [ 4.53364216e-02,  1.97529159e-02, -2.46578455e-03, ...,\n            1.52872726e-02,  1.93116851e-02,  1.50719732e-02],\n          [-2.80970447e-02, -1.32051259e-02, -1.90809853e-02, ...,\n            9.81762633e-03, -1.72104686e-04, -3.57868224e-02],\n          ...,\n          [ 3.26752663e-03, -4.32476625e-02,  1.32203102e-02, ...,\n            2.50012167e-02, -2.61578523e-02, -3.92456129e-02],\n          [-7.55947828e-03, -3.04878224e-02,  2.50239186e-02, ...,\n            3.50849442e-02, -1.43315233e-02,  1.74396969e-02],\n          [-4.48328555e-02, -1.95402857e-02,  2.60808282e-02, ...,\n            3.66047136e-02,  4.57326323e-03, -3.27503011e-02]]],\n \n \n        [[[-4.56989333e-02, -1.31802373e-02,  1.03723742e-02, ...,\n           -3.57813910e-02, -3.31743173e-02,  4.41072546e-02],\n          [ 3.85971777e-02,  2.19856985e-02,  4.53222878e-02, ...,\n            2.16390826e-02, -1.31336972e-03, -2.46326458e-02],\n          [-3.39969434e-02, -3.72795388e-03, -6.51821494e-03, ...,\n           -3.79331410e-03, -1.75643098e-02,  7.17394054e-04],\n          ...,\n          [-2.06043068e-02, -2.64420137e-02,  2.69155987e-02, ...,\n           -3.29151303e-02,  1.71350501e-02,  2.86682136e-02],\n          [ 2.08678469e-03,  3.35945599e-02, -2.50376668e-02, ...,\n            4.42494117e-02,  2.24940442e-02,  2.17701532e-02],\n          [-2.29528472e-02,  2.37540491e-02,  3.29069458e-02, ...,\n           -1.82853993e-02, -3.40368524e-02, -2.99114734e-03]],\n \n         [[ 7.76086003e-04, -2.86135711e-02, -9.92059708e-04, ...,\n           -9.75631922e-03, -3.78541276e-02,  2.28672810e-02],\n          [-1.52250603e-02,  3.88723873e-02,  7.81575963e-03, ...,\n           -4.99725714e-03, -4.39914130e-02, -2.62224395e-02],\n          [-1.80569738e-02,  3.34284268e-02, -3.26478779e-02, ...,\n            3.48426402e-03, -2.22880337e-02,  4.11249660e-02],\n          ...,\n          [ 6.98280334e-03, -2.79037375e-02, -7.50776008e-03, ...,\n           -7.95845315e-03, -2.96271313e-02, -3.61253358e-02],\n          [-1.30611956e-02,  3.75449918e-02, -8.44940543e-03, ...,\n           -3.51021960e-02, -2.35709324e-02, -7.81917945e-03],\n          [-3.11875343e-02,  1.82721205e-02,  3.35378833e-02, ...,\n           -4.02506776e-02,  2.04729997e-02,  1.58174634e-02]],\n \n         [[-1.21723935e-02,  1.87785588e-02, -1.72956008e-02, ...,\n           -3.12411841e-02,  4.10906933e-02,  3.51336636e-02],\n          [-2.11192649e-02,  2.67945863e-02,  1.21255107e-02, ...,\n            2.62474380e-02,  4.04513367e-02,  2.02852003e-02],\n          [-2.19910145e-02,  2.78534330e-02, -2.07421761e-02, ...,\n           -1.23061910e-02, -2.24591680e-02,  2.53092684e-02],\n          ...,\n          [-2.23334599e-02, -4.15961854e-02, -4.48509902e-02, ...,\n           -3.79537195e-02, -4.25850451e-02,  7.83931464e-04],\n          [ 2.74926312e-02, -4.07477096e-03, -2.09193584e-02, ...,\n            4.01274078e-02, -3.87651883e-02,  3.27640437e-02],\n          [-4.08936590e-02, -4.11214009e-02, -2.35879272e-02, ...,\n           -2.95353495e-02, -1.51485559e-02, -2.28894129e-03]],\n \n         [[-3.90718207e-02, -3.63798514e-02,  2.00822763e-02, ...,\n            3.23056802e-03, -2.36698091e-02, -2.87172478e-02],\n          [ 2.47111730e-02, -3.63472067e-02,  2.82665528e-02, ...,\n            2.67550461e-02,  3.88418622e-02, -3.09085287e-02],\n          [-9.44254920e-03,  1.55987851e-02,  4.22660969e-02, ...,\n           -3.60712036e-02,  1.39902718e-02,  2.41840519e-02],\n          ...,\n          [ 3.04707699e-02,  1.00551546e-03,  3.34518515e-02, ...,\n           -6.11205399e-03, -2.40325928e-03,  3.31117846e-02],\n          [-3.40052098e-02,  1.51638947e-02,  6.23105094e-03, ...,\n            1.20333210e-02,  1.13457926e-02,  4.01363894e-03],\n          [ 4.19326685e-02, -2.10869312e-03,  5.05625829e-03, ...,\n            3.75275053e-02, -3.07224616e-02,  1.69480927e-02]],\n \n         [[ 2.54695974e-02, -3.79334912e-02, -4.19652835e-02, ...,\n           -2.61735469e-02, -3.50456312e-02, -2.57095769e-02],\n          [ 4.02319990e-02, -2.96600871e-02, -1.23010054e-02, ...,\n            1.07143074e-04,  2.46573649e-02, -1.06912553e-02],\n          [-8.38457793e-03,  7.81004131e-03, -3.53986397e-02, ...,\n            4.27138023e-02, -3.91172133e-02, -9.98098403e-04],\n          ...,\n          [ 4.22575884e-02, -2.45977938e-03, -3.23336944e-03, ...,\n           -4.62778062e-02,  2.21161731e-02,  2.54104175e-02],\n          [ 1.00833140e-02,  2.26977654e-02,  9.05565917e-04, ...,\n           -4.58726287e-02, -1.47108957e-02, -3.84724736e-02],\n          [ 1.74637139e-03,  3.17553245e-02,  2.07662694e-02, ...,\n            1.15194879e-02, -4.28580046e-02, -1.11366734e-02]]],\n \n \n        [[[ 3.41719054e-02,  3.10724340e-02,  1.39071085e-02, ...,\n            2.16534920e-02,  1.92478262e-02, -3.63363698e-02],\n          [-2.73015350e-03, -1.74707733e-02, -4.37019095e-02, ...,\n           -4.27401774e-02,  6.55319169e-03, -3.82757038e-02],\n          [-4.36639450e-02,  3.76092009e-02,  3.12184580e-02, ...,\n            1.96323507e-02, -2.56971940e-02, -1.96428932e-02],\n          ...,\n          [ 1.24189295e-02, -3.35024260e-02, -4.55718562e-02, ...,\n           -3.75588983e-02,  5.71080670e-03, -3.41151468e-02],\n          [ 2.75897123e-02,  3.02999839e-03,  1.16301104e-02, ...,\n           -6.31702691e-03, -4.17384468e-02, -1.32829323e-02],\n          [ 3.54669131e-02, -3.71836945e-02,  1.04188807e-02, ...,\n            2.91534923e-02, -3.29507478e-02,  2.70855427e-03]],\n \n         [[ 1.25906914e-02,  3.61468382e-02,  2.33819745e-02, ...,\n            3.67548130e-02, -4.29362208e-02, -1.29963905e-02],\n          [ 4.37062792e-02, -7.07843527e-03,  4.14033420e-02, ...,\n           -4.19002660e-02,  1.98427588e-03, -1.36771500e-02],\n          [ 4.25251164e-02, -1.20230354e-02, -5.73049858e-03, ...,\n           -8.30546394e-03, -9.71227139e-03, -7.78555125e-03],\n          ...,\n          [ 1.10273547e-02,  2.65121087e-03,  1.58130713e-02, ...,\n           -2.19080094e-02, -2.32010279e-02,  3.82168926e-02],\n          [-1.29405335e-02, -3.81331109e-02,  1.13736838e-02, ...,\n            4.21495736e-03, -3.10786702e-02, -2.00240444e-02],\n          [-4.39283699e-02, -3.08852643e-03, -2.80456468e-02, ...,\n           -1.49031319e-02, -3.36297303e-02, -1.27644092e-02]],\n \n         [[-1.73847433e-02, -4.53013293e-02, -9.17107984e-03, ...,\n            2.68042572e-02,  3.50095890e-02, -4.60312925e-02],\n          [-5.87888062e-04,  2.01282389e-02,  2.63950489e-02, ...,\n           -2.03969609e-02,  6.63873553e-03,  1.43982619e-02],\n          [-2.03045513e-02, -1.45988204e-02,  3.63263115e-03, ...,\n           -3.48779559e-02,  2.32763588e-03,  3.11237574e-03],\n          ...,\n          [ 1.04378201e-02, -1.65994633e-02, -2.39653885e-03, ...,\n           -4.33094017e-02,  1.62957124e-02, -2.05947366e-02],\n          [ 1.69059262e-03, -1.57182440e-02,  4.26471233e-05, ...,\n           -1.53046791e-02, -4.16539721e-02, -8.29666853e-03],\n          [ 2.02136748e-02, -2.89187580e-03, -3.43961045e-02, ...,\n           -1.79810524e-02, -3.02901492e-03,  8.86743888e-03]],\n \n         [[-2.64612287e-02,  2.05360353e-04,  3.69431265e-02, ...,\n           -3.85212786e-02,  3.36785354e-02,  1.05307586e-02],\n          [-1.62324179e-02,  2.55491398e-02, -6.92911819e-03, ...,\n           -4.44280542e-02,  2.59163044e-02,  1.64041482e-02],\n          [ 3.93018126e-05, -2.31024045e-02, -3.23795900e-02, ...,\n           -5.00160456e-03, -1.30932033e-02, -2.50449851e-02],\n          ...,\n          [-3.00026201e-02, -3.16050276e-02,  4.18222956e-02, ...,\n            2.31175907e-02,  2.60263421e-02,  1.75569914e-02],\n          [ 1.18513033e-02,  5.27217984e-03, -3.27089466e-02, ...,\n            8.54658335e-03,  3.84862609e-02,  3.82304974e-02],\n          [-4.46023792e-02,  5.40474057e-03,  3.35589536e-02, ...,\n           -2.52396166e-02,  1.04414299e-02,  3.74734774e-03]],\n \n         [[ 1.30081102e-02,  4.61674072e-02, -4.09881994e-02, ...,\n           -1.50394142e-02, -3.03057209e-03, -4.05464582e-02],\n          [-1.57275926e-02, -3.51967029e-02, -9.47684050e-03, ...,\n           -4.15362120e-02, -3.90904620e-02, -3.91078219e-02],\n          [ 1.83964036e-02,  3.40593196e-02,  1.59770735e-02, ...,\n           -4.42220978e-02,  3.49287428e-02,  4.62111123e-02],\n          ...,\n          [-3.17752138e-02, -2.26254016e-02,  1.53332092e-02, ...,\n            5.37996367e-03,  1.16974227e-02,  4.85619530e-03],\n          [-3.75352874e-02,  4.17556353e-02, -2.66244635e-03, ...,\n            2.01957934e-02, -1.18678473e-02,  3.25823538e-02],\n          [ 3.94292735e-02,  1.87418647e-02, -3.59234586e-03, ...,\n           -2.84476355e-02,  2.31778733e-02, -2.06130259e-02]]]],\n       dtype=float32)>,\n <tf.Variable 'conv2d_118/kernel:0' shape=(3, 3, 96, 96) dtype=float32, numpy=\n array([[[[ 0.05840261,  0.03148561, -0.01648431, ...,  0.05140105,\n            0.03464008, -0.02952779],\n          [ 0.03300243,  0.04805141,  0.03327597, ...,  0.0282049 ,\n           -0.03789179, -0.01836827],\n          [ 0.02374758, -0.00606089,  0.03349409, ...,  0.04742817,\n            0.05128646,  0.00591983],\n          ...,\n          [ 0.02231652,  0.01078485,  0.00700839, ..., -0.03257415,\n            0.03667355, -0.03186657],\n          [ 0.01352602, -0.00242548,  0.02770464, ..., -0.01988442,\n           -0.02773546, -0.00040691],\n          [ 0.01400844,  0.03495943,  0.0238121 , ..., -0.03090787,\n            0.02629598, -0.05152074]],\n \n         [[-0.05640448, -0.02946049,  0.01115807, ..., -0.02693241,\n           -0.05794978,  0.03431469],\n          [ 0.02873543, -0.0263399 ,  0.05585806, ..., -0.05423713,\n           -0.00573891,  0.0245095 ],\n          [ 0.03039146, -0.05557233,  0.03964366, ...,  0.05245491,\n           -0.04996539, -0.04601778],\n          ...,\n          [-0.00550963, -0.05101967,  0.035494  , ..., -0.02696889,\n           -0.0306181 , -0.02127219],\n          [-0.00329507, -0.04752165,  0.00558053, ...,  0.02743075,\n           -0.05795852, -0.03011249],\n          [-0.02262374,  0.02500879,  0.00694063, ...,  0.01122   ,\n           -0.0182114 , -0.02226011]],\n \n         [[ 0.02760515, -0.00435818,  0.04723602, ...,  0.02164569,\n            0.0345276 , -0.02883779],\n          [ 0.02242856,  0.02845759, -0.00227964, ..., -0.04053018,\n           -0.01712494,  0.00584963],\n          [ 0.008955  , -0.00630896,  0.02248727, ..., -0.05099368,\n           -0.04982279, -0.04485804],\n          ...,\n          [ 0.03975742,  0.04216121, -0.04770075, ..., -0.05625129,\n            0.01734052,  0.05213493],\n          [-0.049413  , -0.05204237,  0.04443111, ...,  0.03400655,\n           -0.05588061, -0.0369845 ],\n          [ 0.03416096, -0.03123163, -0.03677785, ..., -0.0386812 ,\n           -0.02622782, -0.05791157]]],\n \n \n        [[[-0.05263896, -0.0467884 , -0.04684729, ...,  0.02271601,\n            0.04765112,  0.00815753],\n          [ 0.01904705,  0.00171563, -0.0010118 , ...,  0.0353796 ,\n            0.02002588, -0.02361697],\n          [ 0.03856478, -0.02620487, -0.042642  , ...,  0.03206989,\n           -0.04463971, -0.04328654],\n          ...,\n          [-0.05758909, -0.04016061,  0.01905685, ...,  0.05569385,\n           -0.05299073, -0.034184  ],\n          [-0.01610015,  0.03183674,  0.05792847, ...,  0.05751416,\n           -0.05141775,  0.01438488],\n          [ 0.0208494 ,  0.00300282,  0.05276252, ..., -0.04888133,\n            0.02156629,  0.04660922]],\n \n         [[-0.0168511 ,  0.0444789 , -0.023385  , ..., -0.05725101,\n            0.03637857, -0.04983126],\n          [ 0.04159044, -0.00982269,  0.04525552, ...,  0.00954079,\n           -0.02511946,  0.02569886],\n          [ 0.03562542,  0.04628851, -0.05199303, ...,  0.01971877,\n           -0.05004688,  0.02487407],\n          ...,\n          [ 0.00296763,  0.0366194 , -0.04397092, ..., -0.00910272,\n           -0.04513101, -0.03773489],\n          [-0.0187505 , -0.00364982, -0.00647961, ...,  0.01272455,\n           -0.03785199, -0.05170515],\n          [ 0.05152469,  0.04113518, -0.00956865, ...,  0.03711784,\n            0.00217047, -0.00330907]],\n \n         [[ 0.00303078,  0.03766175,  0.03411395, ...,  0.03270976,\n            0.03637454, -0.02712466],\n          [-0.00863212,  0.02643533,  0.00391304, ...,  0.03057488,\n           -0.01311932, -0.02870661],\n          [-0.00190927, -0.03349224, -0.05534738, ..., -0.03982064,\n            0.02583217, -0.00203607],\n          ...,\n          [ 0.02284282, -0.00888875, -0.01587342, ...,  0.00415745,\n           -0.02449475,  0.02671477],\n          [-0.0497236 , -0.03784765, -0.03659889, ...,  0.03408699,\n            0.01351411,  0.04479738],\n          [ 0.01244567,  0.0307603 ,  0.05311042, ...,  0.03088294,\n            0.00680798, -0.04841674]]],\n \n \n        [[[-0.05635764,  0.030635  , -0.00759739, ..., -0.03124193,\n           -0.04109722,  0.03533376],\n          [ 0.05496989,  0.02303907, -0.05676074, ..., -0.0026156 ,\n            0.0368635 ,  0.04192781],\n          [-0.02499231,  0.01752362, -0.0519845 , ...,  0.00179516,\n           -0.03266666,  0.03978528],\n          ...,\n          [ 0.03860119, -0.01092597,  0.04256542, ...,  0.01884269,\n           -0.0134924 , -0.03516295],\n          [ 0.02418744,  0.04018239,  0.03705047, ...,  0.01197403,\n           -0.03688236,  0.04485714],\n          [-0.0432205 ,  0.00366286,  0.05531392, ...,  0.02869835,\n           -0.0534305 , -0.03054282]],\n \n         [[ 0.01384239, -0.01836535, -0.05111856, ...,  0.05489482,\n           -0.00709434, -0.05536031],\n          [-0.0366646 , -0.04516153, -0.03322231, ..., -0.05442899,\n            0.05434363, -0.03922682],\n          [-0.01793049, -0.00475356,  0.03188547, ...,  0.04272394,\n           -0.00263391,  0.05259313],\n          ...,\n          [-0.00553893,  0.02900482,  0.05067561, ..., -0.04639326,\n            0.01521413,  0.05881326],\n          [-0.0417913 ,  0.03121386,  0.02759558, ..., -0.05309754,\n           -0.03724511, -0.02329786],\n          [-0.03975063, -0.02016919,  0.05206174, ..., -0.03224262,\n           -0.03472388,  0.01751177]],\n \n         [[ 0.03202118,  0.02019126,  0.04966784, ...,  0.05141671,\n            0.02471369,  0.02305271],\n          [-0.00688013, -0.00946947, -0.00722558, ..., -0.04201948,\n            0.03577446,  0.05832953],\n          [ 0.01007586,  0.0564937 ,  0.01722983, ..., -0.01894832,\n            0.0175238 , -0.05544775],\n          ...,\n          [-0.03732265,  0.03494001,  0.01939154, ...,  0.05171772,\n            0.05142833,  0.02588789],\n          [-0.01594029, -0.01936549, -0.00234973, ...,  0.01405395,\n            0.00038146, -0.01146049],\n          [-0.00264734, -0.00808173, -0.01158301, ...,  0.02857763,\n           -0.02756383, -0.02334423]]]], dtype=float32)>,\n <tf.Variable 'conv2d_119/kernel:0' shape=(1, 1, 288, 64) dtype=float32, numpy=\n array([[[[ 0.10898224, -0.00359955,  0.05750954, ...,  0.01306869,\n           -0.03513231, -0.03447761],\n          [ 0.11074993,  0.05242392,  0.0727275 , ...,  0.09394233,\n           -0.02107992, -0.02713391],\n          [ 0.00013152,  0.11079806,  0.10458404, ..., -0.08516403,\n           -0.09650054, -0.02304945],\n          ...,\n          [-0.07207556, -0.03600843, -0.02726203, ...,  0.05627981,\n           -0.02554993,  0.04873379],\n          [ 0.11924183,  0.05864249,  0.04967126, ..., -0.06846667,\n            0.05685028, -0.12477403],\n          [ 0.09695943, -0.12861675,  0.07345435, ..., -0.05559946,\n            0.04093479, -0.11621359]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_113/beta:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_113/moving_mean:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_113/moving_variance:0' shape=(64,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_115/beta:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_115/moving_mean:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_115/moving_variance:0' shape=(64,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_118/beta:0' shape=(96,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_118/moving_mean:0' shape=(96,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_118/moving_variance:0' shape=(96,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_119/beta:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_119/moving_mean:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_119/moving_variance:0' shape=(64,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_121/kernel:0' shape=(1, 1, 288, 64) dtype=float32, numpy=\n array([[[[ 0.08093771,  0.12724347,  0.06366163, ..., -0.04595852,\n            0.1133965 , -0.02230183],\n          [-0.00880846,  0.03391442, -0.09642254, ...,  0.00607339,\n           -0.09785642,  0.1177121 ],\n          [-0.09836464,  0.10820492,  0.11803433, ..., -0.1288297 ,\n           -0.02208403,  0.03568691],\n          ...,\n          [ 0.08017305, -0.05965491,  0.09391443, ..., -0.04885083,\n           -0.02437987, -0.11807788],\n          [-0.05508135,  0.01064844,  0.1235107 , ...,  0.03592855,\n           -0.10644905,  0.02952808],\n          [ 0.02944323, -0.12419042, -0.05003174, ..., -0.10726907,\n           -0.0022812 , -0.02792804]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_121/beta:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_121/moving_mean:0' shape=(64,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_121/moving_variance:0' shape=(64,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_122/kernel:0' shape=(3, 3, 64, 96) dtype=float32, numpy=\n array([[[[ 0.05462702,  0.05462905, -0.0552513 , ..., -0.01751719,\n           -0.05979929, -0.06167016],\n          [ 0.04402778, -0.00460748, -0.06070641, ..., -0.01612329,\n           -0.05778306, -0.05177581],\n          [-0.05478404, -0.01447323,  0.04987328, ...,  0.03558704,\n            0.03030244,  0.02387396],\n          ...,\n          [ 0.05259947,  0.02128514,  0.02588821, ...,  0.0195487 ,\n            0.02934686, -0.01392937],\n          [ 0.02733789,  0.00394198,  0.0025021 , ..., -0.01135283,\n            0.05045352, -0.00346264],\n          [-0.06122113,  0.05670252, -0.0462731 , ...,  0.04086774,\n            0.05958352, -0.0035246 ]],\n \n         [[ 0.06349451, -0.01702273, -0.04574876, ..., -0.00816846,\n           -0.05611319, -0.03874068],\n          [-0.0283898 , -0.04323573, -0.02365082, ..., -0.05509046,\n            0.01486989, -0.04493438],\n          [ 0.00906185,  0.05207428, -0.04651969, ..., -0.05285363,\n           -0.00839352,  0.05725501],\n          ...,\n          [ 0.01760671,  0.05694849, -0.04912129, ...,  0.04366038,\n            0.04820295, -0.0186113 ],\n          [-0.05756595,  0.02478022, -0.03907733, ...,  0.00949817,\n           -0.06059251,  0.02747691],\n          [-0.03900823, -0.00253806,  0.00494622, ...,  0.02953602,\n           -0.05460629, -0.03826034]],\n \n         [[ 0.01150248,  0.03093782, -0.04844303, ...,  0.04289792,\n           -0.03790189,  0.00091199],\n          [-0.05797444, -0.00552038, -0.03763681, ..., -0.0544626 ,\n            0.04287987,  0.0423796 ],\n          [-0.00895465,  0.03232386,  0.01302505, ...,  0.00653756,\n            0.0439603 ,  0.00017986],\n          ...,\n          [ 0.01556898,  0.03125382, -0.04346447, ...,  0.03721029,\n            0.01337429, -0.03493802],\n          [-0.01530138,  0.06261753, -0.02952791, ...,  0.05250339,\n           -0.02198184,  0.02397427],\n          [ 0.01742534, -0.0022217 , -0.06382465, ...,  0.04780835,\n           -0.04539463,  0.00298054]]],\n \n \n        [[[-0.05565339, -0.04068264,  0.04388352, ...,  0.00509867,\n            0.01823756, -0.05343991],\n          [-0.00718227,  0.04227573,  0.00719205, ..., -0.01235913,\n            0.00340474, -0.00033224],\n          [-0.05814029, -0.01313293, -0.0542912 , ...,  0.05402811,\n            0.0320719 ,  0.00726689],\n          ...,\n          [-0.00083447,  0.0487602 , -0.06352348, ...,  0.03552709,\n            0.00869599,  0.03260317],\n          [ 0.02018524, -0.04674162,  0.02770443, ..., -0.02233599,\n           -0.03543435,  0.02203105],\n          [ 0.02092484,  0.01774149,  0.01268747, ...,  0.0432665 ,\n            0.02006005,  0.05378652]],\n \n         [[ 0.01092421,  0.0085782 , -0.01206749, ...,  0.02429819,\n            0.01104878,  0.01993121],\n          [ 0.03475747, -0.00217128,  0.0416549 , ..., -0.01615337,\n           -0.00566147,  0.05638665],\n          [ 0.00837108,  0.0473274 ,  0.03809858, ...,  0.00761222,\n            0.05230243, -0.05039846],\n          ...,\n          [-0.0631811 ,  0.03556716,  0.05249516, ...,  0.04789938,\n           -0.05750777,  0.0298076 ],\n          [-0.01648195, -0.04690884, -0.02830983, ...,  0.04147827,\n            0.06244766, -0.04714668],\n          [-0.05048406,  0.06225859, -0.00765914, ...,  0.03603899,\n            0.05223382, -0.00410474]],\n \n         [[ 0.00323308,  0.02890084,  0.01366953, ...,  0.04847457,\n           -0.03430517, -0.02912659],\n          [ 0.02869102,  0.03330358, -0.01342829, ..., -0.02434205,\n            0.02128735,  0.01714621],\n          [ 0.00696605, -0.02296055,  0.03423718, ..., -0.02029363,\n           -0.04529525,  0.00700144],\n          ...,\n          [-0.01193015, -0.00420206, -0.04748277, ..., -0.05502778,\n           -0.01644474,  0.01892704],\n          [-0.03014284,  0.02837837,  0.03461295, ...,  0.01325451,\n           -0.04499724,  0.05814794],\n          [ 0.05021097, -0.03045715, -0.05845756, ..., -0.05310561,\n            0.00557832, -0.0151072 ]]],\n \n \n        [[[-0.03813347,  0.02454777, -0.0376186 , ..., -0.0431581 ,\n            0.01284679, -0.01605873],\n          [ 0.05452482,  0.00852053, -0.0375885 , ...,  0.06448241,\n           -0.03375138,  0.02891436],\n          [-0.03889844,  0.06121822,  0.0089801 , ..., -0.02410545,\n            0.05745693,  0.01341678],\n          ...,\n          [-0.03168054, -0.04983371,  0.06358687, ..., -0.02209527,\n            0.02190727,  0.02105235],\n          [-0.00104096, -0.04273688,  0.05992477, ...,  0.00817534,\n           -0.06103057, -0.03974313],\n          [ 0.05217202, -0.04911084, -0.0642296 , ..., -0.02654988,\n           -0.05651602,  0.05770953]],\n \n         [[ 0.02212882,  0.06348889,  0.03886265, ..., -0.05146945,\n           -0.02393271,  0.03626273],\n          [-0.01466499, -0.01425394,  0.01559177, ..., -0.030483  ,\n           -0.04248201, -0.01734347],\n          [-0.03065512,  0.04139158, -0.03492679, ..., -0.00612456,\n           -0.05199426, -0.02639792],\n          ...,\n          [ 0.01322746,  0.01044029, -0.01274148, ...,  0.01777876,\n            0.01010896, -0.06300932],\n          [ 0.03074104,  0.01162143, -0.05572787, ...,  0.03092754,\n           -0.04552303, -0.0569608 ],\n          [-0.05090035,  0.04768468,  0.00801391, ..., -0.01027688,\n            0.03350405, -0.00383192]],\n \n         [[-0.03480291,  0.03306171,  0.00876541, ...,  0.01449881,\n            0.05219603, -0.01100624],\n          [ 0.0109532 , -0.04004584, -0.03852215, ...,  0.00043438,\n            0.01385912,  0.02418057],\n          [-0.05750176,  0.05914291,  0.04250305, ..., -0.05346125,\n            0.00248726,  0.04950779],\n          ...,\n          [-0.00219193,  0.00899517, -0.03712476, ...,  0.02684104,\n           -0.04643593, -0.018096  ],\n          [ 0.02509677,  0.0061988 ,  0.05210264, ..., -0.02528451,\n           -0.00623888,  0.00260093],\n          [-0.05013369,  0.03084891,  0.02874111, ...,  0.03355259,\n            0.01604129, -0.05263602]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_122/beta:0' shape=(96,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_122/moving_mean:0' shape=(96,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_122/moving_variance:0' shape=(96,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_120/kernel:0' shape=(3, 3, 288, 384) dtype=float32, numpy=\n array([[[[-2.87517980e-02, -3.03667579e-02,  8.88074189e-03, ...,\n            1.34756491e-02, -2.79897824e-02, -2.67639346e-02],\n          [-2.71859597e-02, -1.09122265e-02, -3.54848430e-03, ...,\n           -1.79434419e-02, -1.36512499e-02,  1.69277862e-02],\n          [-1.03836190e-02, -2.79211681e-02,  2.98711471e-02, ...,\n            1.97261795e-02,  1.18054785e-02,  2.80857235e-02],\n          ...,\n          [-2.64752693e-02, -3.75572406e-03, -6.05742447e-03, ...,\n            2.05320269e-02,  1.36681758e-02, -2.93044206e-02],\n          [ 2.58260220e-02, -6.11188263e-03, -5.65735623e-03, ...,\n           -2.58729719e-02, -1.17161628e-02, -1.31699741e-02],\n          [ 1.66524723e-02, -1.49342362e-02, -2.07950175e-03, ...,\n            1.44516304e-03,  1.65078938e-02, -1.69947483e-02]],\n \n         [[ 1.38589181e-02,  2.87734419e-02, -2.11420376e-02, ...,\n            2.36539729e-02,  3.60752270e-03, -2.79480964e-03],\n          [ 1.64621919e-02, -1.30103976e-02,  7.35386088e-03, ...,\n           -1.43437590e-02, -2.64831241e-02,  2.29915641e-02],\n          [-3.08294389e-02,  2.89151296e-02,  1.67636052e-02, ...,\n           -2.31706798e-02,  2.50243545e-02, -3.87843512e-03],\n          ...,\n          [ 2.93830037e-03, -1.99526548e-05, -1.90993622e-02, ...,\n            8.12740996e-03, -1.97423920e-02, -2.04510540e-02],\n          [ 1.05547681e-02,  2.55386792e-02, -1.79179031e-02, ...,\n           -4.65855002e-03, -2.33691018e-02,  5.99230081e-03],\n          [ 1.48770139e-02,  3.13984379e-02,  2.51449570e-02, ...,\n            9.60005820e-03, -7.46483542e-03, -2.41037533e-02]],\n \n         [[-2.12535914e-02,  8.86057690e-03, -1.98436044e-02, ...,\n            9.34385881e-03,  7.06370920e-03, -2.71241572e-02],\n          [-1.97408292e-02, -4.93807532e-03, -1.55735780e-02, ...,\n           -6.38395175e-03,  2.44388431e-02, -2.68363338e-02],\n          [-1.95951387e-02,  4.80801240e-03, -8.80185328e-03, ...,\n           -2.06687301e-02,  1.35589764e-03, -1.25687514e-02],\n          ...,\n          [ 2.00202502e-02, -3.11105717e-02,  2.78231837e-02, ...,\n           -9.95032303e-03,  2.99332142e-02,  1.15366839e-02],\n          [ 1.55736245e-02,  1.37410536e-02, -1.01689231e-02, ...,\n           -5.36229461e-03, -8.28678533e-03,  1.20183825e-03],\n          [-1.16737783e-02,  2.51960531e-02, -2.21297294e-02, ...,\n           -3.00810672e-02, -2.99640018e-02, -2.83950157e-02]]],\n \n \n        [[[-1.17231458e-02, -2.23718584e-02,  1.35286562e-02, ...,\n            2.82421298e-02, -2.10888404e-02,  2.54342742e-02],\n          [ 2.67748833e-02,  2.77329721e-02, -2.04988495e-02, ...,\n           -3.09322290e-02, -1.34745222e-02, -2.14570463e-02],\n          [-1.22690257e-02, -2.90192403e-02, -1.12821590e-02, ...,\n            1.47620663e-02, -2.01161224e-02,  1.46218874e-02],\n          ...,\n          [ 3.12412828e-02, -2.34526582e-02,  1.51013844e-02, ...,\n            2.66037211e-02,  9.95470956e-03,  2.48197168e-02],\n          [-2.67084762e-02,  2.99145281e-03, -6.21998869e-03, ...,\n           -1.29606109e-02,  2.71911919e-02,  1.97861195e-02],\n          [-1.50103681e-02,  2.39824317e-02, -1.54635571e-02, ...,\n            2.10187696e-02, -1.58649459e-02, -9.16863047e-03]],\n \n         [[ 4.38293815e-03,  2.44367607e-02, -1.48950815e-02, ...,\n           -1.75544582e-02, -2.37407908e-02, -2.45609079e-02],\n          [ 1.92512944e-03,  9.93438065e-04,  3.09181325e-02, ...,\n           -1.82660799e-02,  1.59912035e-02,  1.01414472e-02],\n          [-5.07797673e-03, -1.84454583e-03,  2.79869884e-02, ...,\n            1.69887021e-02,  1.67103633e-02,  3.66863608e-03],\n          ...,\n          [-8.97391699e-03,  6.70517609e-03,  2.92851962e-02, ...,\n            3.13736349e-02, -1.60022564e-02, -5.74876182e-03],\n          [-2.73095816e-03,  2.70748660e-02,  1.64589696e-02, ...,\n           -8.83278437e-03,  2.01725252e-02,  1.77480243e-02],\n          [-1.25515647e-03,  3.13316882e-02,  2.39762217e-02, ...,\n           -1.34213623e-02,  1.02926493e-02, -9.34670307e-03]],\n \n         [[ 5.05658239e-03, -2.19323579e-02, -9.29438509e-03, ...,\n            2.18230262e-02, -1.23686008e-02,  1.10630468e-02],\n          [-2.28752494e-02,  2.31147707e-02,  1.79320648e-02, ...,\n           -1.73284840e-02,  3.04082185e-02,  1.33434646e-02],\n          [ 3.03168967e-03,  2.39751749e-02,  1.65373459e-02, ...,\n           -2.24964246e-02, -2.89582722e-02,  4.54194844e-04],\n          ...,\n          [ 1.45197958e-02,  4.90031019e-03,  2.35186145e-02, ...,\n            4.15393710e-03, -1.70156322e-02,  2.60369256e-02],\n          [ 2.62582228e-02, -8.66564550e-03,  7.38917664e-03, ...,\n           -2.00373121e-02, -2.76902877e-02, -1.06348041e-02],\n          [-2.35075019e-02, -1.18332114e-02, -1.83929764e-02, ...,\n            2.24778242e-02, -4.27996740e-03, -1.78066418e-02]]],\n \n \n        [[[-1.82164870e-02,  3.13556641e-02,  1.34327151e-02, ...,\n           -2.08201148e-02, -1.84927136e-04, -3.32383066e-03],\n          [-1.90293361e-02, -3.12601589e-02, -2.31112037e-02, ...,\n           -3.38328257e-03, -1.55209228e-02,  1.30414516e-02],\n          [ 5.65253198e-04, -7.62788951e-03,  5.15113398e-03, ...,\n           -2.68747285e-02, -2.87001636e-02,  1.85390636e-02],\n          ...,\n          [-2.76122950e-02,  1.68988369e-02,  3.05604190e-02, ...,\n            2.87997536e-02, -5.31622395e-03,  2.56276987e-02],\n          [ 1.26164667e-02, -2.17419323e-02,  7.34904781e-03, ...,\n            2.68138498e-02, -1.84413213e-02, -1.05658602e-02],\n          [-6.10982440e-03, -1.85549706e-02, -1.12599302e-02, ...,\n           -9.80834104e-03,  2.01275386e-02, -2.57996731e-02]],\n \n         [[ 2.32293494e-02, -1.89704690e-02, -2.10741609e-02, ...,\n           -2.94040348e-02, -2.38611829e-02,  1.10472329e-02],\n          [-2.36917995e-02, -5.60697541e-03, -1.49871968e-03, ...,\n            7.94256479e-03,  2.20808424e-02, -2.47365236e-03],\n          [ 2.62091868e-02,  1.70039833e-02, -4.88576479e-03, ...,\n            1.05863325e-02, -2.60062199e-02, -1.25088170e-02],\n          ...,\n          [ 2.11080946e-02, -7.14844652e-03, -3.69145721e-03, ...,\n            3.05216610e-02,  1.56752653e-02, -1.23892520e-02],\n          [ 1.84372365e-02,  9.55119357e-03, -3.37071158e-03, ...,\n           -1.71218608e-02, -1.23273432e-02,  3.08632925e-02],\n          [-2.97269262e-02, -1.20525714e-02, -2.96877194e-02, ...,\n           -1.12272874e-02, -3.98613699e-03,  1.55853927e-02]],\n \n         [[-1.25387795e-02, -8.45077075e-03,  1.41405761e-02, ...,\n           -4.20830399e-03, -3.14221829e-02,  2.60169730e-02],\n          [-4.52798232e-03,  4.70936671e-03,  2.71956623e-02, ...,\n           -1.36919431e-02, -6.88022189e-03,  2.47879289e-02],\n          [ 6.62449375e-03,  2.66042985e-02,  9.26297903e-03, ...,\n           -1.87599100e-02, -1.07719880e-02,  1.96220949e-02],\n          ...,\n          [ 2.97623426e-02,  2.83449665e-02, -5.67846559e-03, ...,\n           -8.14419612e-03,  7.87017494e-03,  1.17114931e-03],\n          [-6.26041181e-03,  4.52666730e-03,  3.38189304e-04, ...,\n            1.97796524e-02, -9.72467102e-03, -2.13594064e-02],\n          [-2.98449527e-02, -7.93430582e-03, -2.05347240e-02, ...,\n            2.43871100e-02, -5.04443236e-03, -1.81938764e-02]]]],\n       dtype=float32)>,\n <tf.Variable 'conv2d_123/kernel:0' shape=(3, 3, 96, 96) dtype=float32, numpy=\n array([[[[-0.04065076,  0.00160165, -0.02078212, ..., -0.03611872,\n           -0.04009058,  0.02671187],\n          [-0.05652095,  0.04029357,  0.04120009, ..., -0.05080378,\n           -0.04492805, -0.05821622],\n          [ 0.01563512, -0.05784492, -0.02925021, ..., -0.02601291,\n            0.05239576, -0.04401042],\n          ...,\n          [ 0.03952334, -0.03399202,  0.00875318, ..., -0.02420767,\n           -0.04016936, -0.01355124],\n          [-0.02965834, -0.0336577 ,  0.05401421, ...,  0.02458496,\n            0.01614491,  0.02226497],\n          [ 0.00493961,  0.01192397, -0.05281082, ...,  0.05089794,\n            0.05742054,  0.04584478]],\n \n         [[ 0.01560012, -0.00786793,  0.01273916, ..., -0.01372501,\n           -0.03529231, -0.00406283],\n          [-0.01361734,  0.04176443, -0.02579734, ..., -0.03289306,\n            0.03453251, -0.04589432],\n          [ 0.02914875,  0.02615571,  0.01805835, ..., -0.04295564,\n            0.05621504,  0.00879966],\n          ...,\n          [ 0.04931859,  0.00956922,  0.00973179, ..., -0.00204556,\n            0.02245433, -0.00865011],\n          [-0.02270895,  0.03374726,  0.0554269 , ..., -0.01500373,\n            0.0387953 ,  0.05809518],\n          [-0.01563113, -0.01731503,  0.04514637, ...,  0.0025424 ,\n           -0.00326125,  0.01579807]],\n \n         [[-0.05547287,  0.02153448, -0.01880823, ...,  0.02512563,\n            0.02459816, -0.0530031 ],\n          [ 0.02212221,  0.05341416, -0.05604859, ...,  0.016712  ,\n            0.02989804, -0.02002342],\n          [-0.01189888,  0.05654229,  0.05370936, ..., -0.05037304,\n           -0.02884078,  0.00171002],\n          ...,\n          [ 0.04134016,  0.02912731, -0.02434289, ...,  0.0565958 ,\n           -0.03736713, -0.04442161],\n          [ 0.02637596,  0.04867777,  0.02818281, ..., -0.03037528,\n            0.05553801,  0.00987078],\n          [ 0.04162608, -0.00729908,  0.05599619, ...,  0.00435938,\n            0.00465106, -0.05633383]]],\n \n \n        [[[ 0.0046354 ,  0.01942359, -0.0257099 , ..., -0.03141082,\n           -0.00810643, -0.02764772],\n          [-0.0517091 ,  0.01580306,  0.05631933, ..., -0.00320971,\n            0.03722322,  0.0169252 ],\n          [ 0.02958716, -0.04879329,  0.03317888, ..., -0.04451131,\n            0.01134578, -0.0356279 ],\n          ...,\n          [-0.0041773 , -0.05347981, -0.01467514, ...,  0.01586277,\n           -0.00238283,  0.02344581],\n          [ 0.02179599, -0.05516   ,  0.04265672, ..., -0.00131775,\n            0.00915005, -0.0264965 ],\n          [ 0.04158027, -0.05484921, -0.05563634, ..., -0.01794766,\n           -0.03882448,  0.05036543]],\n \n         [[ 0.00133385,  0.05316148,  0.05800276, ..., -0.04147454,\n            0.00546336, -0.03618865],\n          [-0.05108707,  0.04885828,  0.03701668, ..., -0.02580326,\n            0.03135269,  0.03114072],\n          [-0.05088277,  0.04677528,  0.00718484, ..., -0.04850797,\n           -0.04206482, -0.01781883],\n          ...,\n          [-0.02210519,  0.04465321,  0.05758722, ..., -0.01830752,\n            0.00013944, -0.02883158],\n          [ 0.00647983,  0.0053747 , -0.03035054, ..., -0.02983841,\n           -0.03082879,  0.05417486],\n          [ 0.01041928, -0.0427907 ,  0.02823414, ..., -0.00386697,\n           -0.01962145,  0.00902726]],\n \n         [[ 0.03220912, -0.03987595,  0.02398351, ...,  0.05041803,\n           -0.05281455,  0.01210278],\n          [ 0.05709613, -0.04945029,  0.03104176, ..., -0.01117586,\n            0.03548854, -0.02715769],\n          [-0.03121473, -0.02569331, -0.04810994, ..., -0.02470942,\n           -0.02667454, -0.02448694],\n          ...,\n          [ 0.01520637, -0.00166615,  0.03070349, ..., -0.04195956,\n           -0.01770939,  0.02338862],\n          [-0.04269026,  0.01929593,  0.05737112, ...,  0.00781061,\n            0.03428015, -0.05641536],\n          [-0.04209829,  0.05798597, -0.05495743, ..., -0.01222413,\n           -0.04207898,  0.00284986]]],\n \n \n        [[[-0.05765337,  0.0242662 ,  0.03372477, ..., -0.02819388,\n           -0.00136836, -0.03550849],\n          [ 0.00071009, -0.04739453, -0.04439035, ..., -0.03486917,\n            0.02126789,  0.02467902],\n          [ 0.00084809,  0.04013338,  0.05302933, ..., -0.02395894,\n           -0.01670358,  0.00676037],\n          ...,\n          [ 0.02708839, -0.01162766, -0.0285725 , ..., -0.03555612,\n           -0.05157901, -0.04918772],\n          [-0.0172869 , -0.04510184,  0.03734913, ...,  0.0561771 ,\n           -0.01556562,  0.00345809],\n          [-0.02514971, -0.01889428, -0.01204756, ..., -0.03762859,\n            0.03334496, -0.0349565 ]],\n \n         [[ 0.01796313,  0.02025108,  0.04536114, ..., -0.00410956,\n           -0.00682074, -0.05016567],\n          [ 0.05117648,  0.0389778 , -0.05186958, ..., -0.01419041,\n            0.02005205, -0.00517469],\n          [ 0.05419524,  0.00111283,  0.02238294, ..., -0.02346978,\n            0.05631714,  0.03898684],\n          ...,\n          [ 0.05687398, -0.02945163,  0.01874303, ..., -0.04024292,\n           -0.04998053,  0.05863277],\n          [ 0.05361162,  0.0305289 ,  0.05576052, ...,  0.01468312,\n            0.03041246,  0.0090998 ],\n          [-0.0330011 ,  0.03984851,  0.00028979, ...,  0.05673614,\n           -0.05493148,  0.05734168]],\n \n         [[ 0.05407318, -0.05704174,  0.01166407, ...,  0.02283188,\n           -0.03219292,  0.0450243 ],\n          [-0.01930954, -0.03904516,  0.0207159 , ...,  0.01543061,\n           -0.04801149, -0.03768563],\n          [ 0.03065933,  0.00725526, -0.05421704, ..., -0.00347421,\n            0.0268607 ,  0.04266537],\n          ...,\n          [-0.0402621 ,  0.04352928, -0.03220445, ...,  0.05281326,\n            0.04873127,  0.00419593],\n          [-0.02387778,  0.02060078,  0.02740988, ...,  0.05059865,\n            0.04445961, -0.02626694],\n          [-0.01585271,  0.0136281 ,  0.00731746, ...,  0.02733151,\n           -0.01810484,  0.03767692]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_120/beta:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_120/moving_mean:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_120/moving_variance:0' shape=(384,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_123/beta:0' shape=(96,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_123/moving_mean:0' shape=(96,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_123/moving_variance:0' shape=(96,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_128/kernel:0' shape=(1, 1, 768, 128) dtype=float32, numpy=\n array([[[[ 0.0341447 ,  0.03185483,  0.01449662, ..., -0.01721186,\n           -0.02139252, -0.06920453],\n          [ 0.01524972, -0.04308047,  0.07101889, ...,  0.07690735,\n            0.01905836, -0.0201906 ],\n          [-0.00419774,  0.07104813, -0.07024634, ...,  0.01210231,\n            0.00681189, -0.00784811],\n          ...,\n          [ 0.00449803, -0.01388486, -0.05864895, ..., -0.02372924,\n           -0.02298647,  0.05539799],\n          [-0.07668293,  0.04795127, -0.03961581, ..., -0.04924341,\n            0.01224269,  0.02389055],\n          [-0.03737021, -0.03792305, -0.02325196, ..., -0.022853  ,\n            0.04737324,  0.07658768]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_128/beta:0' shape=(128,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_128/moving_mean:0' shape=(128,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_128/moving_variance:0' shape=(128,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_129/kernel:0' shape=(7, 1, 128, 128) dtype=float32, numpy=\n array([[[[ 0.04911961, -0.03890683,  0.02556787, ...,  0.05605531,\n            0.0433485 , -0.01853113],\n          [-0.04496971,  0.01699576,  0.01944225, ...,  0.0037354 ,\n            0.05286612,  0.05202419],\n          [-0.03509644, -0.01731855, -0.00417944, ...,  0.05379651,\n            0.01037118, -0.02092818],\n          ...,\n          [ 0.02986639, -0.03966403,  0.0058365 , ..., -0.00572876,\n            0.00531285,  0.02500394],\n          [-0.01700144,  0.02866513,  0.0416745 , ...,  0.05283599,\n           -0.03017271, -0.03665664],\n          [-0.00575821,  0.00727218, -0.04152596, ..., -0.03427848,\n           -0.01678287,  0.01992382]]],\n \n \n        [[[-0.01376434, -0.00483507, -0.00091684, ..., -0.03744586,\n           -0.05596624, -0.03821012],\n          [ 0.04401626, -0.04966609, -0.03088658, ..., -0.00299704,\n            0.03054218, -0.01407539],\n          [-0.02137638,  0.04307187,  0.04117619, ...,  0.05643843,\n            0.01427862,  0.00786799],\n          ...,\n          [-0.05411115,  0.05456504,  0.05558417, ...,  0.0537175 ,\n            0.01436839, -0.04572467],\n          [-0.01482551,  0.00205491, -0.05388149, ...,  0.01834331,\n            0.02314812,  0.04946921],\n          [ 0.0259655 , -0.04115529, -0.03616736, ..., -0.00661134,\n            0.03420405,  0.01343852]]],\n \n \n        [[[ 0.0099743 , -0.0221219 ,  0.01147534, ...,  0.05731294,\n           -0.02334404, -0.00621403],\n          [ 0.00069622,  0.01885925,  0.04193626, ...,  0.0387283 ,\n            0.04134189,  0.01683091],\n          [ 0.02651068,  0.04884015, -0.0551541 , ..., -0.02607603,\n            0.03765802, -0.00038072],\n          ...,\n          [ 0.01481353, -0.01873098, -0.05136282, ..., -0.0436094 ,\n            0.02971758, -0.04010087],\n          [-0.05559589, -0.01432562,  0.03701515, ...,  0.04036491,\n           -0.05700874,  0.03705781],\n          [-0.0326337 ,  0.04710037,  0.0248285 , ..., -0.03292469,\n           -0.01513712, -0.00598423]]],\n \n \n        ...,\n \n \n        [[[-0.04576015,  0.01182621,  0.01164855, ..., -0.01565051,\n           -0.04490408,  0.00858299],\n          [ 0.00055552, -0.043587  ,  0.01256175, ..., -0.05347224,\n           -0.05242385,  0.01933473],\n          [ 0.02170205, -0.03888465, -0.02390735, ..., -0.01056828,\n            0.00167131,  0.00302007],\n          ...,\n          [-0.0257966 ,  0.03521643, -0.04253099, ...,  0.03524762,\n            0.0298847 ,  0.03738464],\n          [ 0.04522281, -0.04663422, -0.00222457, ...,  0.01715916,\n            0.05298519, -0.00936875],\n          [-0.00415882,  0.02639002,  0.0501526 , ..., -0.03317028,\n            0.02464002,  0.00434748]]],\n \n \n        [[[ 0.01200492,  0.00371874,  0.03982565, ..., -0.01751665,\n           -0.05576081, -0.03704472],\n          [ 0.0071738 , -0.04960399,  0.02310956, ..., -0.01485592,\n            0.00560483,  0.04057261],\n          [-0.05613981, -0.00913638,  0.0026861 , ...,  0.03034928,\n           -0.01603048,  0.04460463],\n          ...,\n          [-0.05127865,  0.00455664,  0.04230095, ...,  0.02461317,\n           -0.03340421, -0.04626995],\n          [ 0.04154726, -0.02499755, -0.02622839, ..., -0.04825367,\n           -0.00976317,  0.04389399],\n          [ 0.03882869, -0.0193953 ,  0.00264846, ..., -0.02922835,\n            0.03746049, -0.04134542]]],\n \n \n        [[[ 0.04930896,  0.00639164, -0.04010435, ...,  0.01670834,\n           -0.00898406, -0.01613723],\n          [-0.04608495, -0.05727999,  0.00015909, ...,  0.04409662,\n           -0.03226609, -0.03860945],\n          [-0.03855329, -0.04240623,  0.0011538 , ...,  0.01888628,\n           -0.03730437, -0.02565128],\n          ...,\n          [-0.0260063 , -0.0045939 , -0.04443083, ..., -0.01461971,\n           -0.05596564,  0.0496076 ],\n          [-0.04036876,  0.02275588,  0.03986411, ...,  0.04399465,\n           -0.01835877,  0.01991336],\n          [ 0.01276542,  0.02103002, -0.05130742, ...,  0.05004153,\n            0.0460628 , -0.03419449]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_129/beta:0' shape=(128,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_129/moving_mean:0' shape=(128,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_129/moving_variance:0' shape=(128,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_125/kernel:0' shape=(1, 1, 768, 128) dtype=float32, numpy=\n array([[[[ 0.06177968, -0.0323914 ,  0.06665245, ..., -0.01985344,\n            0.04037677, -0.04592506],\n          [ 0.03081047,  0.07428856, -0.01761336, ...,  0.03837098,\n           -0.03271993,  0.02758717],\n          [-0.01872671,  0.00598112,  0.06593092, ..., -0.04174746,\n           -0.01686189, -0.02354596],\n          ...,\n          [-0.04835059, -0.06063247, -0.03614274, ...,  0.03136585,\n            0.04384618, -0.05943718],\n          [-0.07730964,  0.03255367, -0.06612597, ...,  0.06417683,\n           -0.01681007, -0.0533848 ],\n          [ 0.0235381 , -0.05579542, -0.04929841, ..., -0.01247184,\n           -0.025822  ,  0.06117597]]]], dtype=float32)>,\n <tf.Variable 'conv2d_130/kernel:0' shape=(1, 7, 128, 128) dtype=float32, numpy=\n array([[[[ 0.04862506, -0.02939059, -0.03806612, ..., -0.05488202,\n            0.00907689, -0.05444425],\n          [-0.02502572,  0.03432287,  0.01735773, ..., -0.00484217,\n           -0.02041713, -0.01142966],\n          [-0.00905899,  0.04573821, -0.04078794, ..., -0.03512683,\n           -0.02959679, -0.02280948],\n          ...,\n          [-0.05320825, -0.00909865, -0.03249513, ...,  0.01105732,\n           -0.0229936 ,  0.04230938],\n          [ 0.01704627, -0.04604654,  0.01790889, ..., -0.04453302,\n           -0.05737459, -0.01939551],\n          [ 0.00337542,  0.0101181 ,  0.03679326, ..., -0.04854736,\n            0.01071677, -0.00166958]],\n \n         [[-0.01288   ,  0.00686956,  0.05450217, ...,  0.04118986,\n            0.03947604, -0.04780106],\n          [-0.02211411,  0.02452239, -0.05462047, ..., -0.00077443,\n            0.02693368,  0.03536682],\n          [-0.02246989,  0.03383918,  0.02901145, ...,  0.05506707,\n           -0.01071253, -0.03089582],\n          ...,\n          [ 0.04339483, -0.04224186, -0.03317593, ..., -0.00317005,\n           -0.04935112,  0.00159347],\n          [ 0.05400793, -0.04696415, -0.0400435 , ..., -0.01568776,\n            0.00660187,  0.03140108],\n          [ 0.03825883, -0.05157122, -0.00953605, ...,  0.01828166,\n            0.01835271,  0.05354908]],\n \n         [[ 0.04069165, -0.01279894, -0.04037227, ..., -0.04090558,\n           -0.04043542,  0.00961278],\n          [ 0.05084585, -0.03778872,  0.05369308, ...,  0.05707005,\n            0.03414691,  0.0117646 ],\n          [ 0.03119872, -0.02699775, -0.00467796, ..., -0.00705367,\n           -0.00099479,  0.03610323],\n          ...,\n          [ 0.02758805, -0.04065257, -0.03865008, ...,  0.03153421,\n           -0.01881661,  0.04606288],\n          [-0.04133377, -0.0153247 , -0.02522818, ..., -0.03383383,\n            0.00675504, -0.01460682],\n          [ 0.00155697, -0.05107783,  0.04306304, ...,  0.01297896,\n            0.02215825, -0.0408856 ]],\n \n         ...,\n \n         [[ 0.05053806,  0.02426843, -0.04486426, ..., -0.05424752,\n           -0.03381289,  0.00508525],\n          [ 0.03582031, -0.00214398, -0.0469806 , ...,  0.00644578,\n            0.04648184,  0.03044815],\n          [ 0.00623984,  0.01990693, -0.02311381, ..., -0.04902162,\n            0.00087518, -0.00533587],\n          ...,\n          [-0.0393497 , -0.04743924, -0.00618837, ...,  0.05369191,\n            0.02700728,  0.04975582],\n          [ 0.00601994,  0.02321632,  0.02118986, ...,  0.0210276 ,\n           -0.03951288,  0.05645391],\n          [ 0.00978693, -0.05698214,  0.00373761, ..., -0.04787694,\n            0.00510354, -0.04717722]],\n \n         [[ 0.03523117,  0.00941182, -0.04423089, ...,  0.0059377 ,\n            0.00202067,  0.05658949],\n          [ 0.04984792, -0.04948324,  0.04511029, ...,  0.00923729,\n            0.04485884,  0.05674937],\n          [-0.04915753,  0.03499269,  0.02407129, ..., -0.00207588,\n           -0.00932534, -0.02141876],\n          ...,\n          [-0.01648229, -0.03333828, -0.04817393, ...,  0.05405896,\n           -0.0122102 , -0.02433174],\n          [ 0.04570647, -0.00829609,  0.04685684, ..., -0.00288633,\n            0.02861452,  0.03721356],\n          [-0.0032648 , -0.03442982,  0.0146268 , ...,  0.02353867,\n           -0.00060955, -0.040438  ]],\n \n         [[-0.03867785,  0.00637583, -0.01345715, ..., -0.0234365 ,\n           -0.05586839, -0.03990403],\n          [ 0.00414468, -0.02897999, -0.05001952, ...,  0.03549907,\n           -0.02798063,  0.00987443],\n          [ 0.01802819,  0.01940024,  0.00180402, ..., -0.0431542 ,\n           -0.03219467,  0.01976103],\n          ...,\n          [ 0.04491696,  0.0197976 ,  0.01886243, ...,  0.01706944,\n            0.04438798,  0.04429039],\n          [ 0.05179263, -0.0103674 , -0.01209021, ...,  0.01052534,\n            0.02501442, -0.02703864],\n          [ 0.00950286,  0.00140476, -0.04623829, ..., -0.02683551,\n           -0.02409074, -0.0531657 ]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_125/beta:0' shape=(128,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_125/moving_mean:0' shape=(128,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_125/moving_variance:0' shape=(128,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_130/beta:0' shape=(128,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_130/moving_mean:0' shape=(128,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_130/moving_variance:0' shape=(128,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_126/kernel:0' shape=(1, 7, 128, 128) dtype=float32, numpy=\n array([[[[ 0.0540223 , -0.04959955, -0.01625107, ...,  0.01637835,\n           -0.0316288 ,  0.00339397],\n          [ 0.05646086,  0.00254568, -0.05276396, ..., -0.05669986,\n           -0.00183604,  0.01536673],\n          [-0.0174635 ,  0.00834683,  0.04184808, ..., -0.05511514,\n            0.01431727,  0.02618197],\n          ...,\n          [-0.00354355,  0.01745636, -0.02068173, ..., -0.02830914,\n            0.0058371 , -0.00729718],\n          [-0.01960707, -0.01808543,  0.03574345, ...,  0.00808989,\n            0.04967058,  0.03926777],\n          [-0.05714534, -0.00843005, -0.02819229, ...,  0.04304937,\n           -0.02908683,  0.00455701]],\n \n         [[-0.0475833 , -0.05268999,  0.02312737, ..., -0.02552945,\n           -0.00302819, -0.00503962],\n          [-0.01734479, -0.01330131,  0.02148874, ...,  0.03329942,\n            0.05076358, -0.00156758],\n          [ 0.0443648 , -0.04230125, -0.01086594, ..., -0.04900215,\n            0.01409201,  0.01954441],\n          ...,\n          [-0.00402461,  0.05365162,  0.03664962, ..., -0.01742748,\n            0.0453812 ,  0.0239583 ],\n          [ 0.01019869,  0.00064021, -0.02099587, ..., -0.02967365,\n           -0.03358264,  0.05456778],\n          [-0.01795183, -0.05711772, -0.04010778, ...,  0.03423668,\n            0.01278307, -0.04909594]],\n \n         [[ 0.02836395, -0.01872477,  0.04075021, ..., -0.00921578,\n            0.00859428, -0.02824219],\n          [ 0.03497213,  0.02819989,  0.02166482, ...,  0.04412324,\n           -0.00189402, -0.02294521],\n          [ 0.00217981,  0.02565894, -0.03938159, ..., -0.02125369,\n           -0.03470663,  0.01047286],\n          ...,\n          [-0.03936098, -0.04780664, -0.02421293, ..., -0.025293  ,\n            0.05244782, -0.01713233],\n          [-0.01140478, -0.05297001,  0.01097486, ...,  0.01828779,\n            0.01877026, -0.04332306],\n          [-0.04571285, -0.02564745,  0.02801969, ..., -0.02411702,\n            0.00044308,  0.04721255]],\n \n         ...,\n \n         [[ 0.02254578, -0.05284344,  0.01229718, ...,  0.00612037,\n           -0.03480491, -0.01258148],\n          [-0.02546271, -0.01914202, -0.02077469, ...,  0.02144275,\n           -0.05770818, -0.00290472],\n          [ 0.00836404, -0.05318547,  0.01881404, ..., -0.02933564,\n           -0.00150825, -0.04192656],\n          ...,\n          [-0.01635069, -0.01154422, -0.05670094, ..., -0.01487304,\n            0.01517851, -0.0568616 ],\n          [-0.0275245 , -0.04370303, -0.05533711, ..., -0.0246391 ,\n           -0.03345876, -0.00548301],\n          [ 0.02618793,  0.04785808,  0.02866495, ..., -0.03073431,\n           -0.01615573, -0.05566693]],\n \n         [[ 0.00995928, -0.0421368 , -0.04379333, ..., -0.00990524,\n           -0.03072159,  0.02400012],\n          [-0.00377042,  0.04686578, -0.05216852, ...,  0.01671759,\n            0.0416978 , -0.00489233],\n          [-0.00863026, -0.03232639, -0.02404337, ..., -0.0055541 ,\n           -0.02728841,  0.03954118],\n          ...,\n          [ 0.04851843, -0.03111226, -0.02817074, ...,  0.0398129 ,\n            0.04509031, -0.02065251],\n          [ 0.02320887, -0.04114118,  0.01413824, ..., -0.04909258,\n           -0.0313181 ,  0.01465136],\n          [-0.03647852,  0.01004983, -0.01160733, ...,  0.04337696,\n            0.01645155, -0.04966646]],\n \n         [[-0.04936727, -0.00023416, -0.02813143, ...,  0.04124152,\n            0.04218391, -0.00164443],\n          [-0.01184266, -0.02369148,  0.03890719, ...,  0.01327539,\n           -0.04414192, -0.02004381],\n          [-0.02625   , -0.00569634, -0.01419532, ...,  0.01521366,\n           -0.03655157, -0.04050848],\n          ...,\n          [-0.0113772 , -0.04039025, -0.03505155, ...,  0.01065322,\n           -0.01643546,  0.05353149],\n          [-0.04152262,  0.05703971,  0.01474462, ..., -0.04468872,\n            0.02505654, -0.03538807],\n          [ 0.02346684,  0.05400316, -0.02198688, ..., -0.04120876,\n           -0.02818539,  0.02210009]]]], dtype=float32)>,\n <tf.Variable 'conv2d_131/kernel:0' shape=(7, 1, 128, 128) dtype=float32, numpy=\n array([[[[ 1.25014484e-02, -2.55749375e-03, -5.65652139e-02, ...,\n            4.65892255e-03, -5.60416207e-02,  3.72946933e-02],\n          [-1.20225251e-02,  9.34978575e-03, -3.72388922e-02, ...,\n            3.35368067e-02,  5.74589521e-03, -5.73793575e-02],\n          [ 4.16900516e-02,  1.09207630e-03, -4.85555679e-02, ...,\n           -4.31197211e-02, -4.60863858e-03,  1.37166753e-02],\n          ...,\n          [ 1.39540434e-03, -5.22932410e-03,  5.74919209e-02, ...,\n            1.08248740e-02,  2.78984234e-02, -4.12534401e-02],\n          [-3.90007794e-02,  1.56785622e-02,  2.30541080e-02, ...,\n           -1.19010247e-02,  3.97476181e-02, -2.07828134e-02],\n          [ 3.21999192e-03,  1.86539814e-03, -4.04468141e-02, ...,\n           -3.82035896e-02, -3.48064154e-02, -3.45449187e-02]]],\n \n \n        [[[ 3.23910937e-02,  4.67837751e-02,  4.30688187e-02, ...,\n            4.28233221e-02, -4.85105813e-02,  3.30778286e-02],\n          [ 4.42798212e-02,  2.38897353e-02, -3.66827026e-02, ...,\n           -1.44902766e-02, -4.19199020e-02,  1.05138272e-02],\n          [-4.45680469e-02, -2.87809521e-02, -2.52280533e-02, ...,\n           -2.60677896e-02,  5.53815216e-02,  6.85224682e-03],\n          ...,\n          [-5.08909076e-02,  4.89971191e-02, -1.28982812e-02, ...,\n            5.72432354e-02,  1.10748485e-02,  7.71180540e-03],\n          [-1.43626370e-02,  6.24601543e-03, -7.77542591e-05, ...,\n            1.76082179e-02,  2.85825580e-02, -4.97994274e-02],\n          [ 4.54371423e-03, -3.28244716e-02, -2.42860056e-02, ...,\n            5.03062010e-02,  9.22659785e-03, -4.86855395e-02]]],\n \n \n        [[[-4.00571935e-02,  7.57119060e-03,  4.16950583e-02, ...,\n            2.27291808e-02, -3.38071585e-02,  2.60502920e-02],\n          [-4.43549305e-02,  7.31162727e-04, -2.33918056e-02, ...,\n           -2.36840285e-02, -2.92463265e-02,  1.75289810e-04],\n          [ 4.02488485e-02,  1.84905156e-03,  1.45212486e-02, ...,\n           -4.24634144e-02, -2.48695426e-02,  1.79618597e-03],\n          ...,\n          [ 2.10172758e-02, -4.92085107e-02, -3.28269303e-02, ...,\n           -2.61239670e-02,  3.80010530e-03,  2.75576413e-02],\n          [ 9.38531011e-03, -1.78081654e-02, -5.04119322e-02, ...,\n            9.18593258e-04,  4.03239354e-02,  4.89755422e-02],\n          [ 5.14366031e-02, -2.93143801e-02, -2.66565103e-02, ...,\n            2.48423368e-02, -6.45673648e-03,  4.11849990e-02]]],\n \n \n        ...,\n \n \n        [[[-3.76984440e-02, -1.51479356e-02, -4.89821509e-02, ...,\n           -3.54987457e-02, -1.22137479e-02,  1.77433118e-02],\n          [ 4.85179350e-02, -1.47768259e-02,  1.72657371e-02, ...,\n            4.50168476e-02, -6.93943724e-03, -2.94483658e-02],\n          [-4.31621149e-02, -4.41844538e-02,  2.22121924e-02, ...,\n            3.67725566e-02, -1.04452781e-02, -8.25222582e-04],\n          ...,\n          [-2.44833566e-02, -4.27368060e-02,  5.11480123e-03, ...,\n           -3.27912793e-02,  3.17887366e-02, -1.86833292e-02],\n          [-5.40926494e-02, -3.20438221e-02, -3.71285379e-02, ...,\n            2.67985091e-02, -6.65884465e-03,  2.38087252e-02],\n          [ 2.84542516e-02, -3.93038467e-02, -5.27036339e-02, ...,\n           -1.97332986e-02, -4.30040732e-02,  5.66165745e-02]]],\n \n \n        [[[-4.96076345e-02, -5.71167842e-03,  1.72483996e-02, ...,\n            3.00720856e-02,  3.41229439e-02,  5.37657887e-02],\n          [-5.64896129e-02, -2.83535719e-02,  1.86650082e-03, ...,\n           -4.65623960e-02,  5.43737933e-02,  3.28779146e-02],\n          [ 4.70944270e-02, -7.73233548e-03, -1.86292753e-02, ...,\n           -1.53497532e-02, -4.13680971e-02,  2.11628899e-02],\n          ...,\n          [ 1.18262097e-02,  4.32945862e-02,  1.27719641e-02, ...,\n           -4.47588153e-02,  5.23514301e-02,  2.47716904e-02],\n          [ 4.14660200e-02, -2.02154182e-02, -5.19519150e-02, ...,\n            3.91989574e-02, -5.01066074e-03,  5.50894812e-02],\n          [-2.63375379e-02,  4.75077257e-02, -3.34810168e-02, ...,\n           -5.59001192e-02,  2.17554867e-02,  4.31418642e-02]]],\n \n \n        [[[ 5.06198183e-02, -2.25966796e-03, -1.31347030e-03, ...,\n            3.52232978e-02,  4.88761589e-02,  4.93760630e-02],\n          [ 5.39074019e-02,  2.88521424e-02,  4.64566797e-02, ...,\n           -2.85847075e-02, -2.58983076e-02,  6.73083216e-03],\n          [ 3.77881154e-02,  4.52983379e-02,  3.51960957e-03, ...,\n           -2.23208927e-02, -5.11984155e-02,  2.41730437e-02],\n          ...,\n          [ 1.46321952e-02, -4.96069752e-02,  2.08799168e-03, ...,\n           -5.15819117e-02,  3.88330966e-03,  3.68421227e-02],\n          [ 5.74870184e-02,  4.77740243e-02, -1.84695609e-02, ...,\n            2.71572992e-02, -3.41237038e-02, -4.41540070e-02],\n          [-1.61895454e-02,  2.46006772e-02, -2.78429631e-02, ...,\n            5.67440912e-02, -1.30568631e-02, -1.33742653e-02]]]],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_126/beta:0' shape=(128,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_126/moving_mean:0' shape=(128,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_126/moving_variance:0' shape=(128,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_131/beta:0' shape=(128,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_131/moving_mean:0' shape=(128,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_131/moving_variance:0' shape=(128,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_124/kernel:0' shape=(1, 1, 768, 192) dtype=float32, numpy=\n array([[[[-0.05683937, -0.01786784,  0.00235553, ..., -0.01784446,\n            0.0258095 , -0.02762474],\n          [-0.03519387, -0.02601314, -0.07815441, ..., -0.04477921,\n           -0.03966399, -0.03640874],\n          [-0.01332987,  0.01442419, -0.07146203, ...,  0.07473353,\n            0.02520539,  0.01320606],\n          ...,\n          [-0.01403674, -0.05581732,  0.03779074, ..., -0.02659206,\n            0.03078085, -0.03847101],\n          [-0.01538524, -0.00241585, -0.04994647, ..., -0.0154089 ,\n            0.07811596,  0.03677621],\n          [-0.04440239,  0.04402265,  0.06688515, ...,  0.01815204,\n            0.04078639,  0.03801839]]]], dtype=float32)>,\n <tf.Variable 'conv2d_127/kernel:0' shape=(7, 1, 128, 192) dtype=float32, numpy=\n array([[[[ 0.00576995,  0.03039458,  0.03776325, ...,  0.04725819,\n            0.00566052, -0.01903301],\n          [ 0.02643321,  0.01686756, -0.008545  , ..., -0.04159939,\n           -0.03666724,  0.02639096],\n          [ 0.0238873 , -0.00383247,  0.04638388, ..., -0.01588222,\n            0.00812881, -0.01107686],\n          ...,\n          [ 0.0323051 ,  0.0369009 , -0.02822959, ..., -0.04980071,\n           -0.0432243 ,  0.04072521],\n          [ 0.03235198,  0.00592809,  0.0296543 , ..., -0.02303598,\n           -0.01013769,  0.03229724],\n          [ 0.00337064,  0.03130415,  0.0354291 , ..., -0.00744599,\n           -0.00438745, -0.01824781]]],\n \n \n        [[[ 0.00273757, -0.03948636,  0.02502797, ..., -0.04028235,\n            0.01632111,  0.03465383],\n          [-0.04944757, -0.02071825, -0.01655144, ...,  0.0040484 ,\n            0.01968864, -0.01949569],\n          [ 0.01672782,  0.03082474,  0.01305255, ...,  0.04301198,\n           -0.02782847,  0.01762109],\n          ...,\n          [ 0.04291796, -0.01087875,  0.00868498, ...,  0.01805437,\n            0.0207775 ,  0.02547692],\n          [-0.04983561, -0.04278636,  0.02835614, ..., -0.03566147,\n            0.04744187,  0.0204672 ],\n          [-0.04419876,  0.01651494,  0.0333747 , ..., -0.04523487,\n            0.03931915, -0.02784756]]],\n \n \n        [[[ 0.03050867,  0.03005824,  0.01097045, ...,  0.01064363,\n            0.01204311,  0.01995103],\n          [ 0.01367182, -0.02210009, -0.00958701, ...,  0.01822507,\n            0.03878034, -0.02776783],\n          [ 0.04023856, -0.0355879 ,  0.00457408, ...,  0.03938374,\n           -0.03729073,  0.01420939],\n          ...,\n          [-0.03386801, -0.02208765,  0.00245668, ...,  0.0179917 ,\n            0.04192877, -0.02328849],\n          [ 0.03960741,  0.04752747,  0.04746477, ...,  0.03747327,\n            0.02752203, -0.02447389],\n          [-0.02445024, -0.00668051, -0.03295551, ...,  0.0484877 ,\n            0.00064129,  0.02910605]]],\n \n \n        ...,\n \n \n        [[[ 0.04425493, -0.0476233 ,  0.00901609, ..., -0.01668262,\n            0.01610952,  0.01389604],\n          [ 0.04734512, -0.04889317,  0.04963813, ...,  0.00981192,\n           -0.02635964, -0.00189286],\n          [-0.00147618, -0.03031906,  0.03091135, ..., -0.0183874 ,\n           -0.0298779 , -0.00049393],\n          ...,\n          [-0.03790985, -0.03059874, -0.02914899, ..., -0.01972786,\n            0.01683055,  0.01807118],\n          [ 0.03800981,  0.0496948 ,  0.03379885, ...,  0.03468787,\n            0.0064766 , -0.04028269],\n          [-0.03576458,  0.0235853 , -0.04856775, ..., -0.0108748 ,\n            0.04764104,  0.03088531]]],\n \n \n        [[[-0.00272147,  0.04111389,  0.02133795, ..., -0.01014824,\n           -0.03514331, -0.00522051],\n          [ 0.04338991, -0.03228288, -0.0250091 , ..., -0.04759128,\n            0.01554375, -0.03171264],\n          [ 0.03582169, -0.02888437, -0.01715509, ...,  0.00932991,\n           -0.04795752,  0.00661818],\n          ...,\n          [-0.00741262, -0.01893694,  0.04213811, ...,  0.0316408 ,\n            0.03979019,  0.04725558],\n          [-0.02066096, -0.02144445, -0.04186049, ...,  0.01854322,\n            0.02755609,  0.02671725],\n          [-0.04435685, -0.01804641,  0.02249483, ..., -0.03848367,\n           -0.05153561, -0.0063356 ]]],\n \n \n        [[[-0.00436894,  0.04051296,  0.02277463, ...,  0.00905215,\n           -0.05026833, -0.00754711],\n          [-0.01771395,  0.03755582, -0.01644041, ..., -0.0125991 ,\n            0.0032554 ,  0.02873818],\n          [-0.01290357, -0.01507332,  0.05038001, ...,  0.01423743,\n            0.04640821,  0.03592652],\n          ...,\n          [-0.04065396, -0.01496257, -0.0377906 , ..., -0.01403098,\n            0.00928466, -0.0330405 ],\n          [-0.02559497, -0.01413798,  0.03898477, ..., -0.0285496 ,\n            0.04093521,  0.00763204],\n          [ 0.02638796,  0.0110355 ,  0.02341494, ...,  0.01702885,\n            0.05132427,  0.01302074]]]], dtype=float32)>,\n <tf.Variable 'conv2d_132/kernel:0' shape=(1, 7, 128, 192) dtype=float32, numpy=\n array([[[[-0.0097685 , -0.03291361, -0.00389497, ..., -0.02813329,\n           -0.01838568, -0.03308083],\n          [ 0.04126913, -0.00821121,  0.00462782, ..., -0.04121795,\n            0.00454313,  0.04712599],\n          [-0.03063195,  0.00214717,  0.01013302, ...,  0.0159998 ,\n            0.01261961,  0.01301512],\n          ...,\n          [-0.0444214 , -0.0009944 , -0.04669082, ..., -0.00495354,\n            0.00893943,  0.02922674],\n          [ 0.00538161,  0.00020159, -0.02006008, ..., -0.00287647,\n            0.02500648,  0.02006546],\n          [-0.03402333, -0.04994717, -0.04359334, ...,  0.01918257,\n            0.04022152,  0.01676576]],\n \n         [[-0.04300467, -0.00590435,  0.03997808, ..., -0.04848253,\n            0.01801356,  0.03509386],\n          [ 0.03678462, -0.02264484, -0.03170456, ..., -0.0095217 ,\n           -0.00892236,  0.0269558 ],\n          [-0.04937163,  0.0061249 , -0.04175889, ..., -0.04436884,\n           -0.00611646, -0.0031219 ],\n          ...,\n          [-0.01918625,  0.01729871,  0.01596454, ...,  0.01618427,\n            0.00937963, -0.02337594],\n          [ 0.00465329, -0.00296819,  0.00823133, ..., -0.03442604,\n           -0.00236708,  0.02022809],\n          [ 0.04262639, -0.0254656 , -0.02019963, ...,  0.04982697,\n           -0.0173125 , -0.00594744]],\n \n         [[ 0.02757743, -0.03608965, -0.03089959, ...,  0.00626248,\n           -0.03441233,  0.02599193],\n          [ 0.03251978,  0.04658612, -0.0221478 , ..., -0.02291276,\n            0.0207375 ,  0.004585  ],\n          [ 0.01716084,  0.02793453,  0.00342005, ..., -0.013622  ,\n           -0.04929856,  0.03739434],\n          ...,\n          [-0.00190838, -0.02439058,  0.01305905, ...,  0.02793657,\n            0.00924865,  0.01584868],\n          [ 0.01925071, -0.03123759, -0.05148947, ..., -0.01095304,\n            0.03714151,  0.03863728],\n          [ 0.00737542,  0.04046384, -0.01283952, ...,  0.03399293,\n           -0.05044235, -0.01756254]],\n \n         ...,\n \n         [[ 0.00801261, -0.01616195,  0.04256044, ...,  0.0265269 ,\n            0.03248795, -0.00097245],\n          [ 0.02954778, -0.00679659, -0.02061455, ..., -0.0129782 ,\n           -0.01672899,  0.00369351],\n          [ 0.01861724, -0.00071201, -0.03957741, ...,  0.02470428,\n            0.04785595, -0.04965083],\n          ...,\n          [-0.04676127,  0.01072583, -0.00607055, ..., -0.036852  ,\n           -0.04285721, -0.01606626],\n          [-0.05163492, -0.00588657, -0.04230064, ..., -0.04437009,\n            0.04504711, -0.00311247],\n          [-0.00657675,  0.03606755, -0.02904014, ..., -0.01157411,\n           -0.01525604, -0.01295586]],\n \n         [[-0.04279107, -0.01379076, -0.0150156 , ..., -0.01210587,\n            0.00207008,  0.02108726],\n          [ 0.02969266,  0.01647725, -0.03491332, ...,  0.00912998,\n           -0.03952998, -0.05146896],\n          [-0.005353  , -0.02721984,  0.00919156, ...,  0.04250255,\n            0.03847483,  0.0414111 ],\n          ...,\n          [ 0.0267509 , -0.00355051,  0.0039523 , ..., -0.00909345,\n            0.0188426 ,  0.03676024],\n          [-0.00926277,  0.01657845,  0.01362078, ...,  0.04475961,\n           -0.02505605, -0.01072448],\n          [-0.01523947, -0.01015563,  0.04510676, ..., -0.05006779,\n           -0.01535247, -0.04619022]],\n \n         [[-0.01462483, -0.05031067,  0.01266413, ...,  0.0402564 ,\n            0.03805703, -0.01373915],\n          [-0.02569337,  0.02791404, -0.01050515, ..., -0.02050394,\n           -0.01193077, -0.04501361],\n          [-0.03019825, -0.04896053,  0.0069796 , ...,  0.03647339,\n           -0.03673426, -0.00025811],\n          ...,\n          [-0.0331296 , -0.02848863,  0.00146739, ..., -0.00974949,\n            0.04391032,  0.02546392],\n          [-0.00617627, -0.00717257,  0.03572332, ..., -0.0371865 ,\n           -0.02156142, -0.00462921],\n          [-0.03814466, -0.00491045, -0.02209472, ..., -0.03926082,\n            0.03726706,  0.0001813 ]]]], dtype=float32)>,\n <tf.Variable 'conv2d_133/kernel:0' shape=(1, 1, 768, 192) dtype=float32, numpy=\n array([[[[ 0.00212198,  0.05819864,  0.04707835, ..., -0.01076005,\n            0.0124701 , -0.06955815],\n          [-0.06007281,  0.04136218,  0.04896384, ...,  0.00971843,\n            0.05951505,  0.04485604],\n          [ 0.06910784, -0.06830516,  0.0044027 , ..., -0.01400471,\n            0.0176242 , -0.00189868],\n          ...,\n          [-0.04525656,  0.01723275,  0.06827999, ...,  0.07714006,\n           -0.07836859, -0.05209526],\n          [ 0.05235224, -0.0769412 ,  0.05373267, ...,  0.04980371,\n            0.02808771, -0.05290322],\n          [-0.07113177,  0.03777485,  0.00487761, ..., -0.05059017,\n           -0.04567396,  0.02246448]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_124/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_124/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_124/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_127/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_127/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_127/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_132/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_132/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_132/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_133/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_133/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_133/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_138/kernel:0' shape=(1, 1, 768, 160) dtype=float32, numpy=\n array([[[[ 0.07315466,  0.02512448,  0.06861213, ...,  0.01005236,\n           -0.06941453,  0.07367772],\n          [ 0.07268177,  0.05153242,  0.02321759, ...,  0.05310993,\n            0.0180802 , -0.03066437],\n          [ 0.02265337,  0.02728526, -0.07038986, ...,  0.04129391,\n            0.0281985 , -0.02871621],\n          ...,\n          [-0.0314476 ,  0.02816298, -0.05429302, ...,  0.0595848 ,\n           -0.02890876, -0.00528152],\n          [ 0.01420141,  0.06677178, -0.01648884, ...,  0.04564656,\n           -0.05565341,  0.01723184],\n          [ 0.00979014,  0.00801796,  0.01520737, ...,  0.07766081,\n           -0.00798741,  0.0589316 ]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_138/beta:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_138/moving_mean:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_138/moving_variance:0' shape=(160,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_139/kernel:0' shape=(7, 1, 160, 160) dtype=float32, numpy=\n array([[[[ 0.01619386,  0.04360586, -0.02151596, ..., -0.03096497,\n           -0.02375608,  0.02484862],\n          [ 0.03804246,  0.05084598, -0.04967483, ..., -0.04514285,\n            0.0177961 , -0.04225964],\n          [ 0.04483343, -0.02883237,  0.03307197, ..., -0.02583378,\n            0.03636405,  0.02673438],\n          ...,\n          [-0.04287425,  0.04061688,  0.02045167, ..., -0.03714392,\n           -0.01738743, -0.04681378],\n          [ 0.04530027,  0.00302879, -0.04915303, ..., -0.05071488,\n           -0.01979019,  0.03066887],\n          [-0.00594233,  0.01543334,  0.02283876, ...,  0.04185617,\n           -0.05015293,  0.04241459]]],\n \n \n        [[[-0.04610738, -0.02985466,  0.02676712, ..., -0.03367018,\n            0.03206157,  0.03959769],\n          [ 0.02639705, -0.04592428, -0.0110174 , ..., -0.01046584,\n            0.00864767,  0.04372257],\n          [-0.02852368, -0.05022647,  0.02284544, ..., -0.02056298,\n            0.05089222,  0.01274655],\n          ...,\n          [ 0.03715826,  0.02578305,  0.02298015, ..., -0.04810117,\n           -0.02937586, -0.01719307],\n          [-0.04096533,  0.00145895,  0.00972673, ...,  0.00336838,\n            0.02734926, -0.04200014],\n          [-0.0157772 ,  0.02070806,  0.03415133, ...,  0.00904961,\n            0.03197167, -0.03927759]]],\n \n \n        [[[-0.02443218, -0.02229534,  0.04927892, ...,  0.0517108 ,\n           -0.04137892, -0.02288342],\n          [ 0.00667874,  0.05080431,  0.04501685, ...,  0.0395892 ,\n            0.04159428, -0.02448705],\n          [ 0.01488362,  0.00125432, -0.04318356, ...,  0.00852244,\n            0.02437321,  0.01495041],\n          ...,\n          [-0.01704293,  0.0379292 , -0.02844867, ..., -0.00734736,\n            0.03419012,  0.0056998 ],\n          [ 0.00877546,  0.00996412, -0.0281348 , ..., -0.00648631,\n           -0.02739659, -0.01212312],\n          [ 0.04616105, -0.01155414,  0.03030712, ...,  0.02260694,\n            0.01917588, -0.02891794]]],\n \n \n        ...,\n \n \n        [[[-0.05063942,  0.00448515,  0.00635909, ...,  0.02259028,\n            0.00445223, -0.02345515],\n          [-0.04701417, -0.02708119,  0.00268929, ...,  0.01485445,\n            0.04151304, -0.03756814],\n          [-0.02338648, -0.04561332,  0.03007353, ..., -0.00042668,\n           -0.03917041,  0.01839917],\n          ...,\n          [ 0.01470211,  0.03761441,  0.03351104, ...,  0.05064278,\n           -0.00915665,  0.00112852],\n          [-0.03066068,  0.00113652, -0.03914935, ...,  0.04143503,\n           -0.0232656 ,  0.03561508],\n          [ 0.012868  ,  0.02778256,  0.04722487, ...,  0.04696264,\n           -0.02093347,  0.05103296]]],\n \n \n        [[[ 0.02869696,  0.04391189,  0.03882245, ...,  0.00196145,\n           -0.01750891, -0.0363269 ],\n          [ 0.01449785, -0.01617193, -0.00188006, ..., -0.0386731 ,\n            0.03771503, -0.02670258],\n          [-0.00995741, -0.03693918, -0.01173808, ..., -0.04045046,\n           -0.03385868, -0.00388191],\n          ...,\n          [-0.04584923, -0.00602168, -0.01789137, ..., -0.02512165,\n           -0.02113823,  0.02491386],\n          [ 0.04152187, -0.0023965 , -0.04129846, ..., -0.04121464,\n           -0.01483095,  0.02417399],\n          [ 0.04387091,  0.0146735 , -0.01240607, ...,  0.01866989,\n            0.03879337,  0.00080465]]],\n \n \n        [[[ 0.0174959 ,  0.01185327,  0.01079579, ...,  0.02242297,\n            0.02467436,  0.04875099],\n          [ 0.00265238,  0.00338257,  0.01114393, ..., -0.01090347,\n            0.00761648,  0.04207181],\n          [ 0.05110309, -0.00826341,  0.01412427, ...,  0.0254171 ,\n            0.03348683,  0.04257579],\n          ...,\n          [-0.0044685 , -0.00077296, -0.03427008, ...,  0.04970912,\n            0.00935608,  0.02871303],\n          [ 0.00581945,  0.01828102,  0.0306811 , ..., -0.02059886,\n           -0.03526776,  0.02312484],\n          [ 0.05149444,  0.02727254, -0.03025397, ..., -0.05035322,\n            0.03469469,  0.04056056]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_139/beta:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_139/moving_mean:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_139/moving_variance:0' shape=(160,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_135/kernel:0' shape=(1, 1, 768, 160) dtype=float32, numpy=\n array([[[[-7.8238353e-02, -7.0324138e-02, -6.5017454e-02, ...,\n            7.7719629e-02, -3.4129776e-02,  7.3848501e-02],\n          [ 7.3374361e-02,  2.4899811e-02, -4.1238964e-05, ...,\n            7.5599313e-02, -4.0877346e-02, -4.4032186e-03],\n          [ 5.0148115e-02,  6.6991076e-03,  4.8370153e-02, ...,\n           -2.4310861e-02,  5.9760362e-02,  2.9871911e-02],\n          ...,\n          [-7.2934099e-02, -1.9424364e-02,  5.2187577e-02, ...,\n            3.3104196e-02, -5.2086398e-02,  7.8200623e-02],\n          [ 3.5932742e-02, -1.9026987e-02, -3.3101395e-02, ...,\n            7.7359632e-02, -7.3648348e-02, -4.8980296e-02],\n          [-5.5716902e-02,  2.2136137e-02, -1.2781791e-02, ...,\n           -4.2423286e-02, -7.4115582e-02, -3.7255876e-02]]]],\n       dtype=float32)>,\n <tf.Variable 'conv2d_140/kernel:0' shape=(1, 7, 160, 160) dtype=float32, numpy=\n array([[[[ 0.02195529, -0.04283784,  0.01966165, ..., -0.03598733,\n           -0.04001312, -0.04430193],\n          [-0.01892883, -0.00084266, -0.00079717, ..., -0.0158569 ,\n           -0.02287825,  0.04731845],\n          [ 0.03616155,  0.02104329, -0.02788586, ...,  0.04047535,\n            0.02232837, -0.02419836],\n          ...,\n          [ 0.02720189,  0.05133866,  0.03416671, ...,  0.01818964,\n           -0.01112754, -0.00422806],\n          [ 0.04451175, -0.01057072, -0.04179105, ..., -0.01988917,\n           -0.03310239,  0.02154274],\n          [-0.02988402,  0.03080253, -0.01590699, ..., -0.00372147,\n            0.00765969,  0.05107329]],\n \n         [[-0.03586263, -0.00804697, -0.02286507, ..., -0.03064098,\n            0.04999025,  0.01806028],\n          [-0.05114275,  0.04063872, -0.02517391, ..., -0.03346885,\n            0.03087412, -0.00833776],\n          [-0.03440099, -0.03871538,  0.01468877, ..., -0.02004142,\n            0.0291901 , -0.0472037 ],\n          ...,\n          [ 0.04760025,  0.02508809,  0.0306092 , ...,  0.03470952,\n            0.03768464, -0.03994907],\n          [ 0.0102839 , -0.00989402,  0.0352873 , ...,  0.00370465,\n            0.0098712 , -0.01089589],\n          [ 0.03366845, -0.01189017,  0.0138046 , ...,  0.03276646,\n            0.04782173, -0.02344298]],\n \n         [[-0.03652698,  0.01965853,  0.02889344, ..., -0.01961013,\n            0.04034859,  0.04464215],\n          [-0.01562213,  0.00773421,  0.04991646, ..., -0.04180037,\n            0.01738864, -0.02228109],\n          [-0.01338197,  0.03523139,  0.01938279, ...,  0.04968816,\n            0.02753611,  0.03636576],\n          ...,\n          [ 0.02491447,  0.04007487,  0.01051078, ..., -0.00803635,\n            0.00327899, -0.01979122],\n          [-0.0120968 ,  0.00495762, -0.04625203, ..., -0.00804362,\n           -0.00914648,  0.01397097],\n          [ 0.00524939,  0.0180379 , -0.02392545, ...,  0.01975   ,\n           -0.03011354, -0.02394529]],\n \n         ...,\n \n         [[ 0.0269639 , -0.0104689 ,  0.04889741, ...,  0.05001773,\n           -0.03323137, -0.02678391],\n          [ 0.02822785, -0.04922136, -0.02326827, ...,  0.05021608,\n            0.00654457, -0.03287147],\n          [ 0.00506541,  0.04736018,  0.04959549, ..., -0.01255911,\n           -0.02591518,  0.02841187],\n          ...,\n          [-0.04731508,  0.03689677, -0.05025909, ..., -0.01379598,\n           -0.01632973,  0.03166718],\n          [-0.03724026,  0.00576354, -0.00959418, ...,  0.01795863,\n            0.0198223 , -0.02759339],\n          [-0.01247647, -0.02108422,  0.02925694, ...,  0.04748418,\n           -0.04419379, -0.02081256]],\n \n         [[-0.04427242,  0.02307189,  0.01788085, ...,  0.04361026,\n            0.02264775, -0.01599613],\n          [ 0.02343179,  0.01470004,  0.04735681, ...,  0.03960804,\n            0.03805375, -0.02443942],\n          [-0.01170113,  0.04549205, -0.02621084, ...,  0.0323295 ,\n           -0.03186209,  0.0502883 ],\n          ...,\n          [ 0.02918794,  0.0027559 , -0.04935224, ...,  0.04556409,\n            0.03037475,  0.03780193],\n          [-0.04865571, -0.02940853,  0.03060894, ..., -0.05136739,\n           -0.04153662, -0.00314536],\n          [-0.02206386, -0.03717843,  0.05062282, ..., -0.0163865 ,\n           -0.01235388, -0.01594468]],\n \n         [[-0.02002167, -0.00127314, -0.01501586, ...,  0.00160414,\n           -0.02392477,  0.02421135],\n          [ 0.029689  ,  0.01299623,  0.0501678 , ..., -0.01031331,\n           -0.03009854,  0.01248004],\n          [-0.03456134, -0.03860922,  0.00545477, ..., -0.00769871,\n           -0.0379294 ,  0.0098476 ],\n          ...,\n          [-0.028467  ,  0.03572906,  0.00374088, ...,  0.01778173,\n           -0.01220406, -0.05148339],\n          [ 0.0228523 , -0.00175264,  0.00507776, ...,  0.04873985,\n           -0.0508521 ,  0.02590775],\n          [ 0.03477644, -0.00306373,  0.02679059, ..., -0.04401895,\n           -0.03787319, -0.01583702]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_135/beta:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_135/moving_mean:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_135/moving_variance:0' shape=(160,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_140/beta:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_140/moving_mean:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_140/moving_variance:0' shape=(160,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_136/kernel:0' shape=(1, 7, 160, 160) dtype=float32, numpy=\n array([[[[ 0.01433599, -0.0069406 , -0.03012813, ...,  0.03369961,\n            0.00964713,  0.04918799],\n          [-0.01675277, -0.02942088,  0.00389502, ...,  0.02335901,\n            0.02523829, -0.02672573],\n          [-0.01039904,  0.04638916,  0.04762306, ...,  0.04892291,\n           -0.03549042,  0.00762795],\n          ...,\n          [ 0.04766106, -0.02511931, -0.02221933, ...,  0.03929086,\n           -0.04886468, -0.00029846],\n          [ 0.04258577,  0.02378431, -0.04649254, ..., -0.0440387 ,\n           -0.01643844,  0.00332238],\n          [-0.0397947 , -0.01642427,  0.0229249 , ...,  0.04853439,\n            0.04137157, -0.03266852]],\n \n         [[-0.05114533,  0.01796634,  0.01759237, ..., -0.02384861,\n           -0.02090808, -0.02073001],\n          [-0.0187735 , -0.00972572, -0.04719884, ..., -0.04269122,\n           -0.03017299,  0.02186851],\n          [-0.03267134, -0.00744881,  0.04822028, ..., -0.03250701,\n            0.02616008,  0.02067019],\n          ...,\n          [ 0.02036179, -0.03428274,  0.04393898, ...,  0.0162325 ,\n            0.02045671,  0.00675424],\n          [ 0.04884665, -0.0287725 ,  0.04423652, ..., -0.02147342,\n            0.04851118,  0.03208088],\n          [-0.03240961,  0.03959199,  0.0306065 , ..., -0.04511913,\n           -0.04167444,  0.03252565]],\n \n         [[-0.0074755 ,  0.0137124 ,  0.03760687, ...,  0.0191698 ,\n           -0.0431403 , -0.03191582],\n          [-0.01019512, -0.02168613, -0.02077105, ...,  0.03424676,\n            0.03285201, -0.03322501],\n          [ 0.01018554, -0.01818296, -0.04094603, ..., -0.00250547,\n            0.00523721, -0.04402456],\n          ...,\n          [ 0.02244437, -0.04129779,  0.01750166, ..., -0.02938095,\n           -0.03760655, -0.02724195],\n          [-0.02749054, -0.05084447, -0.04263704, ..., -0.02442908,\n           -0.04172494,  0.0090492 ],\n          [-0.00566113,  0.04982255, -0.04452574, ..., -0.03562763,\n            0.02463692,  0.02689624]],\n \n         ...,\n \n         [[ 0.0310392 ,  0.000668  , -0.01103963, ..., -0.02052722,\n           -0.03106384, -0.00737124],\n          [-0.03450307,  0.02772267,  0.00054042, ..., -0.04710211,\n            0.04988122, -0.03160028],\n          [-0.02574628,  0.0138698 ,  0.02634126, ...,  0.00964352,\n           -0.03273528, -0.0069969 ],\n          ...,\n          [ 0.00544884, -0.03411854, -0.02895585, ..., -0.03036657,\n           -0.02518959, -0.00247647],\n          [-0.00779219,  0.00058438, -0.03024045, ...,  0.01779429,\n            0.02849724,  0.04137119],\n          [ 0.00412172, -0.0375992 , -0.01841458, ...,  0.02577497,\n            0.03343811,  0.0116084 ]],\n \n         [[-0.04692361,  0.03817565,  0.00341909, ...,  0.02799485,\n           -0.00680217,  0.01889493],\n          [-0.02339855, -0.0194594 ,  0.00832508, ..., -0.03274626,\n           -0.03206562,  0.03271088],\n          [ 0.04479722,  0.03877363,  0.02556094, ...,  0.009469  ,\n            0.01520358, -0.04011682],\n          ...,\n          [-0.01618843,  0.02483787, -0.00398489, ..., -0.0444013 ,\n            0.04992396,  0.02896623],\n          [ 0.05031954,  0.02686572,  0.01941394, ...,  0.00707136,\n            0.02178524,  0.04703859],\n          [ 0.05100374, -0.02218905,  0.01800873, ...,  0.02879765,\n           -0.0508867 ,  0.01598199]],\n \n         [[-0.02573833, -0.02168904,  0.02955345, ...,  0.02139969,\n           -0.0223903 ,  0.02426145],\n          [ 0.00025617, -0.00803053, -0.01662214, ..., -0.02066716,\n            0.01088391, -0.01947167],\n          [ 0.05155551,  0.02860189, -0.02080957, ...,  0.05020427,\n           -0.02906752,  0.04091549],\n          ...,\n          [-0.01510618,  0.05017832,  0.01652257, ..., -0.04475307,\n            0.04325814,  0.03041006],\n          [-0.02340146, -0.03904611, -0.04379629, ..., -0.01239818,\n           -0.02781876, -0.04861014],\n          [-0.04029384, -0.03640637,  0.04452508, ..., -0.02668686,\n           -0.00685808, -0.00441514]]]], dtype=float32)>,\n <tf.Variable 'conv2d_141/kernel:0' shape=(7, 1, 160, 160) dtype=float32, numpy=\n array([[[[ 3.49397771e-02, -2.78699398e-02,  1.31008588e-02, ...,\n           -3.21620777e-02,  2.74661519e-02,  1.00485981e-02],\n          [ 4.35487293e-02, -2.87657883e-02, -1.80130973e-02, ...,\n            5.16631268e-02, -3.59559804e-02, -7.80430809e-03],\n          [ 1.23555101e-02, -4.52532731e-02, -1.94605999e-02, ...,\n            1.95046403e-02,  1.44258402e-02,  1.72498934e-02],\n          ...,\n          [ 3.52989621e-02, -3.91583964e-02, -1.59880891e-03, ...,\n            3.27672064e-03, -2.63610370e-02, -4.12937775e-02],\n          [-6.01895154e-05, -7.10454583e-03, -2.51878258e-02, ...,\n           -1.79500058e-02, -4.08620872e-02, -4.96417806e-02],\n          [ 2.88061798e-03,  2.07606070e-02,  2.29593031e-02, ...,\n            1.16248839e-02, -1.65504664e-02,  4.04840447e-02]]],\n \n \n        [[[ 4.53783460e-02, -1.48538798e-02, -4.08776216e-02, ...,\n           -3.00278440e-02, -4.35478538e-02, -5.02071083e-02],\n          [-2.15633679e-02,  1.65533312e-02,  3.76044028e-02, ...,\n            1.95831917e-02, -4.01166938e-02, -3.11101638e-02],\n          [ 4.63838167e-02, -2.45159622e-02, -2.33571995e-02, ...,\n           -2.64115054e-02, -3.65948603e-02,  4.75117303e-02],\n          ...,\n          [ 1.42033733e-02,  4.55392115e-02, -6.38649240e-03, ...,\n            3.74029540e-02,  3.00114788e-02, -3.76220495e-02],\n          [ 3.53867523e-02,  2.72939019e-02, -1.24844313e-02, ...,\n            2.02785321e-02, -7.66292214e-03,  4.97498997e-02],\n          [ 2.24522687e-02, -1.38386115e-02, -4.69318070e-02, ...,\n           -1.53536983e-02, -1.48664154e-02,  2.41878740e-02]]],\n \n \n        [[[ 3.83674316e-02,  2.86494680e-02, -1.53689384e-02, ...,\n           -4.43490595e-02, -3.27810422e-02,  1.84123255e-02],\n          [ 2.93953381e-02, -3.63724940e-02, -4.15291637e-02, ...,\n            5.05681597e-02, -3.40287983e-02,  9.98913497e-03],\n          [ 3.81321348e-02,  4.86618392e-02,  4.41807173e-02, ...,\n           -2.89612804e-02, -2.59011872e-02,  3.05471905e-02],\n          ...,\n          [ 2.46637650e-02,  1.29695050e-02, -3.61343324e-02, ...,\n            4.13895585e-02,  1.57520957e-02, -3.67681161e-02],\n          [-5.71690127e-03, -1.53541155e-02, -5.00505492e-02, ...,\n           -4.98634353e-02,  3.62863429e-02,  3.55662778e-03],\n          [-2.93099880e-03, -4.76325192e-02, -3.02649196e-02, ...,\n           -1.25435852e-02,  3.06340642e-02, -2.50233915e-02]]],\n \n \n        ...,\n \n \n        [[[-4.19728756e-02, -4.59213257e-02, -5.13678566e-02, ...,\n           -4.40953858e-02,  1.17487870e-02, -1.92648470e-02],\n          [-1.56632438e-02,  9.58835334e-03, -9.64820012e-03, ...,\n           -4.10705358e-02,  4.34691422e-02, -1.01727583e-02],\n          [-4.91109565e-02,  4.74835224e-02,  3.39684002e-02, ...,\n            4.69542779e-02, -3.10569815e-02,  3.96805964e-02],\n          ...,\n          [-2.28096172e-02, -1.95277855e-02, -4.18906212e-02, ...,\n            3.32791246e-02, -2.24798117e-02,  5.05315624e-02],\n          [-3.74733098e-02,  3.04145180e-02,  3.67147885e-02, ...,\n           -6.77852705e-03, -1.00643188e-02, -3.86772454e-02],\n          [ 4.87919264e-02, -5.05978838e-02, -3.17413807e-02, ...,\n           -8.83474201e-03,  3.10337208e-02,  3.74247842e-02]]],\n \n \n        [[[ 1.10040195e-02, -5.09624109e-02,  5.13517894e-02, ...,\n            1.05942935e-02,  3.31853814e-02,  4.77365516e-02],\n          [ 1.37523077e-02,  1.48479454e-02,  4.03722413e-02, ...,\n           -4.03222889e-02, -1.99213251e-02, -2.92716883e-02],\n          [ 5.02742864e-02, -4.62270677e-02,  1.85720064e-02, ...,\n            3.71126793e-02, -3.49567905e-02,  2.04143636e-02],\n          ...,\n          [-5.03330193e-02, -1.26913376e-02, -3.75932753e-02, ...,\n            4.30699401e-02,  1.54639035e-03,  1.01582594e-02],\n          [-1.23303384e-02,  4.08198684e-04,  3.26416604e-02, ...,\n            2.70994566e-02, -1.51340701e-02, -1.21108852e-02],\n          [ 2.01281421e-02, -3.38713862e-02, -4.20804098e-02, ...,\n            3.13998796e-02,  2.08057053e-02,  2.56303884e-02]]],\n \n \n        [[[-5.10761067e-02, -2.03062855e-02, -3.91090736e-02, ...,\n           -4.25703935e-02, -1.35959722e-02, -2.86204740e-03],\n          [-2.14031432e-02, -3.73074822e-02, -3.96216251e-02, ...,\n            3.46144326e-02,  1.96225978e-02,  4.33889963e-02],\n          [-5.70738688e-03, -2.16681659e-02, -4.70790863e-02, ...,\n            4.56369780e-02,  1.38564408e-03,  1.52418204e-02],\n          ...,\n          [-5.10293245e-03, -3.71646062e-02, -2.61760093e-02, ...,\n           -6.28288090e-03,  2.17931159e-02,  2.55467556e-02],\n          [-6.32171333e-03,  2.65947357e-03,  2.03339756e-03, ...,\n            3.78682949e-02,  4.68728878e-02,  9.88521427e-03],\n          [ 3.53899859e-02,  2.47566439e-02, -1.04691833e-02, ...,\n           -3.81007418e-02, -3.98634784e-02,  4.81813885e-02]]]],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_136/beta:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_136/moving_mean:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_136/moving_variance:0' shape=(160,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_141/beta:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_141/moving_mean:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_141/moving_variance:0' shape=(160,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_134/kernel:0' shape=(1, 1, 768, 192) dtype=float32, numpy=\n array([[[[ 0.04520221,  0.03690977,  0.01893141, ..., -0.05107006,\n           -0.00654257, -0.02873389],\n          [ 0.01980325,  0.00459871,  0.06877569, ..., -0.02252799,\n           -0.00957   , -0.0470353 ],\n          [ 0.07414306,  0.04216072, -0.01153512, ..., -0.00589304,\n            0.01199757,  0.06524158],\n          ...,\n          [ 0.00192396,  0.07380659, -0.07648063, ..., -0.04373671,\n           -0.05038661, -0.00130565],\n          [-0.04871751,  0.02499219,  0.05787057, ...,  0.03242717,\n            0.00743236,  0.07478177],\n          [-0.00551259, -0.03072585,  0.03260484, ..., -0.06246895,\n           -0.00425514,  0.01004252]]]], dtype=float32)>,\n <tf.Variable 'conv2d_137/kernel:0' shape=(7, 1, 160, 192) dtype=float32, numpy=\n array([[[[-0.0328388 , -0.00914277,  0.04121532, ...,  0.03008879,\n           -0.04853851,  0.00641553],\n          [ 0.03271471,  0.03360489,  0.03255749, ...,  0.04618378,\n           -0.03224546, -0.02109886],\n          [-0.03609302, -0.02332168, -0.02287335, ...,  0.03047824,\n            0.01992056, -0.0378738 ],\n          ...,\n          [-0.04254755, -0.04437825, -0.01266995, ..., -0.01856649,\n            0.04323439,  0.04137762],\n          [-0.01660537,  0.03441029, -0.02795921, ...,  0.02971995,\n           -0.03235056, -0.01760492],\n          [ 0.03950369, -0.03629714,  0.01994732, ...,  0.03880392,\n           -0.04663224, -0.03757845]]],\n \n \n        [[[ 0.04314667,  0.0418969 ,  0.0415105 , ..., -0.00926724,\n            0.03621431,  0.00358386],\n          [ 0.03206729, -0.01074209,  0.01428122, ...,  0.00010533,\n            0.04258493,  0.0360244 ],\n          [ 0.0435207 ,  0.03307625, -0.02973988, ...,  0.03222148,\n            0.01058871, -0.01392746],\n          ...,\n          [ 0.03220406,  0.02833528,  0.0172605 , ..., -0.03012907,\n            0.04146108,  0.01035718],\n          [-0.01658891,  0.02855781,  0.02926429, ...,  0.0412535 ,\n            0.02038116, -0.04263245],\n          [-0.01239759,  0.00492444,  0.02824569, ...,  0.03338692,\n           -0.01577667, -0.01061021]]],\n \n \n        [[[-0.01742592,  0.00556776,  0.02088716, ...,  0.04339016,\n            0.01042978, -0.01980313],\n          [-0.02152311, -0.03333946, -0.01704891, ...,  0.00819004,\n            0.02108904,  0.04856609],\n          [-0.04696952, -0.00656605,  0.01411232, ...,  0.02446419,\n           -0.00462056, -0.032758  ],\n          ...,\n          [ 0.02336117,  0.01806286, -0.04294018, ...,  0.02261051,\n            0.00194562, -0.02986942],\n          [ 0.04039716,  0.01222937, -0.02721454, ...,  0.01084967,\n           -0.03260005, -0.01066957],\n          [-0.02747196,  0.04006289, -0.02676396, ...,  0.00213852,\n            0.03563548,  0.00047996]]],\n \n \n        ...,\n \n \n        [[[-0.04897101, -0.00485103, -0.00277028, ..., -0.0273185 ,\n            0.0028208 , -0.01079774],\n          [ 0.03401626, -0.00460946,  0.03005629, ..., -0.02479574,\n           -0.04706185, -0.01471048],\n          [ 0.00337201,  0.0269686 ,  0.0118528 , ..., -0.00772505,\n            0.03535348,  0.01913343],\n          ...,\n          [ 0.0324853 ,  0.0093722 , -0.03227372, ..., -0.01972494,\n           -0.03758509, -0.02299632],\n          [ 0.02246505, -0.00570928, -0.02566915, ..., -0.02848557,\n           -0.03909804,  0.00683798],\n          [-0.03649559,  0.03099103,  0.04374168, ..., -0.02884485,\n           -0.03224254, -0.03553189]]],\n \n \n        [[[-0.00069023, -0.0018364 , -0.04739696, ...,  0.04775273,\n           -0.01123488,  0.01305385],\n          [ 0.00284312,  0.00639807,  0.03669568, ...,  0.00695343,\n           -0.03187869, -0.02662154],\n          [ 0.01145821,  0.01514501,  0.0467873 , ...,  0.02677612,\n           -0.01039895, -0.01842169],\n          ...,\n          [-0.00582879, -0.00784856,  0.02622063, ...,  0.0418261 ,\n           -0.00532291,  0.01953809],\n          [ 0.00419169,  0.01825006,  0.00704307, ..., -0.02917168,\n           -0.02875155,  0.02265956],\n          [-0.02762154,  0.04546754,  0.0413656 , ...,  0.00501344,\n            0.00833772,  0.00631306]]],\n \n \n        [[[-0.04677664, -0.04435043, -0.03957502, ..., -0.0282954 ,\n           -0.02246563, -0.0291391 ],\n          [-0.03787065,  0.03003946, -0.01717789, ..., -0.04230352,\n            0.01218174, -0.02878177],\n          [ 0.03245063, -0.02411444,  0.00162112, ...,  0.00276473,\n           -0.04384056, -0.01072445],\n          ...,\n          [ 0.02280389,  0.03008394, -0.03705384, ..., -0.03269957,\n           -0.00957998,  0.02002609],\n          [ 0.02863203, -0.00193005, -0.01998713, ..., -0.04532867,\n            0.03736592, -0.01648184],\n          [ 0.01769493,  0.01011793,  0.0313948 , ..., -0.04490326,\n           -0.03322001,  0.04301019]]]], dtype=float32)>,\n <tf.Variable 'conv2d_142/kernel:0' shape=(1, 7, 160, 192) dtype=float32, numpy=\n array([[[[ 0.04902446, -0.03146352, -0.01693918, ..., -0.02864512,\n            0.01549519, -0.03367687],\n          [ 0.01078166, -0.01477177, -0.02894763, ...,  0.02753314,\n           -0.04516706, -0.0412432 ],\n          [-0.0124479 ,  0.01238405, -0.0264434 , ...,  0.01122559,\n            0.03220895, -0.01849588],\n          ...,\n          [ 0.01307201, -0.01358427, -0.01009407, ..., -0.03251639,\n           -0.01200741,  0.02538646],\n          [-0.02997025,  0.03558224,  0.0429805 , ...,  0.00244907,\n            0.03363722,  0.00626421],\n          [ 0.0389058 , -0.0177388 , -0.04229053, ...,  0.04879153,\n            0.00540378, -0.0335301 ]],\n \n         [[-0.03268205,  0.03373689, -0.01179279, ..., -0.01691682,\n            0.01555282,  0.03013378],\n          [ 0.01771818, -0.01358502, -0.04398361, ..., -0.0076906 ,\n           -0.01646392, -0.03897958],\n          [ 0.04030061, -0.02481113,  0.01285014, ..., -0.02519517,\n            0.04652217,  0.03323304],\n          ...,\n          [ 0.04370871,  0.0336738 ,  0.0379941 , ..., -0.01064894,\n           -0.00436352,  0.01366019],\n          [ 0.01787307,  0.00760251,  0.01416473, ..., -0.01485995,\n           -0.0111742 ,  0.04276885],\n          [-0.01591338,  0.02446158,  0.0212531 , ...,  0.04918823,\n            0.0109427 , -0.02111455]],\n \n         [[ 0.01216065, -0.02400458, -0.01269109, ...,  0.04514099,\n           -0.03668911, -0.00198653],\n          [ 0.03148196,  0.00777028, -0.03999165, ...,  0.01690191,\n            0.03106778, -0.04864333],\n          [ 0.02475811, -0.03926535, -0.03392628, ...,  0.00164238,\n            0.04493238, -0.00813764],\n          ...,\n          [-0.04804424,  0.00983809,  0.01955369, ..., -0.00086792,\n            0.03732372,  0.02080787],\n          [-0.03089781,  0.03358911,  0.02079396, ...,  0.02120178,\n            0.0101739 ,  0.02937198],\n          [ 0.00490914,  0.04653629, -0.01209835, ...,  0.03229325,\n            0.01860243, -0.04463832]],\n \n         ...,\n \n         [[ 0.03054469, -0.01804751,  0.01250039, ...,  0.02562625,\n           -0.02804419, -0.03902011],\n          [-0.03180659, -0.03563091, -0.02928042, ...,  0.01825621,\n            0.00586918,  0.00435385],\n          [-0.00494152, -0.02646422,  0.03899779, ..., -0.01732903,\n           -0.0107852 ,  0.03700494],\n          ...,\n          [-0.03750753,  0.03038172, -0.0236253 , ...,  0.0119889 ,\n           -0.03294385, -0.04493628],\n          [-0.01733668, -0.02114599,  0.01169155, ...,  0.02888448,\n           -0.0102849 , -0.03929859],\n          [-0.02690213, -0.01877128, -0.00069097, ...,  0.03213599,\n           -0.01504285, -0.0286801 ]],\n \n         [[-0.03740281,  0.03076401,  0.04860468, ...,  0.02053435,\n            0.01869746,  0.01537457],\n          [ 0.04134069, -0.0111202 , -0.00931343, ...,  0.01889672,\n            0.0010288 ,  0.04233477],\n          [ 0.00779399, -0.01834556,  0.0330804 , ...,  0.04907831,\n           -0.00037891, -0.01123224],\n          ...,\n          [ 0.00758141,  0.00523429,  0.02498345, ...,  0.00497439,\n           -0.04301863,  0.02950842],\n          [ 0.01681146, -0.02773208, -0.03144093, ...,  0.02177637,\n            0.04575792, -0.02738767],\n          [ 0.00780869, -0.00980804,  0.01436995, ...,  0.04587766,\n            0.04172232, -0.03665271]],\n \n         [[-0.00824908, -0.04709898, -0.0423677 , ..., -0.02525217,\n           -0.01190129,  0.03038647],\n          [-0.04487662, -0.00774617, -0.00763498, ...,  0.0250256 ,\n           -0.04365205, -0.03746628],\n          [-0.02724259,  0.01557949, -0.01413482, ...,  0.01795933,\n           -0.00068931,  0.02757869],\n          ...,\n          [-0.02424596,  0.01321372,  0.02200739, ...,  0.01074179,\n            0.00648479, -0.00403264],\n          [-0.03919675, -0.01827477,  0.02242858, ..., -0.00445318,\n            0.04292347,  0.01720976],\n          [-0.02828139, -0.03729451, -0.01699822, ...,  0.03651273,\n           -0.03535404,  0.02616131]]]], dtype=float32)>,\n <tf.Variable 'conv2d_143/kernel:0' shape=(1, 1, 768, 192) dtype=float32, numpy=\n array([[[[ 0.01363153,  0.02410089,  0.06423738, ...,  0.03650746,\n           -0.01356445, -0.01022222],\n          [ 0.06887106, -0.07886793, -0.06402127, ..., -0.02904521,\n            0.04882332, -0.07182015],\n          [-0.0185703 ,  0.0153093 ,  0.0369662 , ...,  0.03680471,\n            0.06726541,  0.03581978],\n          ...,\n          [-0.06385233,  0.00850639,  0.05392433, ...,  0.01810098,\n           -0.05736328,  0.04381359],\n          [ 0.03097107,  0.01185518,  0.06666064, ...,  0.00555462,\n            0.05200174,  0.00523745],\n          [-0.02118601,  0.06872157,  0.05125011, ..., -0.07210332,\n            0.06966873,  0.04436549]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_134/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_134/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_134/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_137/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_137/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_137/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_142/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_142/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_142/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_143/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_143/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_143/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_148/kernel:0' shape=(1, 1, 768, 160) dtype=float32, numpy=\n array([[[[ 0.01821138,  0.02014183, -0.07849697, ...,  0.01247402,\n           -0.02335429, -0.00598905],\n          [-0.02967918, -0.03323624, -0.0678616 , ...,  0.0222965 ,\n            0.01654423, -0.02485234],\n          [ 0.07241385,  0.05445015, -0.04695177, ...,  0.03774203,\n           -0.05473832,  0.07645451],\n          ...,\n          [-0.07419271, -0.05224872,  0.01158243, ...,  0.07757425,\n           -0.04491768,  0.03452305],\n          [-0.01908446,  0.06975901,  0.0218661 , ...,  0.00389531,\n           -0.03293097,  0.02485217],\n          [-0.058855  , -0.04698329, -0.04449113, ..., -0.05206613,\n           -0.00329746,  0.01572287]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_148/beta:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_148/moving_mean:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_148/moving_variance:0' shape=(160,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_149/kernel:0' shape=(7, 1, 160, 160) dtype=float32, numpy=\n array([[[[-2.45693419e-02,  6.73525408e-03,  7.62279704e-03, ...,\n           -5.51186875e-03, -5.07674254e-02,  3.79011147e-02],\n          [-3.78196649e-02,  8.17368552e-03,  5.41416556e-03, ...,\n            2.30794139e-02, -2.01956034e-02, -4.08674553e-02],\n          [-3.13246101e-02, -2.44319681e-02,  2.04150937e-02, ...,\n           -4.35293578e-02,  1.69201978e-02, -3.82866561e-02],\n          ...,\n          [ 2.71373577e-02,  4.55253534e-02,  4.84661646e-02, ...,\n            1.47718452e-02, -2.16216482e-02, -1.57115757e-02],\n          [-3.82731482e-03,  2.96464823e-02,  1.38427801e-02, ...,\n           -2.81560533e-02,  3.87909152e-02,  2.60841064e-02],\n          [-4.97165322e-02,  2.13697664e-02, -1.10160634e-02, ...,\n           -1.64498501e-02,  3.54210846e-02,  3.33832689e-02]]],\n \n \n        [[[ 2.00409554e-02,  1.83314644e-02, -1.40001960e-02, ...,\n            2.38981433e-02,  5.69745898e-04, -2.15047207e-02],\n          [ 2.18972228e-02, -2.12546624e-02, -4.97098342e-02, ...,\n            2.95330323e-02,  4.02267464e-02,  2.28723623e-02],\n          [-2.45855674e-02, -4.08631228e-02,  1.99537016e-02, ...,\n            2.07761042e-02, -2.68250462e-02, -1.38484240e-02],\n          ...,\n          [-4.55543920e-02, -1.62563957e-02,  4.05945443e-02, ...,\n            3.97485085e-02,  3.48723307e-03, -2.91646700e-02],\n          [ 6.19326159e-03,  6.57323748e-03,  1.35417245e-02, ...,\n           -5.08648679e-02, -1.27345882e-02,  1.35945417e-02],\n          [-4.41149212e-02, -1.02482848e-02,  2.61127576e-03, ...,\n            4.74746488e-02,  1.22885443e-02,  4.68167923e-02]]],\n \n \n        [[[-5.98642975e-04,  4.25000377e-02, -2.68639643e-02, ...,\n           -4.29969877e-02, -9.47092101e-03,  1.83791183e-02],\n          [ 2.32827403e-02, -2.19582021e-03,  1.80656463e-03, ...,\n            3.89099829e-02, -2.95906365e-02, -3.00667994e-02],\n          [ 2.92958282e-02, -4.28325534e-02,  1.11255161e-02, ...,\n            3.01657207e-02,  1.65120251e-02, -1.98557787e-02],\n          ...,\n          [ 2.73326039e-03,  2.55454592e-02, -3.38389203e-02, ...,\n           -1.27604753e-02,  2.26096697e-02,  8.45786184e-04],\n          [-2.55890526e-02, -2.06263326e-02, -6.87050447e-03, ...,\n           -4.08055484e-02, -7.15217367e-03,  1.04196779e-02],\n          [-5.07161021e-05,  2.09771879e-02,  1.38370581e-02, ...,\n           -2.97570452e-02,  3.06984149e-02,  2.77871452e-02]]],\n \n \n        ...,\n \n \n        [[[ 2.06524916e-02,  2.43532769e-02, -1.13986582e-02, ...,\n            2.15990432e-02, -3.54186632e-02,  3.29362489e-02],\n          [-4.61144224e-02,  4.63883579e-03,  4.45599146e-02, ...,\n            5.02743460e-02,  4.43967395e-02, -7.47636706e-03],\n          [ 1.26625486e-02,  3.97669934e-02, -4.59195115e-02, ...,\n           -7.25178793e-03, -1.28708035e-03, -2.58764960e-02],\n          ...,\n          [-4.84414361e-02, -3.70119661e-02, -2.48792935e-02, ...,\n            3.89265604e-02,  3.38224694e-03, -5.35849482e-04],\n          [ 4.92783524e-02,  3.48009951e-02,  5.95061854e-03, ...,\n            1.67621933e-02, -2.53403764e-02,  4.51803692e-02],\n          [-4.61892746e-02,  2.35189833e-02, -1.94858685e-02, ...,\n            3.24756466e-02,  6.65494800e-03, -4.08375449e-02]]],\n \n \n        [[[-3.83083895e-02,  8.31510872e-03,  1.11430325e-02, ...,\n            4.10475470e-02, -4.52685878e-02,  1.72681920e-02],\n          [-2.11799890e-03,  4.34459783e-02, -1.89795122e-02, ...,\n            4.50649150e-02, -4.56798188e-02, -3.14561352e-02],\n          [-3.62142660e-02, -4.85063531e-02,  3.94588672e-02, ...,\n            8.12325627e-03, -2.23535672e-02,  9.38808545e-03],\n          ...,\n          [ 7.75091723e-03, -3.52950618e-02, -2.60790717e-02, ...,\n           -1.92025341e-02, -3.33234668e-04,  2.68089660e-02],\n          [-3.12593579e-02,  3.72683629e-03, -6.82980940e-03, ...,\n            9.62170586e-03,  1.23080052e-02,  5.62737882e-03],\n          [-4.76779789e-02, -4.66586873e-02, -1.90217383e-02, ...,\n           -1.10384487e-02,  1.03476420e-02, -2.30375119e-02]]],\n \n \n        [[[ 3.61177586e-02, -4.01875079e-02,  4.47881185e-02, ...,\n            2.81609595e-04, -8.16174224e-03, -3.39737758e-02],\n          [ 1.04481094e-02,  1.31616555e-02, -2.61284411e-04, ...,\n           -4.03137133e-02, -2.55349558e-02, -2.06134859e-02],\n          [ 8.48530233e-03, -3.22114006e-02, -1.21580064e-02, ...,\n            3.41499597e-03,  4.25053053e-02,  3.78024839e-02],\n          ...,\n          [-3.28490362e-02, -3.32795791e-02,  3.46579216e-02, ...,\n           -2.04994455e-02,  1.98853798e-02, -1.77248865e-02],\n          [-2.09411830e-02,  6.07189164e-03,  1.90529972e-04, ...,\n            2.68667154e-02,  3.01916637e-02, -2.81254519e-02],\n          [-2.25756634e-02,  1.55002363e-02, -4.49796356e-02, ...,\n           -7.20061734e-03, -3.07699423e-02,  1.47207491e-02]]]],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_149/beta:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_149/moving_mean:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_149/moving_variance:0' shape=(160,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_145/kernel:0' shape=(1, 1, 768, 160) dtype=float32, numpy=\n array([[[[ 0.02728135,  0.00913737, -0.05275761, ..., -0.00426425,\n           -0.02797821, -0.07235468],\n          [ 0.03765915,  0.05908573,  0.03619647, ...,  0.04714321,\n            0.04646944, -0.04487382],\n          [-0.0588143 , -0.0642918 , -0.03324611, ...,  0.00417409,\n            0.06390259, -0.02032601],\n          ...,\n          [-0.06615639,  0.030755  ,  0.07207787, ..., -0.05881664,\n           -0.03360095,  0.03429829],\n          [ 0.02681082,  0.0454029 ,  0.04806551, ...,  0.06363869,\n           -0.00352192, -0.0656477 ],\n          [ 0.06712286,  0.06784621, -0.04400297, ...,  0.00967592,\n            0.04650003, -0.03709706]]]], dtype=float32)>,\n <tf.Variable 'conv2d_150/kernel:0' shape=(1, 7, 160, 160) dtype=float32, numpy=\n array([[[[ 0.05114115, -0.05004282, -0.01366011, ...,  0.00500677,\n            0.05132609,  0.00105093],\n          [ 0.03358474,  0.01288774,  0.03187754, ..., -0.02361114,\n            0.00865662,  0.01658959],\n          [-0.04292996, -0.04980118, -0.04280646, ..., -0.02245973,\n            0.03230619,  0.00840559],\n          ...,\n          [ 0.04659526,  0.04087288,  0.02258076, ...,  0.01694782,\n           -0.04209244,  0.00456988],\n          [-0.04560951, -0.03451915, -0.02754455, ..., -0.03597954,\n           -0.04127482,  0.03403677],\n          [ 0.0317626 ,  0.038397  , -0.02952176, ...,  0.01791335,\n           -0.02771412,  0.0091047 ]],\n \n         [[ 0.05128301,  0.03038467, -0.00728073, ...,  0.00818394,\n           -0.00137475,  0.02742695],\n          [-0.03120296, -0.02596714, -0.00970555, ...,  0.02165918,\n           -0.04311457, -0.03361333],\n          [ 0.02843139,  0.00999326,  0.00681747, ...,  0.01516159,\n           -0.01935864, -0.04199665],\n          ...,\n          [-0.04932091,  0.03581345,  0.00629941, ..., -0.04580098,\n            0.00190755, -0.03247119],\n          [ 0.04386501,  0.01122829,  0.0020364 , ...,  0.00658162,\n            0.01047719,  0.01801484],\n          [-0.02335104,  0.01773403,  0.02175475, ..., -0.00332119,\n            0.03148174,  0.03434402]],\n \n         [[ 0.02769666,  0.01791437,  0.02101645, ..., -0.01489757,\n           -0.03026646, -0.0377355 ],\n          [-0.02226562,  0.01935485, -0.02210599, ..., -0.01162399,\n           -0.04933019, -0.00738021],\n          [-0.00781193,  0.0242967 ,  0.03610049, ...,  0.00189631,\n           -0.05126124,  0.04623153],\n          ...,\n          [ 0.03775359,  0.03653289,  0.02304298, ...,  0.00739321,\n           -0.00491524,  0.01935281],\n          [-0.00571433, -0.01121901,  0.0297374 , ..., -0.01634502,\n            0.01672873,  0.03705038],\n          [-0.05013961,  0.03523592,  0.01194675, ...,  0.02716709,\n            0.00168944,  0.00178176]],\n \n         ...,\n \n         [[-0.040144  , -0.03962905,  0.02827672, ...,  0.00575855,\n            0.02419347, -0.01128262],\n          [ 0.04766387, -0.00039486, -0.02459024, ..., -0.00695911,\n            0.0184125 , -0.02471796],\n          [-0.0458984 , -0.02108253,  0.02430111, ..., -0.01066785,\n           -0.01320742,  0.04710296],\n          ...,\n          [ 0.02515476,  0.01415158,  0.04797784, ..., -0.00945774,\n            0.04985714, -0.02803125],\n          [-0.04319958,  0.0044859 , -0.0225911 , ...,  0.02377808,\n            0.0021996 , -0.00124663],\n          [-0.03511798, -0.04297784,  0.00343445, ...,  0.00557977,\n           -0.02619089,  0.051163  ]],\n \n         [[ 0.02141578,  0.05031269,  0.0242257 , ..., -0.01477125,\n            0.01311852, -0.0296368 ],\n          [ 0.03549714, -0.04509964, -0.02980494, ..., -0.04580892,\n            0.01849082,  0.03614241],\n          [-0.00944076, -0.00508917,  0.03374175, ..., -0.02057663,\n           -0.03369444, -0.04782934],\n          ...,\n          [-0.02858669,  0.01828744,  0.01792224, ...,  0.02442594,\n           -0.03679064,  0.00372015],\n          [ 0.03981269, -0.00353981,  0.03864178, ..., -0.05137171,\n            0.00531933, -0.04242346],\n          [-0.00217359,  0.00999514, -0.03627142, ...,  0.0037717 ,\n            0.03662396, -0.0427022 ]],\n \n         [[ 0.02738721,  0.04382124, -0.05071585, ...,  0.02772439,\n           -0.02383247,  0.01700407],\n          [ 0.04125243, -0.02958268,  0.04813557, ..., -0.01919196,\n            0.04061284,  0.01158891],\n          [-0.03905732, -0.05113577, -0.00889673, ..., -0.01211673,\n           -0.03662936, -0.02430227],\n          ...,\n          [ 0.00022718,  0.00119737,  0.04262038, ...,  0.00164944,\n           -0.05143148, -0.04750104],\n          [-0.03046777, -0.01834282,  0.00273258, ..., -0.02791552,\n           -0.03771631,  0.05028939],\n          [ 0.00938343,  0.04615578,  0.01929389, ...,  0.02886128,\n           -0.00793755,  0.05118592]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_145/beta:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_145/moving_mean:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_145/moving_variance:0' shape=(160,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_150/beta:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_150/moving_mean:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_150/moving_variance:0' shape=(160,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_146/kernel:0' shape=(1, 7, 160, 160) dtype=float32, numpy=\n array([[[[ 0.00410192, -0.02112   ,  0.04455106, ..., -0.00015967,\n           -0.03096167,  0.0236634 ],\n          [-0.04573473, -0.04931589, -0.0081195 , ..., -0.00472858,\n            0.03742984, -0.01735461],\n          [-0.00223739,  0.01296527, -0.02702444, ...,  0.04214298,\n            0.04217393, -0.02307262],\n          ...,\n          [-0.00624933, -0.0289332 , -0.0464271 , ...,  0.03737969,\n           -0.01215658,  0.01873751],\n          [ 0.0353341 ,  0.01242914, -0.00847947, ..., -0.02633488,\n           -0.00053996, -0.02841567],\n          [-0.01909586, -0.04318033, -0.00249892, ..., -0.0045802 ,\n           -0.00910616, -0.01064847]],\n \n         [[ 0.01309686,  0.04911503, -0.00158408, ..., -0.02516434,\n            0.04756534,  0.03449493],\n          [-0.02654206, -0.04691815,  0.05068393, ...,  0.00398443,\n           -0.04036006, -0.01422476],\n          [-0.04613608,  0.00609368, -0.01592487, ...,  0.01619807,\n            0.02717346,  0.01508139],\n          ...,\n          [ 0.00790062,  0.01895084, -0.04777852, ..., -0.00783142,\n            0.03710112,  0.05104381],\n          [-0.00164361, -0.01361085,  0.04858125, ...,  0.0068134 ,\n            0.03414929,  0.01654105],\n          [-0.02812144, -0.02257897,  0.03025101, ...,  0.04596534,\n           -0.04512936, -0.01385404]],\n \n         [[ 0.01556064,  0.0313645 , -0.02045062, ..., -0.02522366,\n           -0.00910284,  0.03359183],\n          [-0.02050826,  0.00539231, -0.04221875, ...,  0.01750243,\n            0.04482244, -0.02214068],\n          [-0.01016987, -0.04644657, -0.04581928, ...,  0.01468878,\n           -0.00601026, -0.00544439],\n          ...,\n          [ 0.02432776,  0.05060177,  0.04003083, ..., -0.03303252,\n           -0.00476652,  0.04965973],\n          [-0.02888174, -0.0085055 , -0.028168  , ...,  0.02607644,\n            0.00225111,  0.02411507],\n          [ 0.04225021,  0.023046  , -0.0492762 , ...,  0.04947316,\n           -0.01397504,  0.00978386]],\n \n         ...,\n \n         [[-0.02354498, -0.01683114,  0.04458397, ..., -0.01169849,\n            0.00289069, -0.03374646],\n          [-0.03948162,  0.00242797, -0.04313542, ...,  0.00878335,\n           -0.0260646 ,  0.03124994],\n          [ 0.05143763,  0.03835374,  0.00058866, ..., -0.00991822,\n           -0.01957161,  0.05140677],\n          ...,\n          [ 0.0122367 ,  0.01261309,  0.0098576 , ...,  0.02293656,\n            0.03372993, -0.02206194],\n          [ 0.05083032,  0.03916105,  0.04753088, ..., -0.03825818,\n           -0.04575058, -0.00608369],\n          [ 0.03224406,  0.00415307, -0.03730748, ...,  0.01166345,\n           -0.00353843, -0.01312783]],\n \n         [[-0.04795111, -0.04050955, -0.03331103, ...,  0.02044433,\n            0.04966766, -0.02315455],\n          [-0.0308801 , -0.04664773, -0.00732063, ...,  0.01717779,\n            0.03263571, -0.02966445],\n          [-0.0184001 , -0.04498136,  0.02651554, ...,  0.02314051,\n           -0.00986477, -0.02590278],\n          ...,\n          [-0.00497506,  0.04568153, -0.02101047, ...,  0.03969765,\n           -0.03286553, -0.01001475],\n          [ 0.02899737,  0.04767989, -0.03538894, ..., -0.01125538,\n           -0.04101456,  0.0229098 ],\n          [-0.02384671,  0.03914962,  0.0425527 , ...,  0.01394252,\n           -0.03756349,  0.03989812]],\n \n         [[-0.00861507,  0.00358581,  0.029459  , ..., -0.0360986 ,\n            0.05052229,  0.0302123 ],\n          [ 0.00121083, -0.01635954, -0.04583034, ...,  0.0112757 ,\n           -0.02720101, -0.00511071],\n          [ 0.00442999, -0.02165219,  0.00900351, ...,  0.01974009,\n           -0.02670602,  0.00940863],\n          ...,\n          [ 0.0270377 ,  0.03184216, -0.00628154, ..., -0.01817822,\n           -0.01851054, -0.02217861],\n          [ 0.00680989,  0.01852999, -0.01991802, ..., -0.01223812,\n           -0.04830785,  0.01583288],\n          [ 0.00319903, -0.02485459, -0.04102446, ...,  0.03235454,\n           -0.0055491 ,  0.03240981]]]], dtype=float32)>,\n <tf.Variable 'conv2d_151/kernel:0' shape=(7, 1, 160, 160) dtype=float32, numpy=\n array([[[[-0.03407038, -0.02547689, -0.03998144, ..., -0.03554711,\n            0.01445441, -0.00655701],\n          [ 0.02779631,  0.03210327, -0.03688002, ...,  0.00843428,\n            0.03539324,  0.02043708],\n          [ 0.02141337,  0.00970323, -0.0233207 , ...,  0.022733  ,\n           -0.03122907, -0.03242802],\n          ...,\n          [ 0.0180284 , -0.0282446 ,  0.03460773, ..., -0.00149893,\n           -0.04308338,  0.02373506],\n          [-0.01554311,  0.05087067,  0.01082944, ..., -0.03386623,\n            0.00179434,  0.0150846 ],\n          [ 0.00284607,  0.02563515, -0.0130209 , ..., -0.02291523,\n            0.01059229,  0.02016596]]],\n \n \n        [[[ 0.00809058,  0.04750479, -0.02904439, ..., -0.0042307 ,\n           -0.03584052, -0.00291269],\n          [ 0.04661155, -0.04194523,  0.01481685, ..., -0.04492821,\n            0.00463821,  0.00296013],\n          [ 0.01466369,  0.01056346,  0.01671407, ...,  0.04015391,\n           -0.03698578, -0.00909895],\n          ...,\n          [ 0.01648605, -0.01613109,  0.02259047, ...,  0.0004314 ,\n           -0.03428063, -0.03395913],\n          [-0.02872078,  0.02462789, -0.05068646, ..., -0.02268392,\n           -0.03928746,  0.04582832],\n          [ 0.00501351, -0.01503759,  0.02785981, ...,  0.01726836,\n           -0.01318571,  0.00769644]]],\n \n \n        [[[ 0.01696372,  0.0058495 ,  0.04082978, ...,  0.04797827,\n           -0.04371576,  0.04229679],\n          [ 0.03802205,  0.02834308, -0.0287902 , ...,  0.00674932,\n           -0.03613992, -0.03683583],\n          [ 0.03400243, -0.03287982, -0.03993987, ...,  0.03821778,\n            0.03388252, -0.04535438],\n          ...,\n          [ 0.04188328, -0.03920332, -0.02734361, ...,  0.02845102,\n           -0.00545026,  0.01172729],\n          [-0.03605232,  0.02806759,  0.0173081 , ..., -0.04427719,\n            0.003308  ,  0.00148573],\n          [-0.0305617 , -0.04591983,  0.04169481, ...,  0.04489636,\n            0.04328124, -0.02011527]]],\n \n \n        ...,\n \n \n        [[[-0.04396376,  0.0098122 , -0.04000887, ..., -0.01350924,\n            0.03680839, -0.00884986],\n          [ 0.00169957,  0.03278678,  0.02485395, ...,  0.03834791,\n            0.03844691,  0.04448377],\n          [ 0.0404774 , -0.03122366, -0.01212066, ...,  0.00872899,\n           -0.01880271,  0.00734131],\n          ...,\n          [ 0.05104792, -0.03415675, -0.04456133, ..., -0.04278097,\n           -0.04545904,  0.02880127],\n          [ 0.05161536, -0.01097321,  0.01036466, ...,  0.01888273,\n           -0.03587807, -0.00645519],\n          [-0.01384022, -0.01023738, -0.01749115, ...,  0.0454029 ,\n            0.05075137,  0.01677317]]],\n \n \n        [[[ 0.00693594,  0.03901887,  0.03498029, ..., -0.01863522,\n            0.00365865,  0.00359009],\n          [-0.00127333, -0.02475584, -0.03050106, ...,  0.02802544,\n            0.03755746, -0.05156145],\n          [ 0.03233272, -0.04189143,  0.00528953, ..., -0.01258823,\n            0.02585434,  0.04844755],\n          ...,\n          [-0.0071263 ,  0.03100884,  0.05018746, ..., -0.04774061,\n           -0.01461766,  0.04738999],\n          [-0.0352874 ,  0.02340035,  0.00716662, ..., -0.04906567,\n           -0.01074799, -0.02932395],\n          [ 0.0443604 , -0.00390019,  0.01717854, ...,  0.0351696 ,\n           -0.04608602, -0.02433355]]],\n \n \n        [[[-0.03342227,  0.03032092,  0.03217113, ...,  0.00963909,\n            0.02757427,  0.00061779],\n          [ 0.02535569, -0.04229114,  0.02380821, ...,  0.00645759,\n           -0.02416129, -0.02792702],\n          [-0.04574226, -0.0021016 ,  0.05126953, ...,  0.03841158,\n           -0.04741617,  0.04789587],\n          ...,\n          [ 0.03746329,  0.03639842,  0.00099897, ..., -0.00704826,\n           -0.00888697, -0.01436713],\n          [ 0.041364  , -0.01727024,  0.03211599, ...,  0.04629597,\n           -0.02915105,  0.03852711],\n          [ 0.03911628,  0.00950092,  0.02088778, ...,  0.01639051,\n            0.00210304, -0.01513434]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_146/beta:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_146/moving_mean:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_146/moving_variance:0' shape=(160,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_151/beta:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_151/moving_mean:0' shape=(160,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_151/moving_variance:0' shape=(160,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_144/kernel:0' shape=(1, 1, 768, 192) dtype=float32, numpy=\n array([[[[ 0.03591807, -0.01032369,  0.07274031, ...,  0.01149303,\n            0.0604059 ,  0.04354915],\n          [-0.05615477,  0.07865543, -0.01294069, ...,  0.04816059,\n           -0.00010691,  0.05716939],\n          [-0.01525528,  0.0048558 , -0.03268732, ..., -0.05562063,\n           -0.07445139, -0.0270197 ],\n          ...,\n          [ 0.04693861, -0.02645916, -0.03640438, ..., -0.03898821,\n           -0.07045747, -0.07288699],\n          [-0.03151308,  0.01440496, -0.05655392, ..., -0.00778916,\n            0.01372065,  0.06256736],\n          [-0.02832616,  0.00171317, -0.07719258, ..., -0.06355033,\n            0.05213899,  0.07561197]]]], dtype=float32)>,\n <tf.Variable 'conv2d_147/kernel:0' shape=(7, 1, 160, 192) dtype=float32, numpy=\n array([[[[ 0.04411518, -0.03831586, -0.0082496 , ..., -0.02303302,\n            0.00763961,  0.02823868],\n          [-0.03835201,  0.04294586,  0.04577496, ..., -0.02370301,\n            0.03888649,  0.0019756 ],\n          [-0.02141307,  0.03829782,  0.04416015, ..., -0.01877788,\n            0.03390763, -0.00967528],\n          ...,\n          [-0.02220334,  0.03062317, -0.01158159, ..., -0.02516045,\n           -0.03864005,  0.04893431],\n          [ 0.01898787,  0.02784592,  0.01300124, ...,  0.04556031,\n            0.0276397 ,  0.0084606 ],\n          [ 0.02104176, -0.01532552,  0.0223566 , ...,  0.02434111,\n            0.00676557,  0.02706961]]],\n \n \n        [[[ 0.0187321 , -0.04390695,  0.003918  , ...,  0.00876496,\n           -0.00926898,  0.01090848],\n          [-0.02574166, -0.00516845,  0.02170898, ..., -0.02797505,\n           -0.03587589, -0.02499286],\n          [ 0.03636989, -0.03556373, -0.00102099, ..., -0.03616109,\n            0.04478438, -0.03477019],\n          ...,\n          [-0.00468427,  0.03812498,  0.01551927, ...,  0.00684727,\n            0.02336632, -0.00342705],\n          [ 0.00135323,  0.00871887,  0.01587998, ..., -0.02959101,\n           -0.02005032,  0.03680473],\n          [ 0.02560835, -0.04154684,  0.02543857, ...,  0.00850036,\n            0.0192983 ,  0.0453035 ]]],\n \n \n        [[[ 0.02739958, -0.00496172, -0.04204795, ...,  0.01294872,\n            0.01789171,  0.01777302],\n          [ 0.00659633,  0.02032721,  0.03927068, ..., -0.03823366,\n            0.01745954, -0.03928706],\n          [-0.03497562, -0.04102016,  0.04641059, ..., -0.03605133,\n           -0.00143081,  0.01577118],\n          ...,\n          [ 0.02620533, -0.00672792,  0.03297459, ...,  0.023433  ,\n           -0.02503457, -0.03842171],\n          [-0.00577117, -0.02713501, -0.00791182, ...,  0.00698043,\n            0.03680364,  0.00674975],\n          [ 0.02599909, -0.03616548, -0.00867362, ...,  0.03015967,\n           -0.01383729, -0.03325287]]],\n \n \n        ...,\n \n \n        [[[ 0.03203503,  0.02962452, -0.040671  , ...,  0.03738328,\n            0.03232722, -0.04714463],\n          [ 0.03304281, -0.00212676, -0.02809396, ..., -0.01505933,\n           -0.03936673,  0.04801952],\n          [-0.04806237, -0.02672254,  0.01335391, ..., -0.03795443,\n           -0.01804315, -0.04125552],\n          ...,\n          [ 0.03360451, -0.04655861,  0.03696385, ..., -0.01620805,\n           -0.00547866, -0.0121069 ],\n          [ 0.03617674, -0.04127617, -0.04723131, ...,  0.03495475,\n            0.01336226, -0.04835766],\n          [ 0.01955127,  0.02822522,  0.03934872, ..., -0.00148138,\n           -0.0360186 ,  0.02523158]]],\n \n \n        [[[ 0.01912894, -0.03359979,  0.01709908, ..., -0.0357574 ,\n            0.03928254,  0.026001  ],\n          [-0.00504453,  0.01608015,  0.02373483, ...,  0.00090438,\n           -0.00637736,  0.02277636],\n          [-0.00052781,  0.04353685,  0.01732728, ..., -0.01852509,\n            0.0276626 , -0.00495118],\n          ...,\n          [-0.00807755, -0.01376349, -0.0356266 , ..., -0.04194996,\n           -0.03677809, -0.04849   ],\n          [ 0.01404655,  0.02334088,  0.04282783, ...,  0.02404794,\n           -0.01775817, -0.0142331 ],\n          [-0.0318746 ,  0.01693628, -0.04499154, ...,  0.02790941,\n            0.01139435,  0.02288173]]],\n \n \n        [[[-0.03267306, -0.04765846,  0.03845363, ...,  0.01410575,\n            0.00511763,  0.01570673],\n          [ 0.00673245, -0.02858406,  0.03181511, ..., -0.02779561,\n            0.0194768 ,  0.02500481],\n          [ 0.03590467,  0.02284032,  0.02959758, ..., -0.04147206,\n            0.03152887, -0.04519382],\n          ...,\n          [-0.03062573, -0.00355968,  0.02039644, ...,  0.04655096,\n           -0.03008113,  0.02042826],\n          [ 0.01415583,  0.04328937,  0.01943501, ...,  0.03913496,\n            0.02448193, -0.02201795],\n          [-0.03534272,  0.02434478,  0.03323053, ..., -0.04338276,\n           -0.00138342,  0.03356041]]]], dtype=float32)>,\n <tf.Variable 'conv2d_152/kernel:0' shape=(1, 7, 160, 192) dtype=float32, numpy=\n array([[[[-0.03268929, -0.04601281,  0.02547077, ..., -0.00247978,\n           -0.020411  , -0.01524136],\n          [ 0.00147441,  0.01297234,  0.02031144, ..., -0.02171814,\n           -0.0061544 , -0.03652284],\n          [ 0.02598285, -0.00016842, -0.03041992, ...,  0.03537279,\n            0.00046104,  0.03879919],\n          ...,\n          [ 0.04861288, -0.04347681, -0.00460017, ...,  0.01093164,\n           -0.00506655,  0.03994213],\n          [-0.04844136,  0.02589506, -0.02833152, ...,  0.01145245,\n            0.03283675,  0.03746576],\n          [ 0.02209173, -0.01125139, -0.03750775, ..., -0.01708902,\n            0.02458498,  0.02487208]],\n \n         [[ 0.04584752, -0.02127984, -0.02154365, ..., -0.04778362,\n            0.0198521 ,  0.03131115],\n          [-0.03523488, -0.00840683,  0.03966234, ..., -0.00865576,\n            0.04167173,  0.03724699],\n          [-0.02912046,  0.04489976,  0.03736863, ...,  0.04389648,\n            0.03785757,  0.00085542],\n          ...,\n          [ 0.03778135,  0.01889816, -0.02263664, ...,  0.03101994,\n            0.03008289,  0.04509943],\n          [ 0.01623661, -0.02126905, -0.04866875, ...,  0.02813539,\n            0.04331361, -0.04325861],\n          [ 0.01823677, -0.00298391,  0.03579262, ..., -0.0461562 ,\n            0.03481905,  0.03922182]],\n \n         [[-0.02366963, -0.0008183 , -0.04171037, ...,  0.04399205,\n            0.03362757,  0.03449235],\n          [ 0.04522381, -0.02879879, -0.03586232, ..., -0.02044638,\n           -0.02680692, -0.01522027],\n          [ 0.0290123 ,  0.00012415, -0.02013478, ..., -0.01030309,\n           -0.01515133,  0.0272116 ],\n          ...,\n          [ 0.03681086,  0.01090689,  0.03448792, ..., -0.03065411,\n           -0.01775969,  0.04496317],\n          [ 0.01732763,  0.03107335, -0.01714581, ...,  0.0301133 ,\n            0.02435603, -0.01919235],\n          [-0.04457029,  0.03303507, -0.03187189, ...,  0.01366829,\n           -0.0135216 , -0.03926245]],\n \n         ...,\n \n         [[ 0.03256767,  0.02137182, -0.04077493, ...,  0.04691822,\n            0.04661053, -0.02522054],\n          [-0.03847703,  0.0123396 ,  0.00507341, ...,  0.03319908,\n           -0.03144359, -0.03860093],\n          [-0.02531048,  0.01385056, -0.01503664, ...,  0.01716468,\n           -0.04430519,  0.01136673],\n          ...,\n          [ 0.02572838, -0.02186287,  0.0392154 , ...,  0.02750706,\n           -0.01527349, -0.04820145],\n          [-0.04006628, -0.0061728 , -0.03860667, ..., -0.0227701 ,\n            0.00905979, -0.0040603 ],\n          [ 0.02606295, -0.00940438,  0.02585537, ..., -0.03447458,\n            0.03364197, -0.04245631]],\n \n         [[ 0.03710863, -0.03871743, -0.02374941, ...,  0.00236738,\n           -0.02142422, -0.02017937],\n          [ 0.01768753,  0.04138789,  0.01448094, ..., -0.02347623,\n           -0.03024046,  0.02808918],\n          [-0.03760837,  0.00279834, -0.04663346, ..., -0.00612872,\n            0.00772297, -0.01077232],\n          ...,\n          [-0.03620189, -0.0164374 , -0.0402064 , ...,  0.01142712,\n            0.02782341, -0.01638491],\n          [-0.01144985,  0.041735  , -0.00607725, ..., -0.00933832,\n           -0.02202767,  0.01340217],\n          [-0.01270649, -0.00284688,  0.03583945, ...,  0.02292815,\n            0.01201585,  0.04762325]],\n \n         [[ 0.00969805, -0.02779971,  0.02231125, ..., -0.04012446,\n            0.04236012,  0.0430588 ],\n          [-0.04506886, -0.02040378,  0.00230514, ..., -0.02215931,\n            0.01183911, -0.01261716],\n          [-0.02745152,  0.03533545, -0.00781454, ..., -0.00784836,\n            0.02005453,  0.04152286],\n          ...,\n          [ 0.02946377, -0.00729064, -0.01936742, ..., -0.01490996,\n           -0.00770465,  0.02636929],\n          [ 0.00546049,  0.00612674,  0.04548591, ...,  0.01916226,\n            0.00117758, -0.03307262],\n          [ 0.0269805 , -0.00747265,  0.00698368, ...,  0.02460283,\n           -0.04247481,  0.03055076]]]], dtype=float32)>,\n <tf.Variable 'conv2d_153/kernel:0' shape=(1, 1, 768, 192) dtype=float32, numpy=\n array([[[[-0.06058704, -0.06158073, -0.01828861, ...,  0.01982909,\n           -0.01660175,  0.00113624],\n          [-0.04901284, -0.05636697,  0.04299485, ...,  0.03872886,\n            0.00724536,  0.01214659],\n          [-0.0361907 ,  0.00524066, -0.01153007, ..., -0.07424828,\n           -0.05843718, -0.01890934],\n          ...,\n          [ 0.03371654,  0.05734385,  0.0283605 , ...,  0.0059616 ,\n           -0.02544335,  0.00980672],\n          [ 0.07730613, -0.03616376,  0.068046  , ..., -0.04292633,\n           -0.06658942,  0.01827061],\n          [ 0.04634532,  0.02036027, -0.04890738, ..., -0.06628411,\n            0.00784221, -0.02089881]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_144/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_144/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_144/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_147/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_147/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_147/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_152/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_152/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_152/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_153/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_153/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_153/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_158/kernel:0' shape=(1, 1, 768, 192) dtype=float32, numpy=\n array([[[[ 0.04899756, -0.04120536,  0.0081493 , ..., -0.01801333,\n            0.07804636, -0.02819932],\n          [-0.06507915, -0.0634519 ,  0.07283888, ...,  0.05532541,\n           -0.06961469,  0.01098991],\n          [ 0.02019612,  0.02421678, -0.01285683, ...,  0.00779551,\n           -0.05319019,  0.0755045 ],\n          ...,\n          [ 0.05084392,  0.05231973,  0.06446796, ..., -0.06506591,\n           -0.06861104, -0.00648397],\n          [ 0.05136517, -0.05281899, -0.0525673 , ...,  0.0134076 ,\n            0.04438397,  0.04452391],\n          [-0.06575342,  0.00553095, -0.04423089, ...,  0.04988723,\n            0.04341563,  0.01243628]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_158/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_158/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_158/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_159/kernel:0' shape=(7, 1, 192, 192) dtype=float32, numpy=\n array([[[[ 0.00632751,  0.02500718,  0.04152841, ..., -0.02173082,\n            0.02395241,  0.03817946],\n          [-0.00841041,  0.02420342, -0.03152552, ..., -0.03932345,\n           -0.00323065,  0.03619577],\n          [-0.04047904, -0.04001698, -0.01624893, ...,  0.04357445,\n           -0.03267492,  0.01540912],\n          ...,\n          [ 0.02096198, -0.04379265, -0.02931663, ...,  0.01658798,\n            0.00145102, -0.03589946],\n          [ 0.00440518,  0.04253566,  0.01254467, ...,  0.03275934,\n           -0.0121637 ,  0.0139352 ],\n          [-0.03998331,  0.01987037, -0.00923083, ...,  0.0122914 ,\n           -0.0373368 ,  0.03832146]]],\n \n \n        [[[ 0.02410864, -0.01580263, -0.019502  , ..., -0.01353646,\n            0.00275232,  0.00806767],\n          [-0.00157973, -0.00746501, -0.04630206, ...,  0.03795605,\n           -0.02353638, -0.04078303],\n          [ 0.04540716, -0.02281463,  0.02335365, ...,  0.03588917,\n            0.04185021,  0.02596193],\n          ...,\n          [ 0.03270643, -0.03947329, -0.00746688, ...,  0.01304898,\n            0.03137289, -0.01587617],\n          [-0.00187406, -0.03056304, -0.01645785, ...,  0.0457887 ,\n            0.03929363,  0.01123679],\n          [ 0.04491432, -0.0075602 , -0.00257883, ..., -0.00255079,\n           -0.04601591, -0.00845064]]],\n \n \n        [[[-0.03300098,  0.01066901,  0.01324201, ..., -0.01424265,\n           -0.01146506,  0.02700469],\n          [ 0.03515996, -0.04001987,  0.01203238, ..., -0.0283623 ,\n            0.01406503,  0.02146985],\n          [-0.02340289, -0.04040888,  0.04478945, ...,  0.04451343,\n            0.04174109,  0.00910487],\n          ...,\n          [-0.01155889, -0.01387823,  0.03130654, ...,  0.0078474 ,\n            0.00560296,  0.0451225 ],\n          [-0.0350482 ,  0.02616805, -0.0363318 , ..., -0.03532608,\n            0.03034483,  0.01416579],\n          [ 0.04564696,  0.00902466,  0.01613839, ..., -0.02305193,\n           -0.03415129,  0.01177762]]],\n \n \n        ...,\n \n \n        [[[-0.01582294, -0.00959259, -0.02139628, ..., -0.03687   ,\n           -0.04599492, -0.03702651],\n          [-0.04597739, -0.04327482,  0.02678681, ..., -0.0445431 ,\n           -0.01057114, -0.04131213],\n          [ 0.01131175, -0.004921  , -0.01799293, ...,  0.02956088,\n            0.02967121, -0.04194125],\n          ...,\n          [-0.00558171, -0.00799255,  0.04329165, ..., -0.03360987,\n           -0.01482807,  0.03260151],\n          [ 0.03591901,  0.02220271,  0.00456066, ..., -0.03910537,\n           -0.01102652,  0.02707381],\n          [-0.03552788,  0.00199071, -0.0210615 , ..., -0.00560568,\n            0.00075785,  0.02069348]]],\n \n \n        [[[ 0.02693767, -0.0074015 ,  0.01223489, ...,  0.03802766,\n            0.01129052,  0.00775322],\n          [ 0.01653337,  0.04272326, -0.02542429, ...,  0.02745367,\n            0.0048131 ,  0.00182342],\n          [ 0.01833245,  0.02961447,  0.01403674, ..., -0.04339483,\n           -0.01252665,  0.02368679],\n          ...,\n          [-0.01121133, -0.02600736, -0.03708876, ...,  0.04217666,\n           -0.00379002,  0.02983724],\n          [ 0.02286438, -0.02289437, -0.03274977, ..., -0.03826012,\n           -0.00792558, -0.00784798],\n          [ 0.03097149,  0.0441622 , -0.01153743, ..., -0.01577716,\n           -0.01778004, -0.03634718]]],\n \n \n        [[[ 0.01854358,  0.01890448,  0.00833825, ..., -0.03325621,\n           -0.02724067,  0.02433196],\n          [ 0.04204721, -0.03204438,  0.03892193, ...,  0.04289781,\n            0.03804598, -0.00767026],\n          [-0.00942931,  0.04367858,  0.01013766, ...,  0.02758719,\n            0.02556732, -0.03090157],\n          ...,\n          [-0.03597102,  0.0186976 , -0.02074138, ...,  0.02211762,\n            0.00287962, -0.01700178],\n          [-0.02888129, -0.00340436,  0.01780878, ...,  0.02259069,\n           -0.03013807,  0.0168451 ],\n          [-0.02352575, -0.01379407,  0.01161824, ..., -0.04682424,\n           -0.00010278, -0.03987736]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_159/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_159/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_159/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_155/kernel:0' shape=(1, 1, 768, 192) dtype=float32, numpy=\n array([[[[ 0.03313433, -0.05319364,  0.00367203, ...,  0.05998405,\n            0.03240174, -0.05529174],\n          [ 0.07252317, -0.06738673,  0.02129239, ...,  0.00379109,\n           -0.00528488, -0.0723835 ],\n          [-0.04337373,  0.04483116, -0.05394616, ..., -0.01529733,\n           -0.07766037, -0.06133801],\n          ...,\n          [-0.05623727,  0.05884656, -0.05116101, ...,  0.03105774,\n            0.0750804 , -0.0444729 ],\n          [ 0.04285704, -0.05885513, -0.03086426, ..., -0.01027618,\n            0.03738876, -0.02494192],\n          [-0.0033148 ,  0.0332537 ,  0.00521653, ...,  0.00907806,\n           -0.07027826,  0.0589763 ]]]], dtype=float32)>,\n <tf.Variable 'conv2d_160/kernel:0' shape=(1, 7, 192, 192) dtype=float32, numpy=\n array([[[[ 0.01379274,  0.00070235,  0.02011934, ..., -0.02363808,\n            0.02701777,  0.00930075],\n          [-0.00324149,  0.04083813,  0.02962193, ..., -0.0344942 ,\n           -0.02984547, -0.04661089],\n          [-0.01932094,  0.01550225,  0.0401533 , ...,  0.04320371,\n            0.00018178,  0.01091219],\n          ...,\n          [ 0.04282882, -0.00444877,  0.03478811, ...,  0.03144315,\n            0.00292831, -0.03704447],\n          [-0.03100544,  0.02469132,  0.00695679, ...,  0.00476735,\n            0.02541098,  0.04440771],\n          [ 0.0366577 , -0.04692356, -0.04396918, ...,  0.043167  ,\n           -0.02957794, -0.0221574 ]],\n \n         [[ 0.03056445,  0.01555282,  0.02429342, ...,  0.03965475,\n            0.03021826,  0.00186514],\n          [ 0.01693321,  0.00913228,  0.03393422, ...,  0.01244096,\n           -0.03100364, -0.01829319],\n          [ 0.01377301, -0.04529737,  0.02921301, ..., -0.02320678,\n           -0.0015993 , -0.01847717],\n          ...,\n          [-0.03904522, -0.01474021, -0.00718768, ...,  0.04430347,\n            0.03451639,  0.04471248],\n          [-0.02213086,  0.03549683,  0.00593388, ..., -0.00520018,\n            0.01153367, -0.03390637],\n          [ 0.0097759 , -0.03815478, -0.00901067, ...,  0.01393804,\n            0.01244489, -0.03639624]],\n \n         [[ 0.00080444, -0.00396647, -0.018116  , ...,  0.01319254,\n           -0.04480805,  0.02101566],\n          [ 0.03811476,  0.02160979,  0.03336456, ...,  0.04630808,\n            0.00586735, -0.04384656],\n          [ 0.02074619,  0.01866204,  0.00351283, ...,  0.0296482 ,\n            0.04266003,  0.00063507],\n          ...,\n          [-0.00797734,  0.0325698 ,  0.04464767, ...,  0.03990596,\n           -0.02259335,  0.04018626],\n          [ 0.00878891,  0.00895743, -0.02269951, ..., -0.00341629,\n           -0.01637553,  0.00341505],\n          [-0.02555538, -0.00958828, -0.01459461, ...,  0.04231754,\n            0.01349219,  0.01390762]],\n \n         ...,\n \n         [[ 0.03429191,  0.00403069,  0.01754729, ...,  0.01259932,\n           -0.01977665, -0.02918541],\n          [-0.00779951, -0.03950204,  0.03820684, ...,  0.02240914,\n           -0.01586898,  0.00425604],\n          [-0.01093422,  0.02043042,  0.00637705, ...,  0.01984701,\n            0.01377874, -0.03590512],\n          ...,\n          [ 0.03855423,  0.01731282, -0.02239374, ...,  0.03243158,\n            0.0011174 ,  0.03157848],\n          [ 0.01605987,  0.01176909,  0.03409607, ..., -0.02115448,\n            0.0224413 ,  0.01611311],\n          [ 0.0090836 , -0.0069753 ,  0.02950421, ..., -0.03654142,\n           -0.01063614,  0.03040627]],\n \n         [[ 0.01051857,  0.02689075,  0.04340651, ..., -0.00719355,\n           -0.0079908 ,  0.0329618 ],\n          [ 0.01431492, -0.0110711 , -0.002121  , ..., -0.04395945,\n            0.01252224, -0.01311407],\n          [-0.01589004,  0.02739203,  0.01018039, ..., -0.00508689,\n            0.02507781,  0.0412623 ],\n          ...,\n          [-0.00064275,  0.0257117 , -0.03794334, ..., -0.01563095,\n            0.04558834,  0.01077393],\n          [-0.02629708,  0.03305004,  0.01626471, ..., -0.0147745 ,\n            0.04332316,  0.03098067],\n          [ 0.01810941, -0.04171492, -0.00832991, ...,  0.01972592,\n            0.02779282, -0.04109499]],\n \n         [[-0.00705687, -0.0393452 , -0.02422296, ...,  0.04253392,\n           -0.04116971,  0.02907078],\n          [-0.03572581, -0.04484186,  0.00163911, ...,  0.01120864,\n            0.01323561, -0.04179873],\n          [ 0.02405738,  0.01275667, -0.02068068, ..., -0.01874079,\n           -0.01797501,  0.00448463],\n          ...,\n          [-0.00536168,  0.01138278,  0.0384012 , ..., -0.0226538 ,\n           -0.02165169, -0.00332547],\n          [-0.04284988,  0.02631937, -0.02935693, ...,  0.00095365,\n            0.02045148,  0.02161991],\n          [-0.03542135,  0.02348607, -0.01257986, ...,  0.0283059 ,\n           -0.00355561,  0.027457  ]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_155/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_155/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_155/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_160/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_160/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_160/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_156/kernel:0' shape=(1, 7, 192, 192) dtype=float32, numpy=\n array([[[[ 0.04192295,  0.02362185,  0.01481728, ..., -0.04069083,\n           -0.02620667, -0.015926  ],\n          [-0.00538038, -0.01858418, -0.00924999, ...,  0.03385342,\n            0.02233757,  0.01915223],\n          [ 0.02172292, -0.0222272 ,  0.03771463, ...,  0.01276252,\n            0.00390375, -0.01317758],\n          ...,\n          [ 0.01981674,  0.04233265, -0.02185186, ...,  0.01397568,\n            0.02331125,  0.03666464],\n          [ 0.03034544,  0.00381448, -0.02019375, ...,  0.03738401,\n            0.00666658,  0.02585421],\n          [-0.00552241, -0.04295335, -0.0051822 , ...,  0.02383505,\n           -0.0287924 ,  0.03331969]],\n \n         [[-0.01356783,  0.03737037,  0.02427628, ...,  0.03415832,\n           -0.00690836,  0.03093715],\n          [ 0.00688475,  0.00221787, -0.00389825, ...,  0.01024158,\n            0.0014199 ,  0.02506563],\n          [ 0.04646834,  0.00017551, -0.00837578, ...,  0.01595497,\n            0.03461114,  0.01536969],\n          ...,\n          [-0.01405041, -0.0374687 , -0.00640544, ..., -0.03526722,\n            0.02914372,  0.04283897],\n          [-0.02354731,  0.01998479,  0.03233929, ..., -0.03469598,\n           -0.04311336, -0.02457281],\n          [-0.00242857,  0.00603358,  0.01005333, ...,  0.00592389,\n            0.02911125,  0.0428597 ]],\n \n         [[ 0.03735505, -0.03855193,  0.03975577, ...,  0.03723172,\n           -0.02408892,  0.02812348],\n          [ 0.01288078,  0.01377678, -0.04113749, ...,  0.00622259,\n            0.00361634, -0.01806294],\n          [ 0.02301425,  0.01568851,  0.00043847, ..., -0.03770702,\n           -0.03008145,  0.00842288],\n          ...,\n          [ 0.03592269,  0.00804311, -0.01644761, ..., -0.03744339,\n           -0.01776055,  0.01798059],\n          [ 0.02801665,  0.03141617,  0.02223345, ...,  0.03890539,\n            0.03019051, -0.02701902],\n          [-0.01887304, -0.00855704, -0.0442475 , ..., -0.03854398,\n            0.02560348,  0.03674281]],\n \n         ...,\n \n         [[-0.01607186,  0.01798039,  0.00831519, ..., -0.00158573,\n            0.02436792,  0.02187138],\n          [-0.02590196,  0.01142926,  0.02191588, ..., -0.03506515,\n            0.00523593, -0.01515181],\n          [ 0.01430108, -0.00309611,  0.02646437, ..., -0.04244656,\n           -0.00827713,  0.01413771],\n          ...,\n          [ 0.04100499,  0.04381787, -0.01962359, ..., -0.01392974,\n           -0.0233093 , -0.03152087],\n          [ 0.01867754,  0.03022734,  0.03116817, ..., -0.02902288,\n            0.02583664,  0.04272121],\n          [ 0.04151824,  0.01899513, -0.01757764, ...,  0.04120126,\n           -0.01733051, -0.02498706]],\n \n         [[-0.01398212, -0.02537203,  0.04514882, ..., -0.023755  ,\n            0.01799324,  0.04508292],\n          [-0.03890273, -0.01591124, -0.02687806, ..., -0.02734083,\n           -0.00305059,  0.03213307],\n          [-0.03410659,  0.02873925,  0.01714603, ...,  0.0372364 ,\n            0.03333417,  0.03302432],\n          ...,\n          [-0.01401142, -0.01002084,  0.03041667, ...,  0.04299043,\n           -0.02228891,  0.04521095],\n          [-0.03100985, -0.03614933, -0.04695133, ..., -0.02196154,\n           -0.01278401,  0.01951541],\n          [ 0.02327802, -0.00723353, -0.01839769, ..., -0.01445372,\n           -0.00715882, -0.00479084]],\n \n         [[ 0.03694579, -0.01656575,  0.00641723, ...,  0.00621513,\n            0.03922479,  0.01778637],\n          [ 0.01411737, -0.01639925,  0.0055977 , ...,  0.01972321,\n           -0.00464823, -0.04715465],\n          [-0.03977202, -0.02466494,  0.01714763, ..., -0.04645429,\n            0.02790797, -0.04119851],\n          ...,\n          [-0.04712534, -0.02138516, -0.02632055, ..., -0.0321532 ,\n            0.04312906,  0.0456509 ],\n          [-0.04463591,  0.01352764, -0.00693786, ..., -0.04609068,\n           -0.04421002, -0.00445097],\n          [-0.02152881, -0.00514301,  0.02009834, ...,  0.01365369,\n           -0.03284118, -0.0446428 ]]]], dtype=float32)>,\n <tf.Variable 'conv2d_161/kernel:0' shape=(7, 1, 192, 192) dtype=float32, numpy=\n array([[[[-0.03959629, -0.03764157, -0.0301559 , ..., -0.0439779 ,\n            0.02247436, -0.03170975],\n          [-0.02496446,  0.01667313, -0.00796032, ..., -0.000898  ,\n           -0.01201824, -0.01435598],\n          [ 0.02857378,  0.01708906,  0.00255898, ..., -0.02669551,\n           -0.04427841,  0.00555253],\n          ...,\n          [ 0.00507731, -0.02425627,  0.02146605, ...,  0.04588005,\n           -0.02180158,  0.01365552],\n          [ 0.0045124 , -0.0338503 ,  0.04342424, ..., -0.04532264,\n           -0.02794181, -0.02310782],\n          [ 0.00930895,  0.03239997, -0.02472124, ..., -0.04659322,\n           -0.01165759,  0.04525571]]],\n \n \n        [[[-0.02946957,  0.01256267,  0.0122447 , ...,  0.00748631,\n            0.01220341,  0.00026827],\n          [-0.01814205, -0.04632672,  0.0060522 , ..., -0.02369363,\n            0.01612655, -0.0259818 ],\n          [-0.01552614,  0.00116308,  0.02237907, ..., -0.01725937,\n           -0.00246478,  0.00711283],\n          ...,\n          [ 0.04243946, -0.01302379, -0.02689924, ..., -0.03792937,\n           -0.03587182,  0.02736505],\n          [-0.0043054 , -0.01315406,  0.02607076, ..., -0.02272391,\n            0.00979875, -0.03890288],\n          [-0.02139442, -0.04023388,  0.00179439, ..., -0.02156152,\n           -0.04587958, -0.00791059]]],\n \n \n        [[[-0.02402971, -0.00142542,  0.01347457, ..., -0.03762426,\n            0.01871706,  0.00518902],\n          [-0.03163549, -0.03431631, -0.04242741, ...,  0.02661477,\n           -0.01812798, -0.00138505],\n          [-0.01034553, -0.03807995, -0.00535087, ..., -0.0188772 ,\n           -0.03387012,  0.00923366],\n          ...,\n          [ 0.03971862,  0.02715027, -0.02711382, ...,  0.03502062,\n           -0.01758072, -0.03824903],\n          [-0.04101267, -0.02322304, -0.02032219, ..., -0.02546541,\n           -0.00260397, -0.01889727],\n          [ 0.00467128,  0.0201964 , -0.00210376, ..., -0.03305244,\n            0.03040991,  0.0206851 ]]],\n \n \n        ...,\n \n \n        [[[ 0.0401989 ,  0.00329761,  0.00727074, ..., -0.04613138,\n           -0.02341741, -0.02455546],\n          [ 0.04518044,  0.0228972 , -0.02559647, ...,  0.01579384,\n           -0.00131736, -0.02349992],\n          [ 0.00954985, -0.01505201, -0.00017979, ..., -0.04342195,\n           -0.03022525,  0.00181703],\n          ...,\n          [-0.01357166,  0.00906209, -0.01678853, ..., -0.00510421,\n           -0.02748773,  0.03613206],\n          [ 0.02516649,  0.03908886, -0.01779552, ...,  0.00979286,\n            0.04283039, -0.00161429],\n          [-0.02609001, -0.01157868, -0.03995517, ...,  0.01933319,\n            0.01494961, -0.03403183]]],\n \n \n        [[[ 0.02650947,  0.01132619,  0.00781931, ..., -0.00383175,\n           -0.02576574, -0.04636749],\n          [ 0.04374835, -0.02959798,  0.03377934, ...,  0.04368314,\n            0.00226227,  0.04541446],\n          [-0.02547124,  0.02963217, -0.04164325, ..., -0.02959939,\n           -0.00513933, -0.03791966],\n          ...,\n          [-0.01935053, -0.04362095, -0.02944756, ..., -0.02389595,\n            0.03566695, -0.01420462],\n          [ 0.00537236,  0.04451725,  0.04241083, ...,  0.02060051,\n            0.0108113 , -0.02227694],\n          [ 0.04537689, -0.00872931,  0.02059397, ..., -0.03137935,\n            0.00046189, -0.0258265 ]]],\n \n \n        [[[ 0.01328635,  0.00567825, -0.0172078 , ..., -0.02981024,\n            0.01950441,  0.00536726],\n          [ 0.01405802,  0.0228574 ,  0.01792083, ..., -0.0034784 ,\n           -0.04605561, -0.02285262],\n          [ 0.04649938, -0.00969803, -0.04411481, ..., -0.04142237,\n           -0.04411551,  0.00727324],\n          ...,\n          [ 0.00392851,  0.01205485, -0.0432798 , ...,  0.03142514,\n            0.03040649,  0.00279285],\n          [ 0.02310334,  0.01873619,  0.04605952, ..., -0.03113501,\n            0.03032744,  0.03984192],\n          [ 0.04478129, -0.03408042,  0.02555254, ...,  0.04509316,\n            0.03717136,  0.041     ]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_156/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_156/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_156/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_161/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_161/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_161/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_154/kernel:0' shape=(1, 1, 768, 192) dtype=float32, numpy=\n array([[[[ 1.2150548e-02, -4.2995658e-02,  3.2066628e-03, ...,\n            1.8265657e-02,  4.2408705e-05,  2.2124946e-03],\n          [-5.0096754e-02, -2.0627409e-02, -3.5184387e-02, ...,\n           -3.3720806e-02,  5.5355005e-02, -2.5367521e-02],\n          [-2.8182473e-02, -3.2039508e-03, -6.1713248e-02, ...,\n            3.9119571e-03,  3.4128278e-03,  3.0880935e-02],\n          ...,\n          [-1.6920127e-02,  5.2685715e-02, -7.6909855e-02, ...,\n           -3.7143249e-02, -5.6378856e-02,  4.5514740e-02],\n          [ 5.6462057e-02, -7.6247044e-02, -3.0703612e-02, ...,\n            7.8900926e-02,  2.3749426e-02, -4.3485235e-02],\n          [-7.4255705e-02, -3.3905093e-02, -6.7300946e-03, ...,\n           -5.9368044e-02, -3.4156512e-02,  6.3392669e-03]]]],\n       dtype=float32)>,\n <tf.Variable 'conv2d_157/kernel:0' shape=(7, 1, 192, 192) dtype=float32, numpy=\n array([[[[-0.03176367,  0.03204187,  0.04241514, ..., -0.01007857,\n           -0.01701816, -0.01518921],\n          [-0.00304231,  0.0420442 ,  0.03121509, ...,  0.03988648,\n           -0.01721971, -0.02726942],\n          [-0.02203237, -0.01208336,  0.00684524, ..., -0.04562004,\n            0.03467285,  0.03745171],\n          ...,\n          [ 0.02106183, -0.02600086, -0.01670259, ...,  0.00093687,\n            0.0344014 , -0.00903159],\n          [-0.02481699, -0.01911901,  0.04073074, ..., -0.04544695,\n           -0.03273362, -0.01121134],\n          [-0.02745001, -0.03067753, -0.03078535, ..., -0.00653881,\n           -0.00157513,  0.03999325]]],\n \n \n        [[[-0.03818561, -0.02296592, -0.04467424, ..., -0.04335917,\n            0.00420192,  0.04623782],\n          [-0.01609665,  0.04685402,  0.00915375, ...,  0.00463706,\n            0.03055437,  0.00164368],\n          [ 0.01540364,  0.01322763, -0.02579457, ..., -0.00778217,\n            0.03093592,  0.04093553],\n          ...,\n          [-0.00068046,  0.03733918,  0.02464372, ...,  0.00259131,\n           -0.00539797,  0.01400406],\n          [-0.03755359,  0.03247618, -0.00476914, ...,  0.00081271,\n           -0.03666769,  0.03551489],\n          [ 0.01576173,  0.0244786 ,  0.02993679, ...,  0.03047354,\n            0.00791893, -0.04318582]]],\n \n \n        [[[-0.0136003 , -0.03314213,  0.03542453, ...,  0.04715749,\n           -0.03287376, -0.04248628],\n          [ 0.01661189, -0.00878456, -0.04695508, ...,  0.01965009,\n            0.02271246,  0.01022926],\n          [ 0.01946897, -0.01614077, -0.01157252, ..., -0.03444637,\n           -0.04687409, -0.0058286 ],\n          ...,\n          [ 0.00421997,  0.04082827, -0.02751381, ..., -0.0269314 ,\n           -0.04273862,  0.02190624],\n          [ 0.03019945, -0.03678172, -0.00902378, ...,  0.00216916,\n           -0.04031853,  0.01342787],\n          [ 0.04375054,  0.03856472, -0.03776663, ...,  0.02978802,\n            0.04060404, -0.02236118]]],\n \n \n        ...,\n \n \n        [[[ 0.03116102, -0.01573059, -0.04554128, ...,  0.00489504,\n            0.00179389,  0.02595201],\n          [-0.02588717,  0.03087133,  0.02937321, ...,  0.02397327,\n           -0.00979232, -0.03861443],\n          [-0.03061224, -0.01726337, -0.03477583, ...,  0.01531399,\n           -0.00309306, -0.01430358],\n          ...,\n          [-0.01359572, -0.03036612, -0.04053019, ..., -0.03946804,\n           -0.03611865,  0.00592601],\n          [-0.01844395,  0.00970361, -0.01244472, ...,  0.0164698 ,\n           -0.01942733, -0.03437347],\n          [-0.00992771,  0.00961295, -0.0451959 , ..., -0.03892005,\n            0.01888127, -0.04380807]]],\n \n \n        [[[ 0.03884731,  0.03546407, -0.00797817, ..., -0.015057  ,\n            0.00105651,  0.00774575],\n          [-0.02912615,  0.04600428, -0.01354691, ...,  0.01598724,\n            0.03570735,  0.01936777],\n          [-0.00940689, -0.03230089,  0.02114321, ..., -0.01900231,\n            0.01773288,  0.03498368],\n          ...,\n          [-0.0366331 ,  0.04672798,  0.02513707, ...,  0.03985602,\n            0.03457197,  0.0127889 ],\n          [ 0.041649  ,  0.00075151,  0.03882419, ..., -0.03628847,\n            0.00966626, -0.02948557],\n          [-0.02559742,  0.00222983,  0.01763306, ...,  0.03875424,\n            0.00284318, -0.00904014]]],\n \n \n        [[[-0.00433707,  0.03855443,  0.03720913, ...,  0.04288556,\n           -0.04521031,  0.02793453],\n          [ 0.02220445, -0.04657492,  0.04305351, ..., -0.00412153,\n           -0.04261406,  0.04079504],\n          [-0.04420166, -0.02227076,  0.03569309, ...,  0.04293611,\n            0.023294  , -0.0408502 ],\n          ...,\n          [-0.00371297, -0.03669592, -0.00058879, ...,  0.02241743,\n            0.01958079, -0.01271001],\n          [-0.02636391,  0.00433546,  0.02574319, ..., -0.0463193 ,\n            0.04546173, -0.00148397],\n          [ 0.00701759,  0.02409327,  0.02207661, ..., -0.006747  ,\n           -0.04517719,  0.0024289 ]]]], dtype=float32)>,\n <tf.Variable 'conv2d_162/kernel:0' shape=(1, 7, 192, 192) dtype=float32, numpy=\n array([[[[-0.01628823,  0.03541588,  0.03418859, ..., -0.02382993,\n           -0.04202877, -0.00693118],\n          [-0.00775868, -0.04672375, -0.00450873, ...,  0.02389329,\n            0.01861615, -0.01009031],\n          [-0.0282367 ,  0.02993606, -0.04618571, ..., -0.01223316,\n            0.03759811,  0.04111517],\n          ...,\n          [ 0.00437758,  0.00935113, -0.03784746, ...,  0.0163433 ,\n           -0.03324687,  0.04215089],\n          [-0.02142498,  0.01706654,  0.0257163 , ..., -0.03341077,\n            0.04052492, -0.02199911],\n          [ 0.00872319,  0.03186539, -0.04379472, ..., -0.02718868,\n           -0.02106552, -0.0147101 ]],\n \n         [[-0.03540051,  0.01190852,  0.01970566, ..., -0.00646138,\n           -0.02381566, -0.03763539],\n          [-0.03137488,  0.03267964,  0.01374129, ..., -0.00624591,\n            0.029558  , -0.04377968],\n          [-0.01869112,  0.01724372, -0.03269022, ..., -0.0307049 ,\n           -0.00493994,  0.02342809],\n          ...,\n          [ 0.03404767, -0.03200754, -0.02663933, ...,  0.02293592,\n           -0.02369883,  0.04278914],\n          [ 0.02144385, -0.01319076, -0.03800054, ..., -0.04241584,\n           -0.02935395,  0.02538059],\n          [-0.01943296, -0.04673444, -0.03848023, ...,  0.0287089 ,\n            0.00843884,  0.00990015]],\n \n         [[ 0.02361629, -0.00249055, -0.03697241, ..., -0.03230254,\n           -0.01674351, -0.01229343],\n          [-0.017914  , -0.02799119,  0.00120359, ...,  0.00238992,\n           -0.04404793, -0.02999004],\n          [ 0.0143062 ,  0.03630789,  0.00824595, ..., -0.00760373,\n           -0.01503814, -0.01200672],\n          ...,\n          [ 0.02359285, -0.01544481, -0.01009791, ...,  0.04140117,\n           -0.02873827, -0.0107019 ],\n          [-0.01458587, -0.00811087, -0.00602819, ...,  0.00920708,\n            0.00397995,  0.0274469 ],\n          [-0.04190777,  0.04048413, -0.01698303, ..., -0.00272883,\n            0.03331514,  0.01578647]],\n \n         ...,\n \n         [[-0.025099  , -0.04291287, -0.00095007, ..., -0.04484421,\n           -0.00768996, -0.0344043 ],\n          [ 0.01577478, -0.03213542, -0.03823574, ...,  0.00220775,\n           -0.03090264, -0.02378848],\n          [-0.01523728,  0.03604515, -0.01169247, ..., -0.0390395 ,\n           -0.02616823, -0.04173402],\n          ...,\n          [ 0.01830463, -0.04392887, -0.0151059 , ..., -0.00248627,\n           -0.00897017,  0.02715562],\n          [-0.03824073, -0.00854437,  0.0184155 , ..., -0.04708087,\n           -0.00048388, -0.02359202],\n          [ 0.02785132, -0.01160575,  0.00251264, ..., -0.00105866,\n            0.03762186,  0.04688146]],\n \n         [[-0.03910889,  0.04273079,  0.0380728 , ...,  0.0349498 ,\n            0.00875746, -0.02177129],\n          [-0.00666039, -0.03944126, -0.04526883, ...,  0.02403631,\n           -0.01210858,  0.01765965],\n          [ 0.01934703,  0.00225705, -0.04581293, ..., -0.02848534,\n            0.04434534, -0.02774537],\n          ...,\n          [ 0.02866903,  0.03417968, -0.03105256, ...,  0.02730272,\n            0.0125064 , -0.01431809],\n          [ 0.03913122, -0.0054561 ,  0.0300562 , ...,  0.01607583,\n           -0.03417963,  0.02571305],\n          [-0.0057225 ,  0.04303643, -0.01151361, ...,  0.03061319,\n            0.02234426, -0.02245975]],\n \n         [[-0.04187381, -0.01068234, -0.04321527, ..., -0.0208695 ,\n           -0.00937824,  0.03901624],\n          [-0.04378096, -0.04478769, -0.03528538, ...,  0.0152885 ,\n            0.00111929,  0.00878243],\n          [ 0.02803796, -0.02813494,  0.01786032, ..., -0.02216266,\n            0.04273715,  0.01395856],\n          ...,\n          [-0.02844618, -0.03191545,  0.01334239, ..., -0.01244709,\n            0.03264297,  0.03820613],\n          [-0.01435549, -0.00634314, -0.00271336, ...,  0.01989727,\n            0.0009576 ,  0.03982225],\n          [ 0.01904563,  0.00454354,  0.02386839, ..., -0.01413246,\n            0.01937323, -0.04130819]]]], dtype=float32)>,\n <tf.Variable 'conv2d_163/kernel:0' shape=(1, 1, 768, 192) dtype=float32, numpy=\n array([[[[ 0.06276064, -0.00588979,  0.04383776, ..., -0.00187651,\n            0.048443  , -0.0436849 ],\n          [ 0.04937398,  0.06887836,  0.06463226, ...,  0.05947991,\n           -0.03231272,  0.07807564],\n          [-0.04206207, -0.02610028, -0.04451931, ..., -0.05660515,\n            0.04305978, -0.06141043],\n          ...,\n          [ 0.04536865, -0.04003699,  0.01730196, ...,  0.05512365,\n            0.00318717, -0.04879576],\n          [-0.03768707,  0.07098109, -0.02960609, ...,  0.04684349,\n            0.00071464, -0.00439791],\n          [ 0.04179703,  0.07320214,  0.0669832 , ...,  0.06770048,\n            0.06001056, -0.03202697]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_154/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_154/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_154/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_157/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_157/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_157/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_162/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_162/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_162/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_163/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_163/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_163/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_166/kernel:0' shape=(1, 1, 768, 192) dtype=float32, numpy=\n array([[[[-0.07844315,  0.03220238, -0.03265241, ...,  0.06572849,\n            0.03212516, -0.04425501],\n          [ 0.00744107,  0.03718106, -0.00368384, ...,  0.04013594,\n            0.02136269, -0.02809703],\n          [ 0.04601338,  0.04369052,  0.03122732, ...,  0.0196401 ,\n            0.01356102, -0.07539983],\n          ...,\n          [ 0.01964851,  0.07416702, -0.04770482, ..., -0.06355966,\n           -0.02520661, -0.05697887],\n          [-0.03364803,  0.03245499, -0.07586049, ..., -0.05632063,\n            0.02759543, -0.07285981],\n          [-0.06618772,  0.06691461,  0.05845723, ..., -0.01460691,\n           -0.02558588,  0.04588706]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_166/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_166/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_166/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_167/kernel:0' shape=(1, 7, 192, 192) dtype=float32, numpy=\n array([[[[-1.39537528e-02, -4.48890030e-04, -4.45861369e-03, ...,\n           -2.56205220e-02,  3.93866487e-02, -3.01334187e-02],\n          [ 2.64250897e-02,  1.96625926e-02,  1.17420815e-02, ...,\n           -2.07737759e-02,  4.21489291e-02,  4.31769900e-02],\n          [-2.24360935e-02, -1.82052199e-02,  1.81698613e-02, ...,\n            2.28265040e-02,  1.60035677e-02,  3.32738049e-02],\n          ...,\n          [ 2.29887664e-05,  3.07529084e-02, -8.51810351e-03, ...,\n           -4.44510728e-02, -1.85551308e-02, -3.01626828e-02],\n          [ 2.34149732e-02, -2.28534900e-02, -3.31032872e-02, ...,\n           -1.92314796e-02, -1.67747084e-02, -2.57845297e-02],\n          [ 1.07908994e-03,  1.70560442e-02,  4.23520096e-02, ...,\n           -1.48506351e-02,  4.50105108e-02,  9.45358723e-03]],\n \n         [[-4.30928022e-02,  2.42970251e-02, -2.64784619e-02, ...,\n           -8.79830122e-03, -2.69833580e-02, -4.28375974e-02],\n          [-3.72328833e-02,  2.51244493e-02,  3.74725051e-02, ...,\n           -1.41610503e-02,  4.00194265e-02, -4.36195508e-02],\n          [-2.99243890e-02,  4.71378081e-02,  1.42619200e-02, ...,\n            1.77936368e-02, -3.36128846e-03, -1.88082606e-02],\n          ...,\n          [ 3.78714316e-02,  4.62847315e-02, -2.17517707e-02, ...,\n           -4.51479144e-02, -2.83666607e-02, -5.37521765e-03],\n          [ 4.54314090e-02, -7.86596164e-03,  1.72441415e-02, ...,\n           -4.08424251e-02,  1.03836954e-02, -3.53435352e-02],\n          [-2.66396869e-02,  1.24213845e-03,  4.54532094e-02, ...,\n           -8.84473324e-03, -6.84664026e-03,  1.55158527e-02]],\n \n         [[ 3.89072783e-02,  1.31611377e-02,  4.04401310e-02, ...,\n           -4.27175462e-02, -4.32082042e-02, -7.20605999e-03],\n          [-1.28236040e-02,  9.63042304e-03, -1.20643601e-02, ...,\n            1.91298239e-02,  2.03683190e-02, -1.88818611e-02],\n          [ 1.43687166e-02, -1.30753964e-03,  1.02625042e-02, ...,\n            2.55382918e-02, -1.90794356e-02,  1.72639601e-02],\n          ...,\n          [-3.72250676e-02,  1.19923837e-02,  3.78840230e-02, ...,\n           -2.74628531e-02, -9.77556407e-03,  4.52994816e-02],\n          [-3.41146551e-02, -4.10128646e-02, -3.61796692e-02, ...,\n           -2.09347755e-02, -1.74115542e-02,  3.52248587e-02],\n          [ 4.15669270e-02, -2.81823538e-02, -4.62514795e-02, ...,\n            2.69303359e-02, -3.37237976e-02,  1.83342732e-02]],\n \n         ...,\n \n         [[ 9.09257680e-04, -4.27387655e-02, -4.08550054e-02, ...,\n            1.09708868e-02, -1.81786343e-03, -2.55148523e-02],\n          [ 4.15691473e-02, -4.48266901e-02, -1.10030174e-04, ...,\n           -9.45093855e-03,  1.42440572e-03, -1.44905262e-02],\n          [ 1.56562775e-04, -1.57691725e-02, -4.44124155e-02, ...,\n            3.81321050e-02,  3.64194848e-02,  3.48949805e-03],\n          ...,\n          [ 4.92144376e-04, -4.61604632e-02,  2.36267187e-02, ...,\n            2.81446390e-02, -2.74705142e-03,  1.39917918e-02],\n          [-3.36624756e-02, -1.43714771e-02,  1.71571933e-02, ...,\n            2.31912844e-02,  3.33199613e-02,  4.64553945e-02],\n          [ 6.50170818e-03, -2.59330031e-02,  4.36964594e-02, ...,\n           -1.87915191e-03,  7.32587650e-03, -3.17457244e-02]],\n \n         [[ 3.02035920e-02,  7.27418438e-03, -2.06416249e-02, ...,\n            3.17618288e-02,  1.09826587e-02,  2.35555656e-02],\n          [ 1.78896599e-02,  3.80308069e-02, -2.08933577e-02, ...,\n           -1.40852295e-02,  2.04498880e-02,  4.47500981e-02],\n          [-2.02249717e-02, -1.95408072e-02,  1.79409720e-02, ...,\n            3.74280848e-02, -2.12995559e-02, -3.91948745e-02],\n          ...,\n          [ 4.45987619e-02,  1.72780491e-02,  3.73961516e-02, ...,\n            2.45020278e-02, -3.73192579e-02,  3.27127017e-02],\n          [ 2.79572867e-02,  2.44475938e-02, -2.16825064e-02, ...,\n            2.16896124e-02, -4.64952923e-02, -1.83438715e-02],\n          [ 2.99090259e-02, -3.05353031e-02, -2.04273239e-02, ...,\n            4.50948887e-02, -3.41083929e-02,  7.64769316e-03]],\n \n         [[ 3.23223285e-02, -4.34888303e-02, -2.93918625e-02, ...,\n           -8.72556865e-03, -1.39054209e-02, -1.81372855e-02],\n          [-1.08256936e-05,  1.15379319e-03,  2.14868225e-02, ...,\n            2.87200101e-02, -3.65338847e-02,  3.66967954e-02],\n          [-2.32258737e-02,  1.36559829e-02,  3.98949347e-02, ...,\n           -3.53986770e-02,  1.58183314e-02, -9.01248306e-04],\n          ...,\n          [-3.78825814e-02,  1.32519603e-02,  4.50377800e-02, ...,\n            9.93698835e-03,  1.70605630e-03, -4.36595269e-02],\n          [-6.55087456e-03, -4.57613543e-03,  2.65442096e-02, ...,\n            6.15315884e-03,  2.97632106e-02,  4.64432500e-02],\n          [ 1.34262070e-02,  4.55340259e-02, -4.69330996e-02, ...,\n           -1.84879396e-02, -4.37004268e-02, -4.02158648e-02]]]],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_167/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_167/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_167/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_164/kernel:0' shape=(1, 1, 768, 192) dtype=float32, numpy=\n array([[[[ 0.05980922,  0.01356575, -0.03311477, ..., -0.06795441,\n           -0.07126408, -0.00729933],\n          [-0.00326297,  0.06725081, -0.02366868, ...,  0.03450148,\n           -0.01593734,  0.0601928 ],\n          [ 0.07749555, -0.01402424,  0.03186878, ...,  0.01611005,\n            0.04084484,  0.06257141],\n          ...,\n          [-0.03718738,  0.00437886, -0.02343808, ..., -0.05581491,\n            0.01271045, -0.05013745],\n          [-0.04587381, -0.02895687,  0.04637139, ...,  0.02813269,\n            0.04336869,  0.04779641],\n          [-0.00700457,  0.0588825 , -0.07807519, ..., -0.03974715,\n            0.04003312, -0.04703038]]]], dtype=float32)>,\n <tf.Variable 'conv2d_168/kernel:0' shape=(7, 1, 192, 192) dtype=float32, numpy=\n array([[[[ 0.00086467, -0.0209574 , -0.00867154, ..., -0.02580711,\n            0.01709498, -0.01352981],\n          [-0.03329226, -0.02644969, -0.02410973, ...,  0.0410351 ,\n           -0.04461382,  0.0310074 ],\n          [-0.02711513,  0.00174196,  0.02196799, ...,  0.03747735,\n           -0.02426421,  0.03723087],\n          ...,\n          [-0.01161499, -0.04292184,  0.03448683, ...,  0.04462068,\n            0.03677687,  0.02836656],\n          [-0.01031564, -0.02468905, -0.03632875, ...,  0.03520994,\n            0.02109081, -0.00176129],\n          [ 0.0297449 ,  0.04217197, -0.00726513, ..., -0.03584378,\n           -0.01662493, -0.01306847]]],\n \n \n        [[[ 0.03088675,  0.00368055, -0.03688871, ...,  0.01701991,\n           -0.03750997,  0.01801   ],\n          [-0.03195792, -0.01854164,  0.02846906, ...,  0.02311758,\n           -0.02147613,  0.03528498],\n          [-0.01353329,  0.02769396, -0.02048362, ...,  0.03441652,\n            0.00141012, -0.01035828],\n          ...,\n          [-0.03259645, -0.00099804, -0.02104466, ..., -0.02063574,\n           -0.03103341,  0.00922241],\n          [-0.03422614,  0.04291824, -0.02174116, ...,  0.01523922,\n           -0.01795165, -0.03567436],\n          [ 0.04249237, -0.00027788,  0.00453762, ..., -0.03415825,\n            0.03899104, -0.03821912]]],\n \n \n        [[[-0.04585221,  0.03939271,  0.02730986, ...,  0.04242505,\n           -0.04131238, -0.03988976],\n          [ 0.02062458, -0.00668855, -0.03245897, ...,  0.00309164,\n            0.04588047,  0.01441249],\n          [-0.04298382,  0.01962745,  0.01607734, ...,  0.00753447,\n           -0.01993006, -0.03343249],\n          ...,\n          [ 0.03715393, -0.02561608, -0.00127441, ..., -0.0293844 ,\n           -0.03905597,  0.04074826],\n          [-0.01657527,  0.02750101,  0.03007986, ..., -0.02892128,\n           -0.00226145,  0.02018366],\n          [ 0.03196299, -0.02802865, -0.0445881 , ...,  0.04055755,\n            0.03039962,  0.00960581]]],\n \n \n        ...,\n \n \n        [[[ 0.04030268, -0.02621258,  0.00794838, ..., -0.03771652,\n            0.0252152 ,  0.00967715],\n          [ 0.0440034 , -0.01414901, -0.03385057, ..., -0.0451817 ,\n           -0.01063561, -0.04107522],\n          [ 0.04370572, -0.03058895, -0.03233061, ...,  0.01608353,\n           -0.00112066, -0.00315171],\n          ...,\n          [-0.03449472,  0.02392096,  0.00435963, ...,  0.01237903,\n            0.03818956,  0.01151356],\n          [ 0.0028943 , -0.00731514, -0.00923824, ...,  0.03659041,\n            0.04110164,  0.02292993],\n          [ 0.03642213, -0.01268969, -0.03586133, ...,  0.04463232,\n            0.00825103, -0.03007818]]],\n \n \n        [[[ 0.00119611,  0.04600699,  0.0283214 , ...,  0.01313282,\n            0.03363832,  0.03934461],\n          [ 0.04437168, -0.03809474,  0.01132123, ..., -0.04519213,\n            0.03424553, -0.0367903 ],\n          [ 0.0263879 ,  0.00622746, -0.02252542, ...,  0.04356598,\n           -0.04714796, -0.01950751],\n          ...,\n          [ 0.01110538, -0.02833709,  0.0053044 , ..., -0.01279094,\n           -0.02621273,  0.03007467],\n          [ 0.02651199, -0.02570812,  0.00228071, ..., -0.0037411 ,\n            0.0207494 , -0.01341013],\n          [ 0.03971412,  0.02063541,  0.02861978, ...,  0.0455024 ,\n            0.02841345, -0.00379508]]],\n \n \n        [[[ 0.04477848,  0.01995153, -0.00382137, ..., -0.02752056,\n           -0.01174869, -0.04318096],\n          [ 0.04668942,  0.0209977 , -0.04556807, ...,  0.02870615,\n            0.01697376,  0.01220606],\n          [ 0.01334322, -0.04327775, -0.01712403, ...,  0.03833289,\n           -0.0242481 , -0.00211006],\n          ...,\n          [-0.0028236 , -0.03637492, -0.04483989, ...,  0.02685665,\n            0.04412199,  0.03634683],\n          [ 0.01942441,  0.01646447,  0.01150237, ...,  0.0340981 ,\n           -0.00908308, -0.00570874],\n          [ 0.02240934,  0.01601132, -0.01426039, ...,  0.02869389,\n           -0.01355056,  0.04679988]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_164/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_164/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_164/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_168/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_168/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_168/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_165/kernel:0' shape=(3, 3, 192, 320) dtype=float32, numpy=\n array([[[[ 0.00018833,  0.02587847, -0.02533725, ...,  0.01589082,\n           -0.00766462, -0.02090069],\n          [ 0.00633441,  0.00626905, -0.01861903, ..., -0.01839988,\n           -0.02552066, -0.00144795],\n          [-0.03274225,  0.0338039 ,  0.03428638, ..., -0.00898503,\n            0.0211492 ,  0.01263833],\n          ...,\n          [ 0.03033144, -0.03458109, -0.00511429, ...,  0.01451748,\n            0.0030017 , -0.00288887],\n          [-0.02928242, -0.01093114, -0.00119496, ..., -0.02409094,\n            0.00709483, -0.01476938],\n          [ 0.01997953,  0.00967605, -0.00396307, ..., -0.03060019,\n            0.00665888,  0.03089571]],\n \n         [[-0.0103608 ,  0.02829762,  0.03366727, ..., -0.01488458,\n            0.01866343,  0.02434739],\n          [ 0.02194729, -0.01154428,  0.03341496, ...,  0.00477333,\n            0.01282402, -0.02011478],\n          [-0.01314135,  0.01228262, -0.01306944, ..., -0.00823959,\n           -0.02807399,  0.00548686],\n          ...,\n          [ 0.00144594, -0.00265986,  0.02421266, ..., -0.00502469,\n            0.01481393,  0.00148703],\n          [ 0.02417111, -0.00579724, -0.03142603, ..., -0.02488772,\n            0.02161925,  0.03068028],\n          [ 0.0026326 , -0.01778472, -0.00165365, ..., -0.0329847 ,\n            0.01186624, -0.02646458]],\n \n         [[ 0.0310235 ,  0.03215861, -0.01628976, ...,  0.00011964,\n           -0.00203869,  0.0262656 ],\n          [-0.03289778,  0.02921388,  0.02122212, ...,  0.02193956,\n           -0.03090027, -0.01454374],\n          [-0.02279879,  0.03271159,  0.01855921, ..., -0.02350919,\n            0.00119324, -0.03422881],\n          ...,\n          [ 0.03410283,  0.01309744,  0.00948742, ..., -0.03489674,\n            0.02237919, -0.00729273],\n          [-0.01486269,  0.01996452, -0.03146022, ..., -0.02536856,\n           -0.00082233,  0.00769215],\n          [ 0.02181001, -0.02881031,  0.02083607, ...,  0.01674104,\n           -0.0125313 ,  0.03156709]]],\n \n \n        [[[ 0.01963499, -0.01660035, -0.02060836, ...,  0.02786164,\n           -0.01222244, -0.025549  ],\n          [-0.02196695, -0.02837587, -0.0314278 , ...,  0.02295934,\n           -0.01848009,  0.01121987],\n          [ 0.02176861,  0.01484315,  0.02294704, ..., -0.0335919 ,\n            0.02965304,  0.01904448],\n          ...,\n          [-0.03598658,  0.02072438, -0.01251456, ...,  0.0282589 ,\n           -0.01209236,  0.00481132],\n          [ 0.00717571,  0.02357429,  0.01135636, ...,  0.01136365,\n           -0.02114039, -0.02176411],\n          [-0.01078986, -0.03207051,  0.03422045, ...,  0.03399248,\n           -0.01802141, -0.01884009]],\n \n         [[-0.02034242, -0.03226312, -0.00540599, ...,  0.03517869,\n           -0.02333438,  0.02583598],\n          [-0.00523828, -0.0323865 , -0.00158286, ..., -0.03285858,\n            0.01206853, -0.02030912],\n          [ 0.00656634, -0.00444245, -0.02972914, ..., -0.01542119,\n           -0.03269287, -0.00503403],\n          ...,\n          [-0.03435724, -0.00063903, -0.00351857, ...,  0.03604424,\n           -0.02530822, -0.01919271],\n          [-0.0032928 ,  0.01543089,  0.02691749, ..., -0.01491079,\n           -0.01990682, -0.03299339],\n          [ 0.01993584,  0.03081955, -0.00099747, ..., -0.01080144,\n            0.03464123,  0.02796717]],\n \n         [[ 0.01736785,  0.00964813, -0.01076021, ..., -0.01989303,\n           -0.03094282, -0.02909165],\n          [-0.00535116,  0.03198177, -0.01769445, ..., -0.01765374,\n            0.01017109,  0.00493538],\n          [ 0.02564527,  0.03482766, -0.00921773, ...,  0.02946325,\n           -0.00666152,  0.02469869],\n          ...,\n          [ 0.02854012,  0.01415341,  0.0128619 , ...,  0.01404618,\n           -0.01829869, -0.01440454],\n          [-0.01468859, -0.01867608, -0.02239033, ..., -0.0098914 ,\n           -0.02963899, -0.0226806 ],\n          [-0.00376851,  0.02126876,  0.00330755, ...,  0.00717022,\n           -0.01518782, -0.02742714]]],\n \n \n        [[[-0.03199189,  0.02841635,  0.02102753, ..., -0.00429878,\n           -0.00654719, -0.02481575],\n          [-0.01375398,  0.02476154, -0.01051986, ..., -0.02020149,\n           -0.0132707 , -0.00204852],\n          [-0.01816202,  0.03333632, -0.0277852 , ..., -0.02060662,\n           -0.02688763,  0.02410514],\n          ...,\n          [ 0.00798339, -0.02078286,  0.01199866, ..., -0.01042161,\n           -0.00374608, -0.03088405],\n          [ 0.00796722,  0.02753277,  0.00127906, ...,  0.02189269,\n           -0.01477414, -0.01414797],\n          [-0.02850457,  0.00163995,  0.00983602, ...,  0.02594798,\n            0.01801294,  0.00868027]],\n \n         [[-0.02002209, -0.02805722,  0.02578059, ..., -0.02716966,\n            0.02861275,  0.02842212],\n          [ 0.01743774, -0.0040827 ,  0.0277728 , ...,  0.01677585,\n            0.02674221, -0.00093315],\n          [-0.02825204, -0.00854842,  0.00817039, ...,  0.01720051,\n           -0.00433977,  0.01614011],\n          ...,\n          [ 0.02167869,  0.01840492,  0.01607243, ...,  0.02436916,\n           -0.00689278, -0.0285472 ],\n          [-0.00680186, -0.01156362,  0.0336514 , ...,  0.00827911,\n           -0.01163507, -0.00342439],\n          [-0.01230972, -0.02297127,  0.01402628, ..., -0.02571066,\n           -0.01887797, -0.01556371]],\n \n         [[ 0.01207886,  0.02447201,  0.01313305, ...,  0.00598604,\n            0.03267108, -0.02606386],\n          [ 0.02013164, -0.01181553, -0.01262983, ..., -0.01634087,\n            0.01388853, -0.02873509],\n          [-0.01552389,  0.03587311,  0.02096942, ...,  0.02810755,\n           -0.02442632, -0.02366363],\n          ...,\n          [-0.03532629, -0.00511716, -0.02296518, ...,  0.01615098,\n            0.03553224,  0.00424312],\n          [ 0.00594603,  0.00560539,  0.01176156, ...,  0.03006277,\n            0.01947385, -0.02132127],\n          [-0.01643889, -0.00981076,  0.03454461, ..., -0.00766411,\n            0.02463187,  0.01931143]]]], dtype=float32)>,\n <tf.Variable 'conv2d_169/kernel:0' shape=(3, 3, 192, 192) dtype=float32, numpy=\n array([[[[-0.01211589, -0.04052984,  0.01268759, ..., -0.01638575,\n           -0.01812321, -0.03120415],\n          [-0.03393799,  0.00885675, -0.0388086 , ..., -0.00239386,\n            0.03273723,  0.03661795],\n          [ 0.01748539,  0.00353831, -0.03762145, ...,  0.00819116,\n            0.03247077,  0.02138864],\n          ...,\n          [-0.01942835, -0.02615567,  0.00528306, ...,  0.02745811,\n           -0.03456638, -0.02433835],\n          [ 0.01323301, -0.00111262, -0.00930106, ...,  0.03022401,\n           -0.00948842,  0.00468911],\n          [-0.03225614, -0.02701399,  0.01607902, ...,  0.02963683,\n           -0.01450796, -0.00554616]],\n \n         [[ 0.03765718, -0.02790962,  0.01666299, ...,  0.01274144,\n           -0.01900859,  0.04060023],\n          [ 0.00435392, -0.03841251, -0.03624007, ..., -0.03436225,\n           -0.00864564, -0.00724893],\n          [-0.01524078,  0.02796041, -0.02915546, ..., -0.00836508,\n           -0.03919184,  0.03501423],\n          ...,\n          [ 0.03015268, -0.03470656, -0.01725107, ..., -0.00757961,\n           -0.01952457,  0.03427668],\n          [-0.02094889,  0.00240059, -0.0288799 , ...,  0.0255302 ,\n           -0.02713988, -0.0352326 ],\n          [-0.00221022,  0.00759869,  0.02031869, ..., -0.01295992,\n            0.02905528, -0.01048256]],\n \n         [[-0.02675954, -0.00374549,  0.03508221, ..., -0.03960944,\n           -0.01066425, -0.02647091],\n          [ 0.01147993, -0.01026423,  0.00852078, ..., -0.04050453,\n           -0.02256018, -0.03021293],\n          [-0.0387098 , -0.0188565 , -0.02729121, ..., -0.0002466 ,\n            0.02130729, -0.00476535],\n          ...,\n          [ 0.02786844,  0.03744239, -0.03295962, ..., -0.04037917,\n            0.02109497,  0.00625178],\n          [-0.01264676, -0.0241765 , -0.04088358, ...,  0.0226892 ,\n            0.03219246,  0.02028347],\n          [-0.03833102,  0.03427296, -0.02217009, ...,  0.03493064,\n           -0.03057419, -0.0006285 ]]],\n \n \n        [[[ 0.01996462,  0.01372542, -0.01761273, ..., -0.01576062,\n            0.00701658, -0.0261276 ],\n          [-0.0026114 , -0.02615754,  0.03163345, ..., -0.02248358,\n           -0.03443827, -0.01598702],\n          [ 0.03627286, -0.01563839, -0.03721491, ...,  0.033568  ,\n            0.00435736,  0.00670077],\n          ...,\n          [ 0.01475545,  0.01914846, -0.04011606, ..., -0.01210367,\n            0.0173692 , -0.02940693],\n          [ 0.03410873, -0.00958869,  0.00894143, ...,  0.00998989,\n           -0.04069182,  0.00543252],\n          [ 0.00883215,  0.01508145,  0.03036676, ..., -0.03499205,\n            0.02018095,  0.03163306]],\n \n         [[ 0.02586417,  0.03626284, -0.00245209, ...,  0.00807147,\n           -0.01128655,  0.03592907],\n          [ 0.03321152,  0.01122769,  0.00400092, ..., -0.03850013,\n           -0.01392829,  0.0085463 ],\n          [-0.01862486,  0.01129071, -0.03854443, ...,  0.03366606,\n           -0.02242318,  0.0274382 ],\n          ...,\n          [-0.02777088, -0.00266337,  0.01877794, ..., -0.00517389,\n            0.03690461, -0.02352218],\n          [ 0.02499424, -0.01851573,  0.04084585, ..., -0.01274645,\n           -0.01783716,  0.03004577],\n          [ 0.00619718, -0.01599001, -0.00467046, ..., -0.03705636,\n            0.00776607, -0.02042185]],\n \n         [[ 0.02049683,  0.0216285 ,  0.03572247, ...,  0.0218636 ,\n            0.01892638, -0.03398221],\n          [-0.00962248, -0.00200397, -0.03872582, ...,  0.01465969,\n           -0.02268399,  0.00641015],\n          [ 0.00472053,  0.00631573, -0.04116286, ...,  0.01547614,\n            0.00581245, -0.00714694],\n          ...,\n          [ 0.00144361,  0.00893415, -0.00482708, ...,  0.01848263,\n            0.03766577, -0.02046463],\n          [ 0.00422003,  0.0259559 , -0.02758202, ...,  0.01697833,\n            0.00838586,  0.01221974],\n          [-0.00858179, -0.02434551,  0.028235  , ...,  0.0131345 ,\n            0.00822942, -0.01338704]]],\n \n \n        [[[-0.00265263, -0.0337528 ,  0.01325385, ..., -0.04072969,\n           -0.00772415, -0.00322768],\n          [ 0.03504397, -0.02564615, -0.02911904, ..., -0.00492202,\n           -0.00737103, -0.00547272],\n          [ 0.0004268 ,  0.0163193 , -0.03703544, ..., -0.02344917,\n           -0.03662144, -0.03337108],\n          ...,\n          [ 0.02763065,  0.00454202,  0.03904462, ...,  0.00294092,\n            0.0052381 ,  0.04053495],\n          [-0.02372188, -0.00131717, -0.02308538, ...,  0.01680009,\n            0.00829566,  0.00444763],\n          [ 0.02159001, -0.01962425,  0.03998009, ...,  0.03853487,\n           -0.0036913 ,  0.02351336]],\n \n         [[ 0.02367977,  0.00987842, -0.00211377, ...,  0.01843435,\n           -0.01736196, -0.01654087],\n          [-0.02792202,  0.02731309, -0.01196896, ...,  0.02128611,\n           -0.02441917, -0.00057378],\n          [ 0.01042793,  0.03398487,  0.01382912, ...,  0.02574501,\n           -0.01618111,  0.02545605],\n          ...,\n          [ 0.00142537,  0.00417512, -0.03565048, ...,  0.00657706,\n            0.0125196 ,  0.02392282],\n          [-0.03969126,  0.0220525 ,  0.02847644, ...,  0.01443623,\n           -0.0390565 ,  0.0124501 ],\n          [ 0.0406611 ,  0.03772982,  0.02922321, ...,  0.00742491,\n           -0.00842272, -0.0210507 ]],\n \n         [[-0.01868803,  0.01427836, -0.00065237, ..., -0.01152895,\n           -0.02369505,  0.01072277],\n          [ 0.00123709,  0.00927842, -0.0314435 , ...,  0.0197726 ,\n            0.03505992, -0.01294323],\n          [-0.00344614,  0.01022514, -0.02732328, ..., -0.00775076,\n           -0.03888723, -0.02506532],\n          ...,\n          [-0.0094978 , -0.04138692, -0.04032265, ..., -0.01536225,\n           -0.02125426,  0.02832035],\n          [-0.00803146, -0.00919783, -0.01757528, ...,  0.03374637,\n           -0.01332958, -0.02186035],\n          [ 0.02025424, -0.00251606,  0.00594098, ..., -0.03416442,\n           -0.03930846, -0.03103182]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_165/beta:0' shape=(320,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_165/moving_mean:0' shape=(320,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_165/moving_variance:0' shape=(320,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_169/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_169/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_169/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_174/kernel:0' shape=(1, 1, 1280, 448) dtype=float32, numpy=\n array([[[[ 0.00523278, -0.0056267 , -0.04055211, ...,  0.02629596,\n           -0.03390893,  0.04896875],\n          [ 0.01338146,  0.04340135, -0.0406909 , ...,  0.05204332,\n            0.01987707,  0.01272978],\n          [-0.05834506,  0.01558996, -0.00549294, ...,  0.01565683,\n            0.05839141, -0.05212865],\n          ...,\n          [ 0.03616097, -0.00805553,  0.04243873, ..., -0.01208118,\n            0.04636954, -0.01945878],\n          [-0.02838939,  0.02852659, -0.00938822, ..., -0.05849092,\n           -0.04172504,  0.0494098 ],\n          [-0.02217738,  0.04944177,  0.05758566, ..., -0.01407019,\n            0.05022853, -0.00180227]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_174/beta:0' shape=(448,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_174/moving_mean:0' shape=(448,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_174/moving_variance:0' shape=(448,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_171/kernel:0' shape=(1, 1, 1280, 384) dtype=float32, numpy=\n array([[[[-0.02244455,  0.05243062, -0.02047986, ...,  0.02882576,\n            0.04573538,  0.02906376],\n          [-0.03027616,  0.0309106 ,  0.04399586, ...,  0.04337797,\n           -0.00048605, -0.00538707],\n          [ 0.00049734,  0.03366972, -0.03694851, ..., -0.01316516,\n            0.04966244, -0.03114446],\n          ...,\n          [ 0.04478172, -0.00550763, -0.02280364, ...,  0.00111837,\n            0.05942566, -0.01439255],\n          [ 0.05452156, -0.02721051, -0.00749762, ..., -0.03352625,\n           -0.00782103, -0.02372684],\n          [ 0.04334892, -0.00026652, -0.02544251, ...,  0.04828741,\n            0.02917378,  0.0051757 ]]]], dtype=float32)>,\n <tf.Variable 'conv2d_175/kernel:0' shape=(3, 3, 448, 384) dtype=float32, numpy=\n array([[[[-0.00872505, -0.02038286,  0.01193669, ...,  0.02633059,\n            0.02521173, -0.01435792],\n          [-0.0040262 ,  0.00788671,  0.00263817, ...,  0.02542014,\n            0.02735456, -0.00926773],\n          [-0.0074693 ,  0.01407698, -0.00630598, ...,  0.01407087,\n            0.01440233, -0.01857409],\n          ...,\n          [-0.01050728,  0.00802848, -0.02623295, ...,  0.01358047,\n           -0.02493279,  0.01214428],\n          [ 0.02494592, -0.00223537, -0.00909676, ...,  0.01219609,\n            0.00150943,  0.02338612],\n          [-0.01713295,  0.01955587, -0.00074359, ..., -0.01895258,\n            0.00862515,  0.01354825]],\n \n         [[ 0.01158831, -0.02552723,  0.00597866, ...,  0.00165715,\n           -0.02059598, -0.00267651],\n          [-0.02240655, -0.02544764, -0.01861167, ...,  0.01899778,\n            0.00024901,  0.00417342],\n          [-0.00072046,  0.01521875,  0.02595246, ...,  0.00484483,\n            0.01721972,  0.0099007 ],\n          ...,\n          [ 0.0052537 ,  0.02503877,  0.01618093, ...,  0.00184408,\n           -0.02708546, -0.0227406 ],\n          [-0.01544418, -0.02066596,  0.00569705, ...,  0.00070117,\n            0.02542561,  0.00105788],\n          [-0.0270212 ,  0.00201262, -0.00802502, ..., -0.01276901,\n            0.01946623,  0.01293139]],\n \n         [[-0.00391599, -0.0067769 , -0.00583646, ...,  0.01735704,\n           -0.00980663, -0.01876623],\n          [ 0.01085296, -0.02701382,  0.0104322 , ...,  0.01776559,\n            0.0009729 ,  0.0190236 ],\n          [-0.00632106, -0.01819789,  0.02815803, ..., -0.01947858,\n            0.00429442,  0.00748934],\n          ...,\n          [ 0.00831519,  0.01298902,  0.01980829, ..., -0.01707995,\n            0.02260249,  0.02568206],\n          [-0.01371141, -0.02529456,  0.02558049, ...,  0.00723285,\n            0.01394255,  0.01252228],\n          [ 0.02127044,  0.01369653,  0.01723442, ..., -0.00022161,\n           -0.01691185,  0.01947383]]],\n \n \n        [[[-0.02676519,  0.00082828, -0.00182745, ...,  0.00356969,\n           -0.01119509,  0.00381256],\n          [-0.00936201, -0.0079087 , -0.00404477, ..., -0.02409458,\n            0.01893332, -0.00486473],\n          [ 0.02402651,  0.00797565,  0.02345723, ...,  0.01427709,\n           -0.02448874,  0.0190226 ],\n          ...,\n          [-0.00348284,  0.00670997, -0.01383869, ...,  0.01216076,\n            0.00921424, -0.02175798],\n          [ 0.00140795,  0.02065017, -0.00546097, ..., -0.00170503,\n            0.003383  ,  0.02613761],\n          [-0.01842854,  0.01594399, -0.01898344, ...,  0.01419961,\n            0.00325853, -0.02768987]],\n \n         [[-0.01324905, -0.00895935,  0.01928367, ...,  0.00039057,\n            0.02404445, -0.01895196],\n          [-0.02739595,  0.00526897,  0.02424656, ..., -0.00113352,\n            0.00120467, -0.01240147],\n          [ 0.00151887,  0.01913083,  0.00271773, ...,  0.02576269,\n           -0.00491048, -0.01725582],\n          ...,\n          [-0.012029  ,  0.01476163, -0.00779201, ...,  0.01864555,\n            0.01511492, -0.02550662],\n          [ 0.01567821, -0.01069373,  0.02698868, ...,  0.01078364,\n           -0.00391328, -0.02762214],\n          [ 0.00375767, -0.00108374, -0.00355258, ...,  0.00721657,\n            0.0097301 , -0.02284037]],\n \n         [[-0.01893859, -0.02142809,  0.01344429, ..., -0.00773866,\n           -0.00817036,  0.00652981],\n          [-0.00874349,  0.00309542, -0.02298521, ...,  0.01503165,\n           -0.00245811,  0.0019752 ],\n          [ 0.00586899, -0.00820894, -0.00952925, ...,  0.00450236,\n           -0.02479599, -0.02713758],\n          ...,\n          [-0.00388475, -0.00211557, -0.0238518 , ...,  0.00231545,\n            0.0211342 , -0.01610211],\n          [ 0.00137046, -0.00956015,  0.00460542, ..., -0.01281095,\n            0.00780519,  0.01679709],\n          [-0.00662963,  0.02419452, -0.01005135, ..., -0.02642903,\n           -0.00979442,  0.01116367]]],\n \n \n        [[[-0.02814335,  0.02525794, -0.00340739, ..., -0.00538445,\n           -0.01738044, -0.02214287],\n          [ 0.01731793,  0.021968  , -0.02299019, ...,  0.02430821,\n            0.00755407, -0.00831678],\n          [ 0.00697867, -0.02211607, -0.008682  , ...,  0.01253056,\n            0.01189513,  0.00185991],\n          ...,\n          [ 0.00950663, -0.00196614, -0.02549966, ...,  0.00021755,\n           -0.02525274,  0.02347187],\n          [ 0.00393342, -0.01643478,  0.01419972, ...,  0.01643787,\n           -0.00435195,  0.00980812],\n          [-0.01022219, -0.02045122, -0.01124914, ...,  0.02772626,\n            0.00810607,  0.00251501]],\n \n         [[ 0.0197305 ,  0.02494079,  0.01547973, ...,  0.00180509,\n            0.00445065,  0.02550284],\n          [-0.00611104, -0.00886904,  0.02297507, ..., -0.02729288,\n            0.0129461 , -0.00126602],\n          [-0.01843428, -0.01381102,  0.02142909, ..., -0.02211925,\n            0.0148226 , -0.00772702],\n          ...,\n          [-0.00958013, -0.02716532,  0.00517719, ..., -0.01970876,\n            0.0130194 , -0.01637588],\n          [ 0.02033796, -0.02665068,  0.01430483, ..., -0.00473457,\n           -0.02277065,  0.0182863 ],\n          [-0.02635583,  0.01608985, -0.02215185, ...,  0.00043089,\n           -0.00099612,  0.01403063]],\n \n         [[-0.00998394, -0.0066916 ,  0.02226923, ..., -0.02827859,\n           -0.01331427, -0.00919514],\n          [-0.02554512,  0.00692877, -0.00591292, ...,  0.00095012,\n           -0.01529872, -0.01125836],\n          [ 0.01474621, -0.01310262,  0.0173615 , ...,  0.01295149,\n            0.00619858,  0.01155211],\n          ...,\n          [ 0.00896492, -0.0223145 ,  0.01357718, ..., -0.00566926,\n            0.00374328,  0.01028841],\n          [ 0.02742677, -0.01082211,  0.02135674, ..., -0.02592906,\n            0.02107867,  0.02217747],\n          [-0.02199895, -0.02713626,  0.02360624, ...,  0.02461696,\n            0.00511902, -0.00651119]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_171/beta:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_171/moving_mean:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_171/moving_variance:0' shape=(384,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_175/beta:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_175/moving_mean:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_175/moving_variance:0' shape=(384,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_172/kernel:0' shape=(1, 3, 384, 384) dtype=float32, numpy=\n array([[[[ 0.01562152,  0.01787099, -0.02284261, ...,  0.00302495,\n            0.00457537,  0.03198609],\n          [ 0.03063609,  0.01551077, -0.00838402, ...,  0.00033438,\n            0.00871382,  0.0083196 ],\n          [ 0.04529764, -0.00767834,  0.01904772, ..., -0.00603127,\n            0.03237956, -0.04923394],\n          ...,\n          [ 0.00463525, -0.0472308 , -0.00081088, ..., -0.01366789,\n            0.03573241, -0.02667468],\n          [ 0.02014814, -0.05043121,  0.00103427, ..., -0.02064797,\n            0.04483201, -0.02518778],\n          [ 0.00995548,  0.02410733,  0.00915372, ..., -0.02707387,\n            0.03545021,  0.04252993]],\n \n         [[-0.04876488,  0.05051018, -0.0071886 , ..., -0.01525878,\n            0.05018996, -0.02547202],\n          [ 0.0227288 ,  0.04185683, -0.01738364, ...,  0.03397714,\n            0.02740277,  0.01377241],\n          [-0.02667075,  0.03865334,  0.03759485, ..., -0.04792375,\n           -0.02296694, -0.0484045 ],\n          ...,\n          [-0.02190383, -0.00409631,  0.04215324, ...,  0.03938662,\n           -0.0080435 , -0.02137424],\n          [ 0.00535434, -0.02511349, -0.03342124, ...,  0.01526678,\n           -0.01737134,  0.00682635],\n          [ 0.02296324, -0.02569579,  0.0229664 , ..., -0.05000019,\n           -0.01896946,  0.00246256]],\n \n         [[-0.02897496,  0.03392958, -0.02044713, ..., -0.04783347,\n            0.04570407,  0.01616378],\n          [ 0.02871262,  0.03555567,  0.03111107, ..., -0.04895967,\n            0.01440914,  0.04317085],\n          [ 0.00314341, -0.03709793,  0.00799312, ...,  0.05079914,\n            0.04948371, -0.02517759],\n          ...,\n          [-0.00624828, -0.01976188, -0.03776607, ..., -0.0401882 ,\n            0.04843538,  0.03187066],\n          [-0.02680901,  0.00410117, -0.03375062, ...,  0.01750956,\n            0.03712094,  0.03049523],\n          [ 0.01166771,  0.04838777,  0.03864512, ...,  0.02332694,\n           -0.00796165,  0.04258029]]]], dtype=float32)>,\n <tf.Variable 'conv2d_173/kernel:0' shape=(3, 1, 384, 384) dtype=float32, numpy=\n array([[[[ 0.01933759, -0.01091899,  0.00665446, ..., -0.02160807,\n           -0.0342638 ,  0.04920848],\n          [-0.04630516,  0.0077317 , -0.04031762, ...,  0.00291857,\n            0.03129684, -0.01814243],\n          [-0.0104827 , -0.00209692,  0.00101107, ...,  0.00581576,\n           -0.04638188,  0.03008811],\n          ...,\n          [-0.04928288, -0.04398502, -0.02280225, ..., -0.04591071,\n           -0.04719901, -0.00843591],\n          [-0.04313748, -0.02037754,  0.03810886, ..., -0.01200982,\n            0.01388805,  0.03607658],\n          [ 0.02300649,  0.02059995, -0.02231908, ...,  0.00408657,\n            0.03886512, -0.04305168]]],\n \n \n        [[[ 0.02863053,  0.02689099, -0.00736481, ..., -0.03203017,\n            0.00124519, -0.00946118],\n          [ 0.01585989,  0.00252849, -0.02941159, ..., -0.02456331,\n            0.02581623,  0.04209699],\n          [-0.04017756,  0.00371969, -0.03325255, ...,  0.03018778,\n            0.02726184,  0.02708754],\n          ...,\n          [ 0.04837971, -0.04887348,  0.02628143, ..., -0.04077449,\n            0.03185661,  0.01942789],\n          [ 0.02488367,  0.03161126, -0.04103492, ...,  0.03934916,\n           -0.01276439,  0.04104891],\n          [-0.0174177 ,  0.04856626, -0.04667324, ..., -0.01404949,\n           -0.00879645,  0.03566723]]],\n \n \n        [[[-0.03343383,  0.00731125, -0.02202559, ...,  0.03850521,\n            0.01114503,  0.02635963],\n          [-0.04325342, -0.00768393, -0.02854074, ..., -0.03163483,\n           -0.02723463,  0.02003185],\n          [-0.00548369,  0.01418222, -0.00557974, ...,  0.04434033,\n            0.016468  , -0.02290105],\n          ...,\n          [ 0.04726752, -0.03903893,  0.04140113, ...,  0.0072744 ,\n           -0.01019795,  0.03577434],\n          [ 0.0251381 ,  0.02200581, -0.0240557 , ...,  0.02628172,\n            0.03831448, -0.01034531],\n          [-0.02002259,  0.01244837,  0.00942391, ..., -0.0012551 ,\n           -0.04928398, -0.03426852]]]], dtype=float32)>,\n <tf.Variable 'conv2d_176/kernel:0' shape=(1, 3, 384, 384) dtype=float32, numpy=\n array([[[[ 0.0497925 , -0.0384107 , -0.04193171, ..., -0.03182679,\n            0.04705974,  0.01899907],\n          [-0.03644536,  0.01898969,  0.00494182, ..., -0.03060139,\n            0.01943466, -0.04120499],\n          [-0.04400614, -0.04602923, -0.04150034, ..., -0.01648661,\n            0.04512562,  0.00376885],\n          ...,\n          [-0.01631708, -0.03061884,  0.00471813, ..., -0.0135111 ,\n           -0.04759157, -0.00604444],\n          [ 0.00162943,  0.01709356,  0.00843608, ..., -0.01274795,\n            0.00081636,  0.02524252],\n          [-0.01373093,  0.04722164, -0.01647246, ...,  0.04097247,\n           -0.02488499, -0.02012146]],\n \n         [[ 0.05076566,  0.03767869, -0.0262615 , ..., -0.03296808,\n            0.01832499, -0.0046785 ],\n          [-0.00887047,  0.00431417, -0.0430831 , ..., -0.00586674,\n           -0.02422558, -0.01372273],\n          [ 0.01666941, -0.00025582,  0.04778431, ..., -0.04883872,\n            0.03796646,  0.01093085],\n          ...,\n          [ 0.0178773 , -0.02002197,  0.00268401, ..., -0.00231007,\n            0.03510465, -0.03751461],\n          [-0.01461179, -0.01840386,  0.01792235, ...,  0.03747333,\n           -0.00495358, -0.04345324],\n          [-0.02114907,  0.04437948,  0.03684005, ..., -0.00600131,\n           -0.04829676,  0.04004668]],\n \n         [[ 0.03946045,  0.0476371 , -0.00891492, ...,  0.0431879 ,\n            0.03464686, -0.01663275],\n          [-0.04504898,  0.00529836,  0.03628917, ...,  0.04166859,\n           -0.03670889,  0.01597625],\n          [-0.03915869,  0.03481673, -0.00390375, ...,  0.04530909,\n           -0.00067985, -0.02516164],\n          ...,\n          [ 0.00417646,  0.04202189, -0.00563784, ..., -0.02284958,\n           -0.04830784,  0.01666981],\n          [-0.01186332, -0.02605643,  0.0456342 , ...,  0.03848571,\n            0.04434104, -0.04084094],\n          [-0.00355135, -0.02444959,  0.03081573, ...,  0.02686995,\n            0.0163506 ,  0.00085178]]]], dtype=float32)>,\n <tf.Variable 'conv2d_177/kernel:0' shape=(3, 1, 384, 384) dtype=float32, numpy=\n array([[[[-0.02366252, -0.01079296,  0.00557483, ..., -0.02065678,\n            0.01279218, -0.00039268],\n          [-0.03215586, -0.04636463,  0.03174137, ..., -0.03476949,\n           -0.04842706, -0.01251364],\n          [ 0.00487025, -0.0217157 ,  0.00223906, ...,  0.0163209 ,\n           -0.01083722,  0.00257548],\n          ...,\n          [ 0.02704336,  0.01033594, -0.00372576, ..., -0.02615405,\n           -0.03428742,  0.01546897],\n          [ 0.00086392, -0.03506391, -0.04637152, ..., -0.00152084,\n           -0.02020702, -0.0442239 ],\n          [-0.02105913,  0.01126906, -0.02519709, ..., -0.0028193 ,\n           -0.00978675,  0.04866438]]],\n \n \n        [[[-0.04897651, -0.02190361, -0.02604795, ...,  0.02091745,\n           -0.01429754, -0.01203627],\n          [-0.03977036, -0.02380829,  0.03616799, ..., -0.00739997,\n            0.01598009, -0.04396734],\n          [-0.03676848, -0.04408173, -0.03868427, ...,  0.0177407 ,\n           -0.011295  , -0.04221603],\n          ...,\n          [ 0.03748065,  0.01849612, -0.03506709, ...,  0.04752941,\n            0.00902107, -0.02091577],\n          [ 0.01946508, -0.02447872, -0.02369648, ...,  0.03331898,\n            0.03420518, -0.01236284],\n          [-0.01634487,  0.03656531,  0.03100219, ..., -0.01092107,\n           -0.02878283,  0.04124012]]],\n \n \n        [[[ 0.02823261, -0.02193801, -0.03020017, ..., -0.00258423,\n            0.02793603, -0.0402774 ],\n          [-0.01014056, -0.0225159 ,  0.03638215, ..., -0.04272504,\n           -0.04129518,  0.04239126],\n          [-0.01317875, -0.02858616, -0.01963779, ...,  0.04225484,\n           -0.02237617,  0.00688294],\n          ...,\n          [-0.03609331, -0.01668261,  0.00897042, ..., -0.00641144,\n            0.02038356, -0.03876945],\n          [-0.00939054,  0.04463921, -0.00653717, ..., -0.03785006,\n            0.02947748, -0.03583582],\n          [ 0.01636378, -0.03378275,  0.02136123, ...,  0.00508972,\n            0.01890335,  0.04813436]]]], dtype=float32)>,\n <tf.Variable 'conv2d_170/kernel:0' shape=(1, 1, 1280, 320) dtype=float32, numpy=\n array([[[[-0.01949522, -0.05420911,  0.06068806, ..., -0.03040314,\n           -0.01083013,  0.02348671],\n          [-0.02743652,  0.05446605, -0.04780375, ...,  0.0143745 ,\n           -0.05649552,  0.03463337],\n          [-0.04403907, -0.0065144 ,  0.0329085 , ..., -0.00386847,\n            0.03151691, -0.03553928],\n          ...,\n          [-0.050016  ,  0.060223  ,  0.05836548, ...,  0.02838571,\n           -0.02456779,  0.02912449],\n          [ 0.04972279, -0.05217474,  0.00871344, ...,  0.03397314,\n            0.04900331,  0.01263739],\n          [ 0.00363415, -0.005399  ,  0.02511069, ...,  0.00948615,\n            0.05144231, -0.04524034]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_172/beta:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_172/moving_mean:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_172/moving_variance:0' shape=(384,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_173/beta:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_173/moving_mean:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_173/moving_variance:0' shape=(384,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_176/beta:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_176/moving_mean:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_176/moving_variance:0' shape=(384,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_177/beta:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_177/moving_mean:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_177/moving_variance:0' shape=(384,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_178/kernel:0' shape=(1, 1, 1280, 192) dtype=float32, numpy=\n array([[[[-0.05730791,  0.01812831, -0.04524868, ..., -0.02357076,\n           -0.05613253, -0.0368359 ],\n          [-0.00523238, -0.03482477, -0.01656783, ..., -0.05941687,\n           -0.03838941,  0.02094001],\n          [-0.05803656,  0.04080452,  0.01532393, ...,  0.00220452,\n           -0.02554461, -0.01769532],\n          ...,\n          [-0.02559559,  0.02559952, -0.02929966, ..., -0.00778353,\n            0.04653274,  0.0606235 ],\n          [-0.00489644,  0.04076739, -0.021255  , ...,  0.00501336,\n           -0.04401001,  0.06150926],\n          [-0.02186615, -0.03763732,  0.02743662, ...,  0.04003295,\n            0.06138279,  0.01390468]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_170/beta:0' shape=(320,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_170/moving_mean:0' shape=(320,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_170/moving_variance:0' shape=(320,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_178/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_178/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_178/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_183/kernel:0' shape=(1, 1, 2048, 448) dtype=float32, numpy=\n array([[[[-0.01893143,  0.04501219, -0.02044309, ...,  0.04628957,\n            0.0377841 ,  0.02545689],\n          [ 0.04348548, -0.01907295, -0.03914293, ..., -0.03393188,\n           -0.02974391,  0.03518365],\n          [-0.02165986,  0.00844681,  0.02506222, ..., -0.03351722,\n           -0.02040455, -0.03045524],\n          ...,\n          [ 0.01160742, -0.02795437,  0.02956833, ..., -0.00622054,\n            0.01185131, -0.04811421],\n          [-0.0020884 ,  0.01534474,  0.03201928, ...,  0.00842414,\n            0.01482879, -0.0341228 ],\n          [-0.03294925,  0.04454177, -0.00462328, ...,  0.04709766,\n            0.02172961, -0.0178161 ]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_183/beta:0' shape=(448,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_183/moving_mean:0' shape=(448,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_183/moving_variance:0' shape=(448,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_180/kernel:0' shape=(1, 1, 2048, 384) dtype=float32, numpy=\n array([[[[-0.01523723, -0.00866845, -0.02718446, ...,  0.02025605,\n           -0.04649432,  0.03083838],\n          [ 0.0414583 ,  0.00925878, -0.00390586, ...,  0.02943499,\n            0.00714422,  0.02846843],\n          [ 0.00909411,  0.01999488, -0.01448179, ...,  0.03097526,\n            0.01910095, -0.04504722],\n          ...,\n          [ 0.00191669, -0.04329957,  0.00351914, ..., -0.03065175,\n           -0.02997511,  0.00571579],\n          [ 0.01078651,  0.00924371,  0.02355998, ..., -0.00455115,\n           -0.0129936 ,  0.00089663],\n          [-0.02662213, -0.036293  , -0.04563263, ...,  0.04355674,\n           -0.04493401, -0.02825436]]]], dtype=float32)>,\n <tf.Variable 'conv2d_184/kernel:0' shape=(3, 3, 448, 384) dtype=float32, numpy=\n array([[[[ 0.01390706, -0.01184943, -0.00255408, ...,  0.01035623,\n            0.02384366, -0.01072499],\n          [-0.00431984,  0.01892812, -0.0007453 , ...,  0.01715739,\n            0.01699853, -0.02071596],\n          [-0.02323532, -0.0080715 , -0.00145046, ..., -0.02435914,\n            0.01353783, -0.00768059],\n          ...,\n          [-0.01232379,  0.0208321 , -0.00491728, ...,  0.00221234,\n           -0.02151544,  0.02424779],\n          [-0.02243872, -0.02115864,  0.01266678, ...,  0.02192078,\n           -0.00243347,  0.02192921],\n          [-0.00650443, -0.00620552, -0.00558797, ..., -0.00602157,\n            0.01035838,  0.0251124 ]],\n \n         [[ 0.0104402 , -0.01815156, -0.02811626, ...,  0.0222521 ,\n            0.00796875, -0.02498897],\n          [ 0.01190457,  0.00102213,  0.00994962, ..., -0.01188018,\n           -0.02611802,  0.02702959],\n          [ 0.00345465, -0.02818937,  0.0044902 , ..., -0.01177185,\n           -0.00317889,  0.00325408],\n          ...,\n          [ 0.00337259,  0.0200248 ,  0.01518067, ..., -0.00710778,\n            0.02609843, -0.00128993],\n          [ 0.01889747, -0.01682584,  0.0010489 , ..., -0.01497595,\n            0.00865956, -0.02481449],\n          [ 0.00998085,  0.00743498,  0.01069179, ..., -0.01925407,\n           -0.01353167,  0.02285654]],\n \n         [[ 0.02521399,  0.00616448, -0.00139476, ..., -0.01783521,\n            0.01298142,  0.00525111],\n          [-0.02571716,  0.0086653 , -0.01437636, ...,  0.02100128,\n           -0.01465676, -0.02231747],\n          [ 0.02177999, -0.01445584,  0.00599267, ..., -0.02076842,\n           -0.02590478,  0.01954889],\n          ...,\n          [-0.02765732, -0.00252068,  0.02618164, ...,  0.00743158,\n           -0.00495844,  0.00454384],\n          [-0.00712449, -0.0200015 ,  0.02513742, ...,  0.02326387,\n            0.01762272,  0.00446036],\n          [-0.01914468,  0.02807677,  0.02348369, ..., -0.00247798,\n            0.01796556, -0.00860178]]],\n \n \n        [[[-0.00590681, -0.02416023,  0.02019013, ...,  0.01354496,\n           -0.01551895,  0.0177543 ],\n          [-0.00592135,  0.019502  , -0.00175336, ...,  0.00662263,\n           -0.01523808,  0.01017508],\n          [-0.00958138,  0.01966204,  0.01012508, ..., -0.00915764,\n            0.01218767,  0.02795142],\n          ...,\n          [ 0.00329879,  0.02491619,  0.01923181, ...,  0.0120366 ,\n           -0.01744053, -0.00257394],\n          [ 0.01272397,  0.00923178, -0.00240756, ...,  0.02124223,\n           -0.01806152, -0.0070004 ],\n          [ 0.00608615,  0.02121371, -0.00583475, ...,  0.02313289,\n            0.00423778, -0.02516179]],\n \n         [[ 0.01407155, -0.01273716, -0.00379892, ...,  0.01406848,\n           -0.00702961, -0.00194708],\n          [ 0.02184569, -0.0206252 , -0.00710496, ...,  0.00548817,\n           -0.02698336, -0.02446311],\n          [-0.02307675,  0.01034094,  0.01273231, ...,  0.0195276 ,\n           -0.02538058, -0.01093454],\n          ...,\n          [-0.00974577,  0.02075547,  0.0158363 , ...,  0.0251295 ,\n           -0.0100137 ,  0.02381293],\n          [ 0.00577092,  0.02366073, -0.02514997, ...,  0.02222105,\n            0.00824582, -0.00636334],\n          [-0.02110378, -0.02515928, -0.01019759, ...,  0.01026361,\n            0.01922486, -0.01492959]],\n \n         [[-0.00873736,  0.00268832, -0.00974242, ..., -0.0264648 ,\n            0.00378491, -0.02619771],\n          [-0.00064425,  0.00102931,  0.01658105, ..., -0.01281832,\n           -0.00103272,  0.02384152],\n          [-0.01518314, -0.01354281,  0.02051711, ..., -0.00571798,\n           -0.00071195, -0.00857703],\n          ...,\n          [-0.01302976, -0.00559596,  0.02237975, ..., -0.0268613 ,\n           -0.02630272,  0.02075394],\n          [ 0.00441142, -0.01012603,  0.02264694, ...,  0.02330544,\n           -0.00565263,  0.01340542],\n          [ 0.01867755,  0.01308808,  0.005902  , ...,  0.00289656,\n            0.0218956 , -0.00340642]]],\n \n \n        [[[-0.02412714,  0.01847488,  0.00145001, ..., -0.02775233,\n           -0.02074252, -0.01859346],\n          [-0.00441173,  0.01515985,  0.00546537, ...,  0.0003967 ,\n           -0.00675128,  0.01618144],\n          [-0.01470874,  0.01786423,  0.00633146, ..., -0.0022655 ,\n           -0.02387914,  0.01883162],\n          ...,\n          [-0.00865045,  0.01650019, -0.02125722, ..., -0.02215222,\n            0.0056129 ,  0.02766251],\n          [-0.00783394,  0.00037656, -0.00083702, ..., -0.01983518,\n            0.00388104,  0.02165409],\n          [-0.02063562,  0.02214968, -0.01164105, ...,  0.02225316,\n            0.02707388,  0.01720514]],\n \n         [[ 0.02261604,  0.02664079,  0.01576585, ...,  0.01022645,\n           -0.01589325,  0.006966  ],\n          [-0.00482315, -0.00424425, -0.003439  , ..., -0.02049879,\n            0.0259997 ,  0.01150396],\n          [ 0.00736613,  0.02000513,  0.00840331, ..., -0.01771385,\n           -0.02033116, -0.022498  ],\n          ...,\n          [ 0.02038866,  0.0226343 , -0.02809437, ...,  0.02017115,\n            0.01020609,  0.01423181],\n          [-0.00158396, -0.02782413,  0.01076103, ...,  0.02190269,\n           -0.00675573, -0.02491619],\n          [-0.02474442,  0.02481679, -0.00259309, ..., -0.01487163,\n            0.02459137, -0.00908269]],\n \n         [[-0.0148709 ,  0.02514567, -0.00802065, ..., -0.0185856 ,\n            0.01732707,  0.01826523],\n          [ 0.01048276, -0.00242028,  0.02817621, ...,  0.01081   ,\n            0.0013446 ,  0.01021273],\n          [-0.02248356, -0.01302032, -0.00841267, ..., -0.00198126,\n            0.02446446, -0.00777273],\n          ...,\n          [-0.01200237, -0.02623972, -0.00324093, ...,  0.0149764 ,\n            0.00028805, -0.02058071],\n          [-0.00197198, -0.01708637, -0.0200716 , ...,  0.00042555,\n           -0.0218488 ,  0.02719499],\n          [ 0.02693852,  0.01365642,  0.0043972 , ...,  0.00135105,\n           -0.00174531,  0.0129139 ]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_180/beta:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_180/moving_mean:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_180/moving_variance:0' shape=(384,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_184/beta:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_184/moving_mean:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_184/moving_variance:0' shape=(384,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_181/kernel:0' shape=(1, 3, 384, 384) dtype=float32, numpy=\n array([[[[ 3.3158563e-02, -2.9276760e-02,  1.8945388e-02, ...,\n            5.0783031e-02,  3.0870602e-02, -4.0969368e-02],\n          [-6.0960390e-03,  3.9407149e-02,  4.1106828e-02, ...,\n            2.3934707e-02, -1.1456978e-02, -1.5548568e-02],\n          [-3.9939564e-02,  9.1554411e-03, -3.7116483e-03, ...,\n            8.6435750e-03,  2.4724938e-02, -2.3829676e-03],\n          ...,\n          [ 2.2390127e-02,  1.2529902e-02,  2.5399677e-02, ...,\n            3.0968659e-02,  4.0165000e-02,  3.5316832e-02],\n          [-1.4521975e-02,  1.1523336e-02, -6.2520057e-04, ...,\n           -3.1504720e-02,  9.4260797e-03,  3.7441850e-02],\n          [ 4.5437083e-02,  9.9462420e-03, -5.0308034e-03, ...,\n            1.7238908e-02, -5.1474944e-03,  4.2959906e-02]],\n \n         [[ 1.1694737e-02, -4.4702481e-02,  4.4279195e-02, ...,\n           -2.0148233e-04, -1.1825763e-02, -3.7085973e-02],\n          [ 1.3024129e-02,  1.2319103e-02,  4.2212680e-02, ...,\n            3.9645359e-02,  2.8788485e-02,  5.3051859e-04],\n          [ 1.5097968e-03, -3.3860680e-02, -2.2111822e-02, ...,\n           -8.2208291e-03, -4.0879615e-02, -4.9381919e-02],\n          ...,\n          [ 1.9929864e-02,  1.0258272e-02,  1.9591749e-03, ...,\n           -1.1306886e-02, -9.6159875e-03, -3.2512605e-02],\n          [ 1.4585257e-02,  1.6190842e-02, -9.7668432e-03, ...,\n            2.2376373e-02, -4.8092600e-02,  2.4293639e-02],\n          [ 1.5694410e-02, -3.8621917e-02,  3.3014506e-02, ...,\n           -4.6435352e-02, -2.4613105e-03,  1.0935351e-02]],\n \n         [[-2.6455535e-02,  3.6348000e-02, -5.0726894e-02, ...,\n           -5.0017983e-03, -5.1694810e-03, -3.4171380e-02],\n          [-4.0818695e-02, -1.9991536e-02,  1.9130997e-02, ...,\n            1.9906610e-03, -4.1140959e-02, -1.1917148e-02],\n          [ 3.8560830e-02, -9.8823681e-03, -4.7063001e-02, ...,\n            3.5275705e-02, -2.7499113e-02,  3.8548112e-02],\n          ...,\n          [-6.3751079e-03,  6.5674260e-03,  2.0700112e-02, ...,\n            3.6273055e-02,  2.0727783e-02,  4.1489474e-02],\n          [-3.2018825e-02,  3.4657404e-02,  4.4218145e-02, ...,\n            2.4210103e-02,  3.2327473e-02, -5.0976500e-03],\n          [-4.8119001e-02, -6.2705949e-03, -1.6892776e-02, ...,\n           -4.1163050e-02, -3.4298748e-05, -1.4302108e-02]]]],\n       dtype=float32)>,\n <tf.Variable 'conv2d_182/kernel:0' shape=(3, 1, 384, 384) dtype=float32, numpy=\n array([[[[ 0.04878211, -0.04665725,  0.04597898, ..., -0.04441171,\n           -0.01396849, -0.01119182],\n          [ 0.04632992, -0.04770464, -0.03703929, ..., -0.01796055,\n           -0.01522635,  0.01565772],\n          [ 0.04377672, -0.04525609,  0.00542389, ..., -0.04018866,\n            0.04690259,  0.00488905],\n          ...,\n          [ 0.00403944,  0.04314695,  0.00747104, ..., -0.03518663,\n            0.00898898, -0.01187651],\n          [-0.03852801,  0.04623465, -0.00209182, ..., -0.02752811,\n            0.02766757,  0.0032283 ],\n          [-0.0068295 , -0.04435238,  0.02768473, ...,  0.00709068,\n            0.0080853 ,  0.00166086]]],\n \n \n        [[[-0.02831432,  0.02635399, -0.04438514, ...,  0.00743946,\n            0.0477135 , -0.00246898],\n          [ 0.04788451,  0.00641013, -0.02235814, ..., -0.01597072,\n            0.00996396,  0.00425128],\n          [-0.02350097,  0.03973313,  0.01437829, ..., -0.02357643,\n           -0.0225671 , -0.05013508],\n          ...,\n          [ 0.01729383,  0.0180503 ,  0.01984701, ..., -0.05035666,\n            0.02336491,  0.04936129],\n          [ 0.01174095, -0.01344467, -0.01789184, ..., -0.01728113,\n            0.04840819, -0.0120259 ],\n          [-0.02417146, -0.00131669, -0.05011206, ...,  0.00367906,\n           -0.02319295, -0.01113157]]],\n \n \n        [[[-0.02032239, -0.04496891,  0.04616031, ..., -0.04923547,\n            0.04096263, -0.03776474],\n          [-0.00885399, -0.02523461,  0.01166358, ..., -0.03540393,\n            0.00977146,  0.04257281],\n          [ 0.00480969, -0.02719592, -0.00349784, ...,  0.02586976,\n           -0.01818788, -0.01320255],\n          ...,\n          [-0.0416114 ,  0.03222297, -0.00728769, ..., -0.00946029,\n           -0.02784161,  0.02234617],\n          [ 0.00443111,  0.02008893, -0.02356805, ..., -0.02853566,\n           -0.02457289,  0.00321922],\n          [ 0.0497499 , -0.0173417 ,  0.0247279 , ...,  0.03439865,\n            0.03431194, -0.04493945]]]], dtype=float32)>,\n <tf.Variable 'conv2d_185/kernel:0' shape=(1, 3, 384, 384) dtype=float32, numpy=\n array([[[[ 4.14243713e-03,  2.19894499e-02, -1.09642111e-02, ...,\n           -1.91530287e-02,  2.68053636e-02,  4.31456566e-02],\n          [-2.24821661e-02, -4.24037874e-03,  2.04459876e-02, ...,\n           -8.50450620e-03, -3.56125459e-03,  2.31672153e-02],\n          [-3.16958502e-02, -5.22937626e-04, -3.16745937e-02, ...,\n            3.48856524e-02, -1.53358318e-02, -2.43497491e-02],\n          ...,\n          [-3.15102935e-03,  1.51577145e-02,  4.11203355e-02, ...,\n           -3.15786451e-02,  3.55819613e-02,  6.81285560e-03],\n          [ 3.46348286e-02,  4.76490259e-02, -3.09423506e-02, ...,\n           -1.29693411e-02, -1.06145516e-02,  4.52591330e-02],\n          [ 3.13638151e-03, -2.92028710e-02,  2.25470588e-03, ...,\n            4.15462703e-02, -2.31919624e-02, -4.51122560e-02]],\n \n         [[ 4.40961048e-02,  5.08025214e-02, -1.89649053e-02, ...,\n            2.91183516e-02, -1.75961703e-02,  2.24900991e-03],\n          [-3.67948711e-02, -3.11521292e-02,  4.04175222e-02, ...,\n           -5.60879707e-05, -1.15766972e-02,  1.68635100e-02],\n          [-4.32728603e-03, -2.61167381e-02,  3.04780528e-03, ...,\n           -2.52501015e-02,  2.77776495e-02,  4.36792150e-03],\n          ...,\n          [ 3.13798711e-03,  2.51507685e-02, -1.27786733e-02, ...,\n            2.98893675e-02,  5.05312383e-02,  1.38328150e-02],\n          [ 2.64121741e-02, -3.65694463e-02,  2.48704627e-02, ...,\n           -6.36562705e-04,  2.97531858e-02,  2.60379836e-02],\n          [-2.26461869e-02,  1.35371760e-02, -1.35987364e-02, ...,\n            4.13543954e-02,  2.07825303e-02, -1.53256990e-02]],\n \n         [[-2.58575995e-02, -2.39617042e-02,  4.61393371e-02, ...,\n            4.60276604e-02, -4.71385419e-02, -2.42843535e-02],\n          [-2.68769655e-02,  3.05957347e-02, -3.60648669e-02, ...,\n           -4.64458652e-02,  4.29447368e-03, -4.23940457e-02],\n          [-3.95167805e-02,  1.23092681e-02,  4.53549623e-03, ...,\n            4.09159213e-02, -1.18509606e-02, -2.86713783e-02],\n          ...,\n          [ 3.30190212e-02,  3.26388478e-02,  5.79733402e-03, ...,\n            1.04684271e-02,  3.07681262e-02,  1.75582692e-02],\n          [ 3.77729610e-02,  1.69964582e-02, -3.14914249e-02, ...,\n           -1.86591186e-02, -2.95523182e-03, -4.30969186e-02],\n          [ 1.07316561e-02, -6.33936375e-04,  2.57015228e-02, ...,\n           -4.80203032e-02,  3.21478322e-02,  1.58546120e-03]]]],\n       dtype=float32)>,\n <tf.Variable 'conv2d_186/kernel:0' shape=(3, 1, 384, 384) dtype=float32, numpy=\n array([[[[-0.00995694,  0.02478676, -0.03109187, ..., -0.0199016 ,\n            0.00214709, -0.02684539],\n          [ 0.01795038,  0.00094311,  0.03834449, ...,  0.01955242,\n            0.02498543, -0.03170765],\n          [-0.04594531, -0.00677146,  0.01157031, ..., -0.021905  ,\n            0.00834659,  0.00055   ],\n          ...,\n          [ 0.01444562, -0.0333561 ,  0.04324658, ...,  0.03768574,\n           -0.00328101, -0.04947166],\n          [ 0.04442004, -0.02111041,  0.04878774, ..., -0.03890719,\n           -0.03666535,  0.04702813],\n          [-0.02311183, -0.00721171, -0.04084032, ..., -0.02465803,\n           -0.0066825 ,  0.0052768 ]]],\n \n \n        [[[ 0.02069818, -0.00153102, -0.03051576, ...,  0.007037  ,\n           -0.00022117,  0.04202151],\n          [ 0.04436259,  0.02554337, -0.03271123, ...,  0.04766066,\n           -0.03664274, -0.00713906],\n          [-0.00043921, -0.00439804, -0.00457731, ...,  0.03689011,\n           -0.04167968,  0.03952549],\n          ...,\n          [-0.02549735, -0.04356365, -0.03802296, ...,  0.02322821,\n           -0.04083641, -0.01866727],\n          [-0.01689472, -0.02494667, -0.03448548, ...,  0.01448222,\n           -0.0430576 , -0.01677232],\n          [ 0.02728941,  0.01721917, -0.028463  , ...,  0.02425449,\n           -0.04758807,  0.03922167]]],\n \n \n        [[[ 0.02350464,  0.00154739,  0.02588965, ...,  0.00563961,\n            0.0013364 , -0.0376723 ],\n          [ 0.00842829, -0.04886556, -0.0329762 , ..., -0.009208  ,\n            0.03850091, -0.01327658],\n          [-0.04218388, -0.04913461, -0.04455514, ..., -0.00355611,\n            0.0139242 ,  0.00805063],\n          ...,\n          [-0.02049001,  0.04703663,  0.04765445, ..., -0.03445843,\n           -0.03017869, -0.03275455],\n          [-0.03719599,  0.03786469, -0.04827399, ..., -0.05100743,\n            0.03401248, -0.05032245],\n          [ 0.00913942, -0.05084422,  0.02639863, ..., -0.02957157,\n           -0.02573916,  0.04803389]]]], dtype=float32)>,\n <tf.Variable 'conv2d_179/kernel:0' shape=(1, 1, 2048, 320) dtype=float32, numpy=\n array([[[[ 0.00415121, -0.0217739 ,  0.02602372, ..., -0.02754919,\n           -0.03927035,  0.04895091],\n          [ 0.04815628, -0.04085588,  0.02850584, ..., -0.01142923,\n           -0.02495802,  0.02151293],\n          [-0.0245175 ,  0.03478   ,  0.00853496, ..., -0.0041905 ,\n            0.00303658,  0.02028794],\n          ...,\n          [ 0.04494256, -0.00702661,  0.03291953, ..., -0.02179174,\n            0.0320176 , -0.03037533],\n          [-0.00254289, -0.03653982, -0.01111879, ...,  0.03196657,\n            0.00374068, -0.01234826],\n          [-0.02621338,  0.01160546,  0.04743195, ...,  0.03474066,\n           -0.04033339, -0.03102631]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_181/beta:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_181/moving_mean:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_181/moving_variance:0' shape=(384,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_182/beta:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_182/moving_mean:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_182/moving_variance:0' shape=(384,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_185/beta:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_185/moving_mean:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_185/moving_variance:0' shape=(384,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'batch_normalization_186/beta:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_186/moving_mean:0' shape=(384,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_186/moving_variance:0' shape=(384,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n <tf.Variable 'conv2d_187/kernel:0' shape=(1, 1, 2048, 192) dtype=float32, numpy=\n array([[[[ 0.02050361,  0.02634333,  0.03857175, ...,  0.04596705,\n            0.0176499 , -0.00032773],\n          [ 0.0504543 ,  0.012323  ,  0.03374971, ...,  0.036205  ,\n            0.02825778, -0.01040245],\n          [ 0.00691323,  0.02671588,  0.0365116 , ..., -0.04133673,\n            0.03891738,  0.02714096],\n          ...,\n          [ 0.00100684,  0.03824574,  0.03457806, ...,  0.01227369,\n            0.04154401, -0.03937868],\n          [-0.02668813,  0.0267367 , -0.01513148, ...,  0.01542332,\n           -0.0342895 ,  0.04088879],\n          [-0.0375983 , -0.01982399,  0.00112776, ..., -0.01129659,\n           -0.04232023, -0.04379579]]]], dtype=float32)>,\n <tf.Variable 'batch_normalization_179/beta:0' shape=(320,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_179/moving_mean:0' shape=(320,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_179/moving_variance:0' shape=(320,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n       dtype=float32)>,\n <tf.Variable 'batch_normalization_187/beta:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_187/moving_mean:0' shape=(192,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32)>,\n <tf.Variable 'batch_normalization_187/moving_variance:0' shape=(192,) dtype=float32, numpy=\n array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.], dtype=float32)>]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model.weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "pretrained_model.load_weights(local_weights_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# frezee its layers\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, 74, 74, 32)   864         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, 74, 74, 32)  96          ['conv2d_94[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_94 (Activation)     (None, 74, 74, 32)   0           ['batch_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, 72, 72, 32)   9216        ['activation_94[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_95 (BatchN  (None, 72, 72, 32)  96          ['conv2d_95[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_95 (Activation)     (None, 72, 72, 32)   0           ['batch_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)             (None, 72, 72, 64)   18432       ['activation_95[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_96 (BatchN  (None, 72, 72, 64)  192         ['conv2d_96[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_96 (Activation)     (None, 72, 72, 64)   0           ['batch_normalization_96[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)  0           ['activation_96[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)             (None, 35, 35, 80)   5120        ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_97 (BatchN  (None, 35, 35, 80)  240         ['conv2d_97[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_97 (Activation)     (None, 35, 35, 80)   0           ['batch_normalization_97[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)             (None, 33, 33, 192)  138240      ['activation_97[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_98 (BatchN  (None, 33, 33, 192)  576        ['conv2d_98[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_98 (Activation)     (None, 33, 33, 192)  0           ['batch_normalization_98[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_98[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)            (None, 16, 16, 64)   12288       ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_102 (Batch  (None, 16, 16, 64)  192         ['conv2d_102[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_102 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_102[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)            (None, 16, 16, 48)   9216        ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_102[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_100 (Batch  (None, 16, 16, 48)  144         ['conv2d_100[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_103 (Batch  (None, 16, 16, 96)  288         ['conv2d_103[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_100 (Activation)    (None, 16, 16, 48)   0           ['batch_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " activation_103 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_103[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_9 (AveragePo  (None, 16, 16, 192)  0          ['max_pooling2d_5[0][0]']        \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)             (None, 16, 16, 64)   12288       ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)            (None, 16, 16, 64)   76800       ['activation_100[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)            (None, 16, 16, 96)   82944       ['activation_103[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)            (None, 16, 16, 32)   6144        ['average_pooling2d_9[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_99 (BatchN  (None, 16, 16, 64)  192         ['conv2d_99[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_101 (Batch  (None, 16, 16, 64)  192         ['conv2d_101[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_104 (Batch  (None, 16, 16, 96)  288         ['conv2d_104[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_105 (Batch  (None, 16, 16, 32)  96          ['conv2d_105[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_99 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " activation_101 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_101[0][0]']\n",
      "                                                                                                  \n",
      " activation_104 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_104[0][0]']\n",
      "                                                                                                  \n",
      " activation_105 (Activation)    (None, 16, 16, 32)   0           ['batch_normalization_105[0][0]']\n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_99[0][0]',          \n",
      "                                                                  'activation_101[0][0]',         \n",
      "                                                                  'activation_104[0][0]',         \n",
      "                                                                  'activation_105[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)            (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_109 (Batch  (None, 16, 16, 64)  192         ['conv2d_109[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_109 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_109[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)            (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_109[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_107 (Batch  (None, 16, 16, 48)  144         ['conv2d_107[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_110 (Batch  (None, 16, 16, 96)  288         ['conv2d_110[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_107 (Activation)    (None, 16, 16, 48)   0           ['batch_normalization_107[0][0]']\n",
      "                                                                                                  \n",
      " activation_110 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_110[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_10 (AverageP  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)            (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)            (None, 16, 16, 64)   76800       ['activation_107[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)            (None, 16, 16, 96)   82944       ['activation_110[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)            (None, 16, 16, 64)   16384       ['average_pooling2d_10[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_106 (Batch  (None, 16, 16, 64)  192         ['conv2d_106[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_108 (Batch  (None, 16, 16, 64)  192         ['conv2d_108[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_111 (Batch  (None, 16, 16, 96)  288         ['conv2d_111[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_112 (Batch  (None, 16, 16, 64)  192         ['conv2d_112[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_106 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " activation_108 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_108[0][0]']\n",
      "                                                                                                  \n",
      " activation_111 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_111[0][0]']\n",
      "                                                                                                  \n",
      " activation_112 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_112[0][0]']\n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_106[0][0]',         \n",
      "                                                                  'activation_108[0][0]',         \n",
      "                                                                  'activation_111[0][0]',         \n",
      "                                                                  'activation_112[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)            (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_116 (Batch  (None, 16, 16, 64)  192         ['conv2d_116[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_116 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_116[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)            (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_116[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_114 (Batch  (None, 16, 16, 48)  144         ['conv2d_114[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_117 (Batch  (None, 16, 16, 96)  288         ['conv2d_117[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_114 (Activation)    (None, 16, 16, 48)   0           ['batch_normalization_114[0][0]']\n",
      "                                                                                                  \n",
      " activation_117 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_117[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_11 (AverageP  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)            (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)            (None, 16, 16, 64)   76800       ['activation_114[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)            (None, 16, 16, 96)   82944       ['activation_117[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)            (None, 16, 16, 64)   18432       ['average_pooling2d_11[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_113 (Batch  (None, 16, 16, 64)  192         ['conv2d_113[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_115 (Batch  (None, 16, 16, 64)  192         ['conv2d_115[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_118 (Batch  (None, 16, 16, 96)  288         ['conv2d_118[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_119 (Batch  (None, 16, 16, 64)  192         ['conv2d_119[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_113 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_113[0][0]']\n",
      "                                                                                                  \n",
      " activation_115 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_115[0][0]']\n",
      "                                                                                                  \n",
      " activation_118 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_118[0][0]']\n",
      "                                                                                                  \n",
      " activation_119 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_119[0][0]']\n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_113[0][0]',         \n",
      "                                                                  'activation_115[0][0]',         \n",
      "                                                                  'activation_118[0][0]',         \n",
      "                                                                  'activation_119[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)            (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_121 (Batch  (None, 16, 16, 64)  192         ['conv2d_121[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_121 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_121[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_121[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_122 (Batch  (None, 16, 16, 96)  288         ['conv2d_122[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_122 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_122[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)            (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)            (None, 7, 7, 96)     82944       ['activation_122[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_120 (Batch  (None, 7, 7, 384)   1152        ['conv2d_120[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_123 (Batch  (None, 7, 7, 96)    288         ['conv2d_123[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_120 (Activation)    (None, 7, 7, 384)    0           ['batch_normalization_120[0][0]']\n",
      "                                                                                                  \n",
      " activation_123 (Activation)    (None, 7, 7, 96)     0           ['batch_normalization_123[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_120[0][0]',         \n",
      "                                                                  'activation_123[0][0]',         \n",
      "                                                                  'max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)            (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_128 (Batch  (None, 7, 7, 128)   384         ['conv2d_128[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_128 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_128[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_128[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_129 (Batch  (None, 7, 7, 128)   384         ['conv2d_129[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_129 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_129[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)            (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_129[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_125 (Batch  (None, 7, 7, 128)   384         ['conv2d_125[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_130 (Batch  (None, 7, 7, 128)   384         ['conv2d_130[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_125 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_125[0][0]']\n",
      "                                                                                                  \n",
      " activation_130 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_130[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_125[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_130[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_126 (Batch  (None, 7, 7, 128)   384         ['conv2d_126[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_131 (Batch  (None, 7, 7, 128)   384         ['conv2d_131[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_126 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_126[0][0]']\n",
      "                                                                                                  \n",
      " activation_131 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_131[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_12 (AverageP  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)            (None, 7, 7, 192)    172032      ['activation_126[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)            (None, 7, 7, 192)    172032      ['activation_131[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_12[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_124 (Batch  (None, 7, 7, 192)   576         ['conv2d_124[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_127 (Batch  (None, 7, 7, 192)   576         ['conv2d_127[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_132 (Batch  (None, 7, 7, 192)   576         ['conv2d_132[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_133 (Batch  (None, 7, 7, 192)   576         ['conv2d_133[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_124 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_124[0][0]']\n",
      "                                                                                                  \n",
      " activation_127 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_127[0][0]']\n",
      "                                                                                                  \n",
      " activation_132 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_132[0][0]']\n",
      "                                                                                                  \n",
      " activation_133 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_133[0][0]']\n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_124[0][0]',         \n",
      "                                                                  'activation_127[0][0]',         \n",
      "                                                                  'activation_132[0][0]',         \n",
      "                                                                  'activation_133[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_138 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_138 (Batch  (None, 7, 7, 160)   480         ['conv2d_138[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_138 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_138[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_138[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_139 (Batch  (None, 7, 7, 160)   480         ['conv2d_139[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_139 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_139[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_135 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_139[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_135 (Batch  (None, 7, 7, 160)   480         ['conv2d_135[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_140 (Batch  (None, 7, 7, 160)   480         ['conv2d_140[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_135 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_135[0][0]']\n",
      "                                                                                                  \n",
      " activation_140 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_140[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_136 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_135[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_140[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_136 (Batch  (None, 7, 7, 160)   480         ['conv2d_136[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_141 (Batch  (None, 7, 7, 160)   480         ['conv2d_141[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_136 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_136[0][0]']\n",
      "                                                                                                  \n",
      " activation_141 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_141[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_13 (AverageP  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_134 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_137 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_136[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_141[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_13[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_134 (Batch  (None, 7, 7, 192)   576         ['conv2d_134[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_137 (Batch  (None, 7, 7, 192)   576         ['conv2d_137[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_142 (Batch  (None, 7, 7, 192)   576         ['conv2d_142[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_143 (Batch  (None, 7, 7, 192)   576         ['conv2d_143[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_134 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_134[0][0]']\n",
      "                                                                                                  \n",
      " activation_137 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_137[0][0]']\n",
      "                                                                                                  \n",
      " activation_142 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_142[0][0]']\n",
      "                                                                                                  \n",
      " activation_143 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_143[0][0]']\n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_134[0][0]',         \n",
      "                                                                  'activation_137[0][0]',         \n",
      "                                                                  'activation_142[0][0]',         \n",
      "                                                                  'activation_143[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_148 (Batch  (None, 7, 7, 160)   480         ['conv2d_148[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_148 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_148[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_148[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_149 (Batch  (None, 7, 7, 160)   480         ['conv2d_149[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_149 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_149[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_150 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_149[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_145 (Batch  (None, 7, 7, 160)   480         ['conv2d_145[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_150 (Batch  (None, 7, 7, 160)   480         ['conv2d_150[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_145 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_145[0][0]']\n",
      "                                                                                                  \n",
      " activation_150 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_150[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_145[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_151 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_150[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_146 (Batch  (None, 7, 7, 160)   480         ['conv2d_146[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_151 (Batch  (None, 7, 7, 160)   480         ['conv2d_151[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_146 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_146[0][0]']\n",
      "                                                                                                  \n",
      " activation_151 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_151[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_14 (AverageP  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_146[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_152 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_151[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_153 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_14[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_144 (Batch  (None, 7, 7, 192)   576         ['conv2d_144[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_147 (Batch  (None, 7, 7, 192)   576         ['conv2d_147[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_152 (Batch  (None, 7, 7, 192)   576         ['conv2d_152[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_153 (Batch  (None, 7, 7, 192)   576         ['conv2d_153[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_144 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_144[0][0]']\n",
      "                                                                                                  \n",
      " activation_147 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_147[0][0]']\n",
      "                                                                                                  \n",
      " activation_152 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_152[0][0]']\n",
      "                                                                                                  \n",
      " activation_153 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_153[0][0]']\n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_144[0][0]',         \n",
      "                                                                  'activation_147[0][0]',         \n",
      "                                                                  'activation_152[0][0]',         \n",
      "                                                                  'activation_153[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_158 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_158 (Batch  (None, 7, 7, 192)   576         ['conv2d_158[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_158 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_158[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_159 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_158[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_159 (Batch  (None, 7, 7, 192)   576         ['conv2d_159[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_159 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_159[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_155 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_160 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_159[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_155 (Batch  (None, 7, 7, 192)   576         ['conv2d_155[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_160 (Batch  (None, 7, 7, 192)   576         ['conv2d_160[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_155 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_155[0][0]']\n",
      "                                                                                                  \n",
      " activation_160 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_160[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_156 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_155[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_161 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_160[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_156 (Batch  (None, 7, 7, 192)   576         ['conv2d_156[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_161 (Batch  (None, 7, 7, 192)   576         ['conv2d_161[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_156 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_156[0][0]']\n",
      "                                                                                                  \n",
      " activation_161 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_161[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_15 (AverageP  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_154 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_157 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_156[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_162 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_161[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_163 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_15[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_154 (Batch  (None, 7, 7, 192)   576         ['conv2d_154[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_157 (Batch  (None, 7, 7, 192)   576         ['conv2d_157[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_162 (Batch  (None, 7, 7, 192)   576         ['conv2d_162[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_163 (Batch  (None, 7, 7, 192)   576         ['conv2d_163[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_154 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_154[0][0]']\n",
      "                                                                                                  \n",
      " activation_157 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_157[0][0]']\n",
      "                                                                                                  \n",
      " activation_162 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_162[0][0]']\n",
      "                                                                                                  \n",
      " activation_163 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_163[0][0]']\n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_154[0][0]',         \n",
      "                                                                  'activation_157[0][0]',         \n",
      "                                                                  'activation_162[0][0]',         \n",
      "                                                                  'activation_163[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_166 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_166 (Batch  (None, 7, 7, 192)   576         ['conv2d_166[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_166 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_166[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_167 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_166[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_167 (Batch  (None, 7, 7, 192)   576         ['conv2d_167[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_167 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_167[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_164 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_168 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_167[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_164 (Batch  (None, 7, 7, 192)   576         ['conv2d_164[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_168 (Batch  (None, 7, 7, 192)   576         ['conv2d_168[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_164 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_164[0][0]']\n",
      "                                                                                                  \n",
      " activation_168 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_168[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_165 (Conv2D)            (None, 3, 3, 320)    552960      ['activation_164[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_169 (Conv2D)            (None, 3, 3, 192)    331776      ['activation_168[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_165 (Batch  (None, 3, 3, 320)   960         ['conv2d_165[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_169 (Batch  (None, 3, 3, 192)   576         ['conv2d_169[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_165 (Activation)    (None, 3, 3, 320)    0           ['batch_normalization_165[0][0]']\n",
      "                                                                                                  \n",
      " activation_169 (Activation)    (None, 3, 3, 192)    0           ['batch_normalization_169[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 3, 3, 1280)   0           ['activation_165[0][0]',         \n",
      "                                                                  'activation_169[0][0]',         \n",
      "                                                                  'max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_174 (Conv2D)            (None, 3, 3, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_174 (Batch  (None, 3, 3, 448)   1344        ['conv2d_174[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_174 (Activation)    (None, 3, 3, 448)    0           ['batch_normalization_174[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_171 (Conv2D)            (None, 3, 3, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_175 (Conv2D)            (None, 3, 3, 384)    1548288     ['activation_174[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_171 (Batch  (None, 3, 3, 384)   1152        ['conv2d_171[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_175 (Batch  (None, 3, 3, 384)   1152        ['conv2d_175[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_171 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_171[0][0]']\n",
      "                                                                                                  \n",
      " activation_175 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_175[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_172 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_171[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_173 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_171[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_176 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_175[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_177 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_175[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_16 (AverageP  (None, 3, 3, 1280)  0           ['mixed8[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_170 (Conv2D)            (None, 3, 3, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_172 (Batch  (None, 3, 3, 384)   1152        ['conv2d_172[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_173 (Batch  (None, 3, 3, 384)   1152        ['conv2d_173[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_176 (Batch  (None, 3, 3, 384)   1152        ['conv2d_176[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_177 (Batch  (None, 3, 3, 384)   1152        ['conv2d_177[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_178 (Conv2D)            (None, 3, 3, 192)    245760      ['average_pooling2d_16[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_170 (Batch  (None, 3, 3, 320)   960         ['conv2d_170[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_172 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_172[0][0]']\n",
      "                                                                                                  \n",
      " activation_173 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_173[0][0]']\n",
      "                                                                                                  \n",
      " activation_176 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_176[0][0]']\n",
      "                                                                                                  \n",
      " activation_177 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_177[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_178 (Batch  (None, 3, 3, 192)   576         ['conv2d_178[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_170 (Activation)    (None, 3, 3, 320)    0           ['batch_normalization_170[0][0]']\n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 3, 3, 768)    0           ['activation_172[0][0]',         \n",
      "                                                                  'activation_173[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 3, 3, 768)    0           ['activation_176[0][0]',         \n",
      "                                                                  'activation_177[0][0]']         \n",
      "                                                                                                  \n",
      " activation_178 (Activation)    (None, 3, 3, 192)    0           ['batch_normalization_178[0][0]']\n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 3, 3, 2048)   0           ['activation_170[0][0]',         \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate_2[0][0]',          \n",
      "                                                                  'activation_178[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_183 (Conv2D)            (None, 3, 3, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_183 (Batch  (None, 3, 3, 448)   1344        ['conv2d_183[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_183 (Activation)    (None, 3, 3, 448)    0           ['batch_normalization_183[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_180 (Conv2D)            (None, 3, 3, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_184 (Conv2D)            (None, 3, 3, 384)    1548288     ['activation_183[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_180 (Batch  (None, 3, 3, 384)   1152        ['conv2d_180[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_184 (Batch  (None, 3, 3, 384)   1152        ['conv2d_184[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_180 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_180[0][0]']\n",
      "                                                                                                  \n",
      " activation_184 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_184[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_181 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_180[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_182 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_180[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_185 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_184[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_186 (Conv2D)            (None, 3, 3, 384)    442368      ['activation_184[0][0]']         \n",
      "                                                                                                  \n",
      " average_pooling2d_17 (AverageP  (None, 3, 3, 2048)  0           ['mixed9[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_179 (Conv2D)            (None, 3, 3, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_181 (Batch  (None, 3, 3, 384)   1152        ['conv2d_181[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_182 (Batch  (None, 3, 3, 384)   1152        ['conv2d_182[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_185 (Batch  (None, 3, 3, 384)   1152        ['conv2d_185[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_186 (Batch  (None, 3, 3, 384)   1152        ['conv2d_186[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_187 (Conv2D)            (None, 3, 3, 192)    393216      ['average_pooling2d_17[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_179 (Batch  (None, 3, 3, 320)   960         ['conv2d_179[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_181 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_181[0][0]']\n",
      "                                                                                                  \n",
      " activation_182 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_182[0][0]']\n",
      "                                                                                                  \n",
      " activation_185 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_185[0][0]']\n",
      "                                                                                                  \n",
      " activation_186 (Activation)    (None, 3, 3, 384)    0           ['batch_normalization_186[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_187 (Batch  (None, 3, 3, 192)   576         ['conv2d_187[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_179 (Activation)    (None, 3, 3, 320)    0           ['batch_normalization_179[0][0]']\n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 3, 3, 768)    0           ['activation_181[0][0]',         \n",
      "                                                                  'activation_182[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 3, 3, 768)    0           ['activation_185[0][0]',         \n",
      "                                                                  'activation_186[0][0]']         \n",
      "                                                                                                  \n",
      " activation_187 (Activation)    (None, 3, 3, 192)    0           ['batch_normalization_187[0][0]']\n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 3, 3, 2048)   0           ['activation_179[0][0]',         \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_3[0][0]',          \n",
      "                                                                  'activation_187[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pretrained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## add Dense layer to classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, 74, 74, 32)   864         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, 74, 74, 32)  96          ['conv2d_94[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_94 (Activation)     (None, 74, 74, 32)   0           ['batch_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, 72, 72, 32)   9216        ['activation_94[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_95 (BatchN  (None, 72, 72, 32)  96          ['conv2d_95[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_95 (Activation)     (None, 72, 72, 32)   0           ['batch_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)             (None, 72, 72, 64)   18432       ['activation_95[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_96 (BatchN  (None, 72, 72, 64)  192         ['conv2d_96[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_96 (Activation)     (None, 72, 72, 64)   0           ['batch_normalization_96[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)  0           ['activation_96[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)             (None, 35, 35, 80)   5120        ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_97 (BatchN  (None, 35, 35, 80)  240         ['conv2d_97[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_97 (Activation)     (None, 35, 35, 80)   0           ['batch_normalization_97[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)             (None, 33, 33, 192)  138240      ['activation_97[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_98 (BatchN  (None, 33, 33, 192)  576        ['conv2d_98[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_98 (Activation)     (None, 33, 33, 192)  0           ['batch_normalization_98[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_98[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)            (None, 16, 16, 64)   12288       ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_102 (Batch  (None, 16, 16, 64)  192         ['conv2d_102[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_102 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_102[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)            (None, 16, 16, 48)   9216        ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_102[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_100 (Batch  (None, 16, 16, 48)  144         ['conv2d_100[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_103 (Batch  (None, 16, 16, 96)  288         ['conv2d_103[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_100 (Activation)    (None, 16, 16, 48)   0           ['batch_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " activation_103 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_103[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_9 (AveragePo  (None, 16, 16, 192)  0          ['max_pooling2d_5[0][0]']        \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)             (None, 16, 16, 64)   12288       ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)            (None, 16, 16, 64)   76800       ['activation_100[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)            (None, 16, 16, 96)   82944       ['activation_103[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)            (None, 16, 16, 32)   6144        ['average_pooling2d_9[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_99 (BatchN  (None, 16, 16, 64)  192         ['conv2d_99[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_101 (Batch  (None, 16, 16, 64)  192         ['conv2d_101[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_104 (Batch  (None, 16, 16, 96)  288         ['conv2d_104[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_105 (Batch  (None, 16, 16, 32)  96          ['conv2d_105[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_99 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " activation_101 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_101[0][0]']\n",
      "                                                                                                  \n",
      " activation_104 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_104[0][0]']\n",
      "                                                                                                  \n",
      " activation_105 (Activation)    (None, 16, 16, 32)   0           ['batch_normalization_105[0][0]']\n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_99[0][0]',          \n",
      "                                                                  'activation_101[0][0]',         \n",
      "                                                                  'activation_104[0][0]',         \n",
      "                                                                  'activation_105[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)            (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_109 (Batch  (None, 16, 16, 64)  192         ['conv2d_109[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_109 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_109[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)            (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_109[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_107 (Batch  (None, 16, 16, 48)  144         ['conv2d_107[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_110 (Batch  (None, 16, 16, 96)  288         ['conv2d_110[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_107 (Activation)    (None, 16, 16, 48)   0           ['batch_normalization_107[0][0]']\n",
      "                                                                                                  \n",
      " activation_110 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_110[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_10 (AverageP  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)            (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)            (None, 16, 16, 64)   76800       ['activation_107[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)            (None, 16, 16, 96)   82944       ['activation_110[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)            (None, 16, 16, 64)   16384       ['average_pooling2d_10[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_106 (Batch  (None, 16, 16, 64)  192         ['conv2d_106[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_108 (Batch  (None, 16, 16, 64)  192         ['conv2d_108[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_111 (Batch  (None, 16, 16, 96)  288         ['conv2d_111[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_112 (Batch  (None, 16, 16, 64)  192         ['conv2d_112[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_106 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " activation_108 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_108[0][0]']\n",
      "                                                                                                  \n",
      " activation_111 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_111[0][0]']\n",
      "                                                                                                  \n",
      " activation_112 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_112[0][0]']\n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_106[0][0]',         \n",
      "                                                                  'activation_108[0][0]',         \n",
      "                                                                  'activation_111[0][0]',         \n",
      "                                                                  'activation_112[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)            (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_116 (Batch  (None, 16, 16, 64)  192         ['conv2d_116[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_116 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_116[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)            (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_116[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_114 (Batch  (None, 16, 16, 48)  144         ['conv2d_114[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_117 (Batch  (None, 16, 16, 96)  288         ['conv2d_117[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_114 (Activation)    (None, 16, 16, 48)   0           ['batch_normalization_114[0][0]']\n",
      "                                                                                                  \n",
      " activation_117 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_117[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_11 (AverageP  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)            (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)            (None, 16, 16, 64)   76800       ['activation_114[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)            (None, 16, 16, 96)   82944       ['activation_117[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)            (None, 16, 16, 64)   18432       ['average_pooling2d_11[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_113 (Batch  (None, 16, 16, 64)  192         ['conv2d_113[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_115 (Batch  (None, 16, 16, 64)  192         ['conv2d_115[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_118 (Batch  (None, 16, 16, 96)  288         ['conv2d_118[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_119 (Batch  (None, 16, 16, 64)  192         ['conv2d_119[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_113 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_113[0][0]']\n",
      "                                                                                                  \n",
      " activation_115 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_115[0][0]']\n",
      "                                                                                                  \n",
      " activation_118 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_118[0][0]']\n",
      "                                                                                                  \n",
      " activation_119 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_119[0][0]']\n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_113[0][0]',         \n",
      "                                                                  'activation_115[0][0]',         \n",
      "                                                                  'activation_118[0][0]',         \n",
      "                                                                  'activation_119[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)            (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_121 (Batch  (None, 16, 16, 64)  192         ['conv2d_121[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_121 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_121[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)            (None, 16, 16, 96)   55296       ['activation_121[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_122 (Batch  (None, 16, 16, 96)  288         ['conv2d_122[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_122 (Activation)    (None, 16, 16, 96)   0           ['batch_normalization_122[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)            (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)            (None, 7, 7, 96)     82944       ['activation_122[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_120 (Batch  (None, 7, 7, 384)   1152        ['conv2d_120[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_123 (Batch  (None, 7, 7, 96)    288         ['conv2d_123[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_120 (Activation)    (None, 7, 7, 384)    0           ['batch_normalization_120[0][0]']\n",
      "                                                                                                  \n",
      " activation_123 (Activation)    (None, 7, 7, 96)     0           ['batch_normalization_123[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_120[0][0]',         \n",
      "                                                                  'activation_123[0][0]',         \n",
      "                                                                  'max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)            (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_128 (Batch  (None, 7, 7, 128)   384         ['conv2d_128[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_128 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_128[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_128[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_129 (Batch  (None, 7, 7, 128)   384         ['conv2d_129[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_129 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_129[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)            (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_129[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_125 (Batch  (None, 7, 7, 128)   384         ['conv2d_125[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_130 (Batch  (None, 7, 7, 128)   384         ['conv2d_130[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_125 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_125[0][0]']\n",
      "                                                                                                  \n",
      " activation_130 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_130[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_125[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_130[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_126 (Batch  (None, 7, 7, 128)   384         ['conv2d_126[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_131 (Batch  (None, 7, 7, 128)   384         ['conv2d_131[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_126 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_126[0][0]']\n",
      "                                                                                                  \n",
      " activation_131 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_131[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_12 (AverageP  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)            (None, 7, 7, 192)    172032      ['activation_126[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)            (None, 7, 7, 192)    172032      ['activation_131[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_12[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_124 (Batch  (None, 7, 7, 192)   576         ['conv2d_124[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_127 (Batch  (None, 7, 7, 192)   576         ['conv2d_127[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_132 (Batch  (None, 7, 7, 192)   576         ['conv2d_132[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_133 (Batch  (None, 7, 7, 192)   576         ['conv2d_133[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_124 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_124[0][0]']\n",
      "                                                                                                  \n",
      " activation_127 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_127[0][0]']\n",
      "                                                                                                  \n",
      " activation_132 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_132[0][0]']\n",
      "                                                                                                  \n",
      " activation_133 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_133[0][0]']\n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_124[0][0]',         \n",
      "                                                                  'activation_127[0][0]',         \n",
      "                                                                  'activation_132[0][0]',         \n",
      "                                                                  'activation_133[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_138 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_138 (Batch  (None, 7, 7, 160)   480         ['conv2d_138[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_138 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_138[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_138[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_139 (Batch  (None, 7, 7, 160)   480         ['conv2d_139[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_139 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_139[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_135 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_139[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_135 (Batch  (None, 7, 7, 160)   480         ['conv2d_135[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_140 (Batch  (None, 7, 7, 160)   480         ['conv2d_140[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_135 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_135[0][0]']\n",
      "                                                                                                  \n",
      " activation_140 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_140[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_136 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_135[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_140[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_136 (Batch  (None, 7, 7, 160)   480         ['conv2d_136[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_141 (Batch  (None, 7, 7, 160)   480         ['conv2d_141[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_136 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_136[0][0]']\n",
      "                                                                                                  \n",
      " activation_141 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_141[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_13 (AverageP  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_134 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_137 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_136[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_141[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_13[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_134 (Batch  (None, 7, 7, 192)   576         ['conv2d_134[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_137 (Batch  (None, 7, 7, 192)   576         ['conv2d_137[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_142 (Batch  (None, 7, 7, 192)   576         ['conv2d_142[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_143 (Batch  (None, 7, 7, 192)   576         ['conv2d_143[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_134 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_134[0][0]']\n",
      "                                                                                                  \n",
      " activation_137 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_137[0][0]']\n",
      "                                                                                                  \n",
      " activation_142 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_142[0][0]']\n",
      "                                                                                                  \n",
      " activation_143 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_143[0][0]']\n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_134[0][0]',         \n",
      "                                                                  'activation_137[0][0]',         \n",
      "                                                                  'activation_142[0][0]',         \n",
      "                                                                  'activation_143[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_148 (Batch  (None, 7, 7, 160)   480         ['conv2d_148[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_148 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_148[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_148[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_149 (Batch  (None, 7, 7, 160)   480         ['conv2d_149[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_149 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_149[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)            (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_150 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_149[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_145 (Batch  (None, 7, 7, 160)   480         ['conv2d_145[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_150 (Batch  (None, 7, 7, 160)   480         ['conv2d_150[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_145 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_145[0][0]']\n",
      "                                                                                                  \n",
      " activation_150 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_150[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_145[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_151 (Conv2D)            (None, 7, 7, 160)    179200      ['activation_150[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_146 (Batch  (None, 7, 7, 160)   480         ['conv2d_146[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_151 (Batch  (None, 7, 7, 160)   480         ['conv2d_151[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_146 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_146[0][0]']\n",
      "                                                                                                  \n",
      " activation_151 (Activation)    (None, 7, 7, 160)    0           ['batch_normalization_151[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_14 (AverageP  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_146[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_152 (Conv2D)            (None, 7, 7, 192)    215040      ['activation_151[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_153 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_14[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_144 (Batch  (None, 7, 7, 192)   576         ['conv2d_144[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_147 (Batch  (None, 7, 7, 192)   576         ['conv2d_147[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_152 (Batch  (None, 7, 7, 192)   576         ['conv2d_152[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_153 (Batch  (None, 7, 7, 192)   576         ['conv2d_153[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_144 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_144[0][0]']\n",
      "                                                                                                  \n",
      " activation_147 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_147[0][0]']\n",
      "                                                                                                  \n",
      " activation_152 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_152[0][0]']\n",
      "                                                                                                  \n",
      " activation_153 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_153[0][0]']\n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_144[0][0]',         \n",
      "                                                                  'activation_147[0][0]',         \n",
      "                                                                  'activation_152[0][0]',         \n",
      "                                                                  'activation_153[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_158 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_158 (Batch  (None, 7, 7, 192)   576         ['conv2d_158[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_158 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_158[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_159 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_158[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_159 (Batch  (None, 7, 7, 192)   576         ['conv2d_159[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_159 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_159[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_155 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_160 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_159[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_155 (Batch  (None, 7, 7, 192)   576         ['conv2d_155[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_160 (Batch  (None, 7, 7, 192)   576         ['conv2d_160[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_155 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_155[0][0]']\n",
      "                                                                                                  \n",
      " activation_160 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_160[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_156 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_155[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_161 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_160[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_156 (Batch  (None, 7, 7, 192)   576         ['conv2d_156[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_161 (Batch  (None, 7, 7, 192)   576         ['conv2d_161[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_156 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_156[0][0]']\n",
      "                                                                                                  \n",
      " activation_161 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_161[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_15 (AverageP  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_154 (Conv2D)            (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_157 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_156[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_162 (Conv2D)            (None, 7, 7, 192)    258048      ['activation_161[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_163 (Conv2D)            (None, 7, 7, 192)    147456      ['average_pooling2d_15[0][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_154 (Batch  (None, 7, 7, 192)   576         ['conv2d_154[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_157 (Batch  (None, 7, 7, 192)   576         ['conv2d_157[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_162 (Batch  (None, 7, 7, 192)   576         ['conv2d_162[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_163 (Batch  (None, 7, 7, 192)   576         ['conv2d_163[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_154 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_154[0][0]']\n",
      "                                                                                                  \n",
      " activation_157 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_157[0][0]']\n",
      "                                                                                                  \n",
      " activation_162 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_162[0][0]']\n",
      "                                                                                                  \n",
      " activation_163 (Activation)    (None, 7, 7, 192)    0           ['batch_normalization_163[0][0]']\n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_154[0][0]',         \n",
      "                                                                  'activation_157[0][0]',         \n",
      "                                                                  'activation_162[0][0]',         \n",
      "                                                                  'activation_163[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 37632)        0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1024)         38536192    ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 1024)         0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            1025        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import Model\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "x = Flatten()(last_output)\n",
    "x = Dense(1024)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=pretrained_model.input, outputs=outputs)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Set the training parameters\n",
    "model.compile(optimizer = RMSprop(learning_rate=0.0001),\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Define our example directories and files\n",
    "base_dir = '../Week_1/cats_and_dogs_filtered/cats_and_dogs_filtered'\n",
    "\n",
    "train_dir = os.path.join( base_dir, 'train')\n",
    "validation_dir = os.path.join( base_dir, 'validation')\n",
    "\n",
    "# Directory with training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "\n",
    "# Directory with training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory with validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "\n",
    "# Directory with validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = (150, 150))\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                          batch_size  = 20,\n",
    "                                                          class_mode  = 'binary',\n",
    "                                                          target_size = (150, 150))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 - 51s - loss: 0.7447 - accuracy: 0.8620 - val_loss: 0.2922 - val_accuracy: 0.9400 - 51s/epoch - 506ms/step\n",
      "Epoch 2/20\n",
      "100/100 - 39s - loss: 0.5823 - accuracy: 0.8890 - val_loss: 0.2254 - val_accuracy: 0.9530 - 39s/epoch - 389ms/step\n",
      "Epoch 3/20\n",
      "100/100 - 38s - loss: 0.4731 - accuracy: 0.9050 - val_loss: 0.2306 - val_accuracy: 0.9540 - 38s/epoch - 378ms/step\n",
      "Epoch 4/20\n",
      "100/100 - 39s - loss: 0.3968 - accuracy: 0.9210 - val_loss: 0.3706 - val_accuracy: 0.9380 - 39s/epoch - 386ms/step\n",
      "Epoch 5/20\n",
      "100/100 - 38s - loss: 0.4040 - accuracy: 0.9200 - val_loss: 0.1727 - val_accuracy: 0.9630 - 38s/epoch - 381ms/step\n",
      "Epoch 6/20\n",
      "100/100 - 39s - loss: 0.3431 - accuracy: 0.9335 - val_loss: 0.2817 - val_accuracy: 0.9540 - 39s/epoch - 392ms/step\n",
      "Epoch 7/20\n",
      "100/100 - 39s - loss: 0.3569 - accuracy: 0.9310 - val_loss: 0.3241 - val_accuracy: 0.9400 - 39s/epoch - 394ms/step\n",
      "Epoch 8/20\n",
      "100/100 - 39s - loss: 0.3404 - accuracy: 0.9265 - val_loss: 0.1882 - val_accuracy: 0.9670 - 39s/epoch - 395ms/step\n",
      "Epoch 9/20\n",
      "100/100 - 40s - loss: 0.2944 - accuracy: 0.9355 - val_loss: 0.3325 - val_accuracy: 0.9430 - 40s/epoch - 403ms/step\n",
      "Epoch 10/20\n",
      "100/100 - 38s - loss: 0.3085 - accuracy: 0.9345 - val_loss: 0.2472 - val_accuracy: 0.9490 - 38s/epoch - 382ms/step\n",
      "Epoch 11/20\n",
      "100/100 - 39s - loss: 0.3191 - accuracy: 0.9435 - val_loss: 0.3170 - val_accuracy: 0.9460 - 39s/epoch - 385ms/step\n",
      "Epoch 12/20\n",
      "100/100 - 38s - loss: 0.2734 - accuracy: 0.9505 - val_loss: 0.2248 - val_accuracy: 0.9590 - 38s/epoch - 383ms/step\n",
      "Epoch 13/20\n",
      "100/100 - 38s - loss: 0.3083 - accuracy: 0.9415 - val_loss: 0.2870 - val_accuracy: 0.9410 - 38s/epoch - 381ms/step\n",
      "Epoch 14/20\n",
      "100/100 - 37s - loss: 0.2204 - accuracy: 0.9520 - val_loss: 0.2805 - val_accuracy: 0.9470 - 37s/epoch - 373ms/step\n",
      "Epoch 15/20\n",
      "100/100 - 38s - loss: 0.2595 - accuracy: 0.9465 - val_loss: 0.2717 - val_accuracy: 0.9530 - 38s/epoch - 381ms/step\n",
      "Epoch 16/20\n",
      "100/100 - 38s - loss: 0.2520 - accuracy: 0.9455 - val_loss: 0.2253 - val_accuracy: 0.9580 - 38s/epoch - 380ms/step\n",
      "Epoch 17/20\n",
      "100/100 - 39s - loss: 0.2285 - accuracy: 0.9545 - val_loss: 0.2332 - val_accuracy: 0.9630 - 39s/epoch - 386ms/step\n",
      "Epoch 18/20\n",
      "100/100 - 38s - loss: 0.2110 - accuracy: 0.9525 - val_loss: 0.1956 - val_accuracy: 0.9690 - 38s/epoch - 381ms/step\n",
      "Epoch 19/20\n",
      "100/100 - 37s - loss: 0.2127 - accuracy: 0.9505 - val_loss: 0.2225 - val_accuracy: 0.9600 - 37s/epoch - 374ms/step\n",
      "Epoch 20/20\n",
      "100/100 - 38s - loss: 0.2202 - accuracy: 0.9535 - val_loss: 0.2072 - val_accuracy: 0.9640 - 38s/epoch - 376ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = 100,\n",
    "            epochs = 20,\n",
    "            validation_steps = 50,\n",
    "            verbose = 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}